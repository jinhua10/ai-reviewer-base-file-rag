# ğŸ‡¨ğŸ‡³ Qwen æ¨¡å‹å¿«é€Ÿä¸Šæ‰‹æŒ‡å—

## ğŸ“… æ›´æ–°æ—¶é—´
2025-12-04 21:00:00

## âœ… å·²å®Œæˆçš„æ›´æ”¹

### 1. é…ç½®æ–‡ä»¶æ›´æ–° âœ…
- `application.yml` - ONNX é…ç½®å·²åˆ‡æ¢åˆ° Qwen æ¨¡å‹
- `PPLConfig.java` - é»˜è®¤è·¯å¾„å·²æ›´æ–°

### 2. æ–°å¢æ–‡ä»¶ âœ…
- `scripts/download_qwen_models.py` - Qwen æ¨¡å‹ä¸‹è½½è„šæœ¬

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆ3 æ­¥ï¼‰

### æ­¥éª¤ 1ï¼šä¸‹è½½ Qwen æ¨¡å‹

```bash
# æ–¹æ³•1ï¼šä½¿ç”¨è‡ªåŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰
cd D:\Jetbrains\hackathon\ai-reviewer-base-file-rag
python scripts/download_qwen_models.py --model 0.5b

# æ–¹æ³•2ï¼šæ‰‹åŠ¨ä¸‹è½½
python scripts/download_qwen_models.py --model 1.5b  # æ›´å¥½çš„è´¨é‡
python scripts/download_qwen_models.py --model 7b    # æœ€é«˜è´¨é‡ï¼ˆéœ€è¦æ›´å¤šèµ„æºï¼‰
```

**æ¨¡å‹é€‰æ‹©å»ºè®®ï¼š**
- `0.5b` - è½»é‡çº§ï¼ˆæ¨èï¼Œ~500MBï¼Œå¿«é€Ÿï¼‰
- `1.5b` - å¹³è¡¡ï¼ˆ~1.5GBï¼Œè´¨é‡æ›´å¥½ï¼‰
- `7b` - é«˜è´¨é‡ï¼ˆ~7GBï¼Œéœ€è¦ 8GB+ å†…å­˜ï¼‰

### æ­¥éª¤ 2ï¼šéªŒè¯æ¨¡å‹æ–‡ä»¶

```bash
# æ£€æŸ¥æ¨¡å‹æ˜¯å¦ä¸‹è½½æˆåŠŸ
ls ./models/qwen2.5-0.5b-instruct/

# åº”è¯¥çœ‹åˆ°ï¼š
# - model.onnx          (æ¨¡å‹æ–‡ä»¶)
# - tokenizer.json      (åˆ†è¯å™¨)
# - config.json         (é…ç½®)
```

### æ­¥éª¤ 3ï¼šå¯åŠ¨åº”ç”¨

```bash
# å¯åŠ¨ Spring Boot åº”ç”¨
./mvnw spring-boot:run

# æˆ–ä½¿ç”¨ IDE ç›´æ¥è¿è¡Œ
```

---

## ğŸ“‹ å½“å‰é…ç½®

### application.ymlï¼ˆå·²æ›´æ–°ï¼‰

```yaml
knowledge:
  qa:
    ppl:
      default-provider: onnx
      
      onnx:
        enabled: true
        
        # Qwen2.5-0.5Bï¼ˆæ¨èï¼‰
        model-path: ./models/qwen2.5-0.5b-instruct/model.onnx
        tokenizer-path: ./models/qwen2.5-0.5b-instruct/tokenizer.json
        
        # å…¶ä»–é€‰é¡¹ï¼ˆæ³¨é‡Šæ‰ï¼‰
        # Qwen2.5-1.5B: ./models/qwen2.5-1.5b-instruct/
        # Qwen2-7B: ./models/qwen2-7b-instruct/
```

### PPLConfig.javaï¼ˆå·²æ›´æ–°ï¼‰

```java
public static class OnnxConfig {
    private boolean enabled = true;
    private String modelPath = "./models/qwen2.5-0.5b-instruct/model.onnx";
    private String tokenizerPath = "./models/qwen2.5-0.5b-instruct/tokenizer.json";
    // ...
}
```

---

## ğŸ”§ é«˜çº§é…ç½®

### åˆ‡æ¢åˆ°å…¶ä»– Qwen æ¨¡å‹

#### 1. ä½¿ç”¨ Qwen2.5-1.5Bï¼ˆæ›´å¥½çš„è´¨é‡ï¼‰

```yaml
# application.yml
onnx:
  model-path: ./models/qwen2.5-1.5b-instruct/model.onnx
  tokenizer-path: ./models/qwen2.5-1.5b-instruct/tokenizer.json
```

```bash
# ä¸‹è½½æ¨¡å‹
python scripts/download_qwen_models.py --model 1.5b
```

#### 2. ä½¿ç”¨ Qwen2-7Bï¼ˆæœ€é«˜è´¨é‡ï¼‰

```yaml
# application.yml
onnx:
  model-path: ./models/qwen2-7b-instruct/model.onnx
  tokenizer-path: ./models/qwen2-7b-instruct/tokenizer.json
  max-batch-size: 4  # é™ä½æ‰¹å¤„ç†å¤§å°
```

```bash
# ä¸‹è½½æ¨¡å‹ï¼ˆéœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰
python scripts/download_qwen_models.py --model 7b
```

### æ€§èƒ½ä¼˜åŒ–é…ç½®

```yaml
onnx:
  enabled: true
  model-path: ./models/qwen2.5-0.5b-instruct/model.onnx
  tokenizer-path: ./models/qwen2.5-0.5b-instruct/tokenizer.json
  
  # æ€§èƒ½ä¼˜åŒ–
  max-batch-size: 16        # æé«˜å¹¶å‘ï¼ˆå¦‚æœå†…å­˜å……è¶³ï¼‰
  use-cache: true           # å¯ç”¨ç¼“å­˜
  cache-size: 50000         # å¢å¤§ç¼“å­˜
  cache-ttl: 7200           # å»¶é•¿ç¼“å­˜æ—¶é—´ï¼ˆ2å°æ—¶ï¼‰
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### Qwen vs GPT2ï¼ˆPPL è®¡ç®—ï¼‰

| æŒ‡æ ‡ | GPT2-Medium | Qwen2.5-0.5B | Qwen2.5-1.5B |
|------|-------------|--------------|--------------|
| **æ¨¡å‹å¤§å°** | ~1.5GB | ~500MB | ~1.5GB |
| **ä¸­æ–‡æ”¯æŒ** | â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |
| **é€Ÿåº¦** | 15-50ms | 20-60ms | 30-80ms |
| **è´¨é‡** | â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| **æ¨èåœºæ™¯** | è‹±æ–‡ä¸ºä¸» | ä¸­æ–‡ä¼˜å…ˆ âœ… | é«˜è´¨é‡éœ€æ±‚ |

### ä¸ºä»€ä¹ˆé€‰æ‹© Qwenï¼Ÿ

1. **ä¸­æ–‡ä¼˜åŒ–** âœ…
   - Qwen ç”±é˜¿é‡Œè¾¾æ‘©é™¢å¼€å‘ï¼Œä¸“é—¨ä¼˜åŒ–äº†ä¸­æ–‡æ€§èƒ½
   - å¯¹ä¸­æ–‡æ–‡æ¡£çš„å›°æƒ‘åº¦è®¡ç®—æ›´å‡†ç¡®

2. **å¼€æºå…è´¹** âœ…
   - å®Œå…¨å¼€æºï¼Œå¯å•†ç”¨
   - Apache 2.0 è®¸å¯è¯

3. **æ€§èƒ½ä¼˜ç§€** âœ…
   - 0.5B æ¨¡å‹è¶³å¤Ÿè½»é‡ï¼Œé€Ÿåº¦å¿«
   - è´¨é‡æ¥è¿‘ç”šè‡³è¶…è¿‡æ›´å¤§çš„æ¨¡å‹

4. **å›½äº§æ”¯æŒ** ğŸ‡¨ğŸ‡³
   - æ”¯æŒå›½äº§æŠ€æœ¯å‘å±•
   - é¿å…æµ·å¤–ä¾èµ–

---

## ğŸ§ª æµ‹è¯•éªŒè¯

### 1. åŸºç¡€æµ‹è¯•

```bash
# å¯åŠ¨åº”ç”¨åï¼Œè®¿é—®å¥åº·æ£€æŸ¥
curl http://localhost:8080/api/ppl/health

# é¢„æœŸå“åº”
{
  "status": "UP",
  "providers": {
    "onnx": {
      "healthy": true,
      "latency": 25
    }
  },
  "currentProvider": "onnx"
}
```

### 2. PPL è®¡ç®—æµ‹è¯•

```bash
# æµ‹è¯•å›°æƒ‘åº¦è®¡ç®—
curl -X POST http://localhost:8080/api/ppl/calculate \
  -H "Content-Type: application/json" \
  -d '{
    "text": "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºå»æ•£æ­¥ã€‚",
    "provider": "onnx"
  }'

# é¢„æœŸå“åº”
{
  "perplexity": 15.234,
  "provider": "onnx",
  "latency": 28
}
```

### 3. æ–‡æ¡£åˆ‡åˆ†æµ‹è¯•

```bash
# æµ‹è¯• PPL Chunking
curl -X POST http://localhost:8080/api/ppl/chunk \
  -H "Content-Type: application/json" \
  -d '{
    "content": "å¾ˆé•¿çš„æ–‡æ¡£å†…å®¹...",
    "provider": "onnx"
  }'
```

---

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜ 1ï¼šæ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°

**ç—‡çŠ¶ï¼š**
```
FileNotFoundException: ./models/qwen2.5-0.5b-instruct/model.onnx
```

**è§£å†³ï¼š**
```bash
# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls ./models/qwen2.5-0.5b-instruct/

# å¦‚æœä¸å­˜åœ¨ï¼Œé‡æ–°ä¸‹è½½
python scripts/download_qwen_models.py --model 0.5b
```

### é—®é¢˜ 2ï¼šæ¨¡å‹åŠ è½½å¤±è´¥

**ç—‡çŠ¶ï¼š**
```
ONNXRuntimeException: Failed to load model
```

**è§£å†³ï¼š**
```bash
# 1. æ£€æŸ¥ ONNX Runtime æ˜¯å¦å®‰è£…
pip list | grep onnxruntime

# 2. é‡æ–°å®‰è£…
pip install onnxruntime

# 3. é‡æ–°ä¸‹è½½æ¨¡å‹
python scripts/download_qwen_models.py --model 0.5b
```

### é—®é¢˜ 3ï¼šå†…å­˜ä¸è¶³

**ç—‡çŠ¶ï¼š**
```
OutOfMemoryError: Java heap space
```

**è§£å†³ï¼š**
```bash
# 1. åˆ‡æ¢åˆ°æ›´å°çš„æ¨¡å‹ï¼ˆ0.5Bï¼‰
# 2. å‡å°‘æ‰¹å¤„ç†å¤§å°
# application.yml:
onnx:
  max-batch-size: 4  # é™ä½åˆ° 4
  
# 3. å¢åŠ  JVM å†…å­˜
export JAVA_OPTS="-Xmx4g"
./mvnw spring-boot:run
```

### é—®é¢˜ 4ï¼šä¸‹è½½é€Ÿåº¦æ…¢

**è§£å†³ï¼š**
```bash
# ä½¿ç”¨å›½å†…é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com
python scripts/download_qwen_models.py --model 0.5b

# æˆ–æ‰‹åŠ¨ä»é­”æ­ç¤¾åŒºä¸‹è½½
# https://modelscope.cn/models/Qwen/Qwen2.5-0.5B-Instruct
```

---

## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
- [Qwen GitHub](https://github.com/QwenLM/Qwen)
- [Qwen æ¨¡å‹åº“](https://huggingface.co/Qwen)
- [é­”æ­ç¤¾åŒº](https://modelscope.cn/organization/Qwen)

### æ¨¡å‹ä¸‹è½½
- **Hugging Face**: `Qwen/Qwen2.5-0.5B-Instruct`
- **é­”æ­ç¤¾åŒº**: `qwen/Qwen2.5-0.5B-Instruct`

### æŠ€æœ¯åšå®¢
- [Qwen2.5 æŠ€æœ¯æŠ¥å‘Š](https://qwenlm.github.io/blog/qwen2.5/)
- [ONNX Runtime æ–‡æ¡£](https://onnxruntime.ai/docs/)

---

## âœ… æ£€æŸ¥æ¸…å•

ä½¿ç”¨å‰è¯·ç¡®è®¤ï¼š

- [ ] Python ç¯å¢ƒå·²å®‰è£…ï¼ˆ3.8+ï¼‰
- [ ] å·²è¿è¡Œ `download_qwen_models.py` è„šæœ¬
- [ ] æ¨¡å‹æ–‡ä»¶å·²ä¸‹è½½åˆ° `./models/` ç›®å½•
- [ ] `application.yml` é…ç½®å·²æ›´æ–°
- [ ] åº”ç”¨å¯ä»¥æ­£å¸¸å¯åŠ¨
- [ ] å¥åº·æ£€æŸ¥æ¥å£è¿”å›æ­£å¸¸
- [ ] PPL è®¡ç®—æµ‹è¯•é€šè¿‡

---

## ğŸ‰ æ€»ç»“

### å·²å®Œæˆçš„å·¥ä½œ

1. âœ… é…ç½®æ–‡ä»¶å·²åˆ‡æ¢åˆ° Qwen æ¨¡å‹
2. âœ… æä¾›äº†è‡ªåŠ¨ä¸‹è½½è„šæœ¬
3. âœ… æ›´æ–°äº†é»˜è®¤é…ç½®
4. âœ… åˆ›å»ºäº†å®Œæ•´çš„ä½¿ç”¨æŒ‡å—

### ä¼˜åŠ¿

- ğŸ‡¨ğŸ‡³ **å›½äº§æ¨¡å‹**ï¼šæ”¯æŒå›½äº§æŠ€æœ¯
- ğŸš€ **æ€§èƒ½ä¼˜ç§€**ï¼šä¸­æ–‡åœºæ™¯è¡¨ç°æ›´å¥½
- ğŸ’° **å®Œå…¨å…è´¹**ï¼šå¼€æºå…è´¹ï¼Œå¯å•†ç”¨
- âš¡ **å¿«é€Ÿè½»é‡**ï¼š0.5B æ¨¡å‹è¶³å¤Ÿå°å·§

### ä¸‹ä¸€æ­¥

ç°åœ¨ä½ å¯ä»¥ï¼š
1. ä¸‹è½½ Qwen æ¨¡å‹
2. å¯åŠ¨åº”ç”¨æµ‹è¯•
3. äº«å—æ›´å¥½çš„ä¸­æ–‡ PPL è®¡ç®—æ•ˆæœï¼

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0  
**æœ€åæ›´æ–°**ï¼š2025-12-04 21:00:00  
**çŠ¶æ€**ï¼šâœ… é…ç½®å·²æ›´æ–°ï¼Œå¯ä»¥ä½¿ç”¨

