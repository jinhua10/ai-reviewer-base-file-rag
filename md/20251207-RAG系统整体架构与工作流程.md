# RAG 智能知识库系统 - 整体架构与工作流程

> 文档版本: v1.0  
> 更新日期: 2025-12-07  
> 作者: AI Reviewer Team

---

## 一、系统架构概览

### 1.1 核心设计理念

本系统采用**可插拔的 AI 引擎架构**，支持在多个关键环节灵活切换不同的 AI 能力提供者：

| 环节 | 可选引擎 | 特点 |
|------|---------|------|
| 文档分块 | ONNX本地模型 / Ollama / 在线LLM | 离线优先，按需升级 |
| 向量嵌入 | BGE-Base-ZH / BGE-M3 / 其他ONNX模型 | 国产模型优先 |
| 文档重排序 | PPL Rerank / 无 | 提升检索精度 |
| 问答生成 | DeepSeek / OpenAI / Qwen / Ollama | 成本与质量平衡 |
| 图片理解 | Qwen-VL / GPT-4o / Ollama Vision | 多模态支持 |

### 1.2 系统架构图

```
+------------------------------------------------------------------+
|                        用户界面 (React)                           |
|  +------------+  +------------+  +------------+  +------------+   |
|  | 智能问答   |  | 文档管理   |  | AI分析     |  | 统计信息   |   |
|  +------------+  +------------+  +------------+  +------------+   |
+------------------------------------------------------------------+
                              |
                              v
+------------------------------------------------------------------+
|                     Spring Boot 后端                              |
|  +------------------+  +------------------+  +------------------+ |
|  | KnowledgeQA      |  | DocumentMgmt    |  | FeedbackSystem   | |
|  | Controller       |  | Controller      |  | Controller       | |
|  +------------------+  +------------------+  +------------------+ |
+------------------------------------------------------------------+
                              |
          +-------------------+-------------------+
          v                   v                   v
+----------------+  +------------------+  +------------------+
| RAG 核心引擎   |  | AI 引擎抽象层    |  | 反馈优化系统     |
| - Lucene索引   |  | - LLMClient      |  | - 权重调整       |
| - 向量索引     |  | - PPLService     |  | - 问答归档       |
| - 混合检索     |  | - VisionLLM      |  | - 相似问题       |
+----------------+  +------------------+  +------------------+
          |                   |
          v                   v
+------------------------------------------------------------------+
|                      存储层                                       |
|  +------------+  +------------+  +------------+  +------------+   |
|  | 文档存储   |  | 向量索引   |  | 反馈记录   |  | 问答归档   |   |
|  | ./data/    |  | ./data/    |  | ./data/    |  | ./data/    |   |
|  | documents  |  | vector-idx |  | feedback   |  | rag        |   |
|  +------------+  +------------+  +------------+  +------------+   |
+------------------------------------------------------------------+
```

---

## 二、文档索引流程

### 2.1 文档入库方式

系统支持两种文档入库方式：

#### 方式一：Web 上传（推荐）

```
用户选择文件 → 上传到服务器 → 保存到 ./data/documents
                                    ↓
                          auto-index-after-upload = true?
                                    ↓
                            是 → 自动触发增量索引
                            否 → 等待手动触发
```

#### 方式二：本地复制

```
用户复制文件到 ./data/documents 目录
                    ↓
        手动点击"增量索引"按钮
                    ↓
              触发索引流程
```

### 2.2 索引处理流程

```
┌─────────────────────────────────────────────────────────────────┐
│                        索引处理流程                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  1. 文件扫描                                                     │
│     FileTrackingService.needsUpdate()                           │
│     ├── 检查文件是否新增                                         │
│     ├── 检查文件是否修改（MD5校验）                              │
│     └── 跳过未变更文件                                           │
│                        ↓                                         │
│  2. 文档解析                                                     │
│     DocumentParser                                               │
│     ├── Excel → ExcelParser                                     │
│     ├── Word → WordParser                                       │
│     ├── PPT → PowerPointParser                                  │
│     ├── PDF → PDFParser                                         │
│     └── 其他 → TextParser                                       │
│                        ↓                                         │
│  3. 图片处理 (可选)                                              │
│     ImageStorageService                                          │
│     ├── strategy: placeholder → 仅保存占位符                    │
│     ├── strategy: vision-llm → 调用 Vision LLM 提取文本         │
│     │   ├── Qwen-VL (默认)                                      │
│     │   ├── GPT-4o                                              │
│     │   └── Ollama Vision (本地)                                │
│     └── strategy: llm-client → 使用主LLM的图片能力              │
│                        ↓                                         │
│  4. 智能分块 ★★★ 可切换引擎 ★★★                                │
│     DocumentPreprocessingService.chunkDocumentWithPPL()          │
│     ├── strategy: ppl (默认，推荐)                              │
│     │   ├── provider: onnx → 本地 ONNX 模型 (免费、快速)        │
│     │   ├── provider: ollama → 本地 Ollama (qwen2.5:0.5b)       │
│     │   └── provider: openai → 在线 API (高精度、收费)          │
│     ├── strategy: llm → 使用大语言模型切分                      │
│     │   └── 调用 LLMClient.generate() 智能识别语义边界          │
│     └── strategy: auto → 自动选择（优先LLM，降级PPL）           │
│                        ↓                                         │
│  5. 建立索引                                                     │
│     LocalFileRAG                                                 │
│     ├── Lucene 全文索引 → 关键词检索                            │
│     └── 向量索引 → 语义检索                                     │
│         └── Embedding 模型 ★★★ 可切换 ★★★                      │
│             ├── bge-base-zh (默认，智源)                        │
│             ├── bge-m3 (最新)                                   │
│             └── text2vec-base-chinese (阿里)                    │
│                        ↓                                         │
│  6. 记录追踪                                                     │
│     FileTrackingService.markAsProcessed()                        │
│     └── 记录文件MD5、处理时间                                   │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 2.3 PPL 智能分块详解

PPL (Perplexity) 分块是本系统的核心创新之一：

```
原理：利用语言模型的困惑度（Perplexity）检测语义边界

输入文档: "第一章 产品介绍...第二章 技术规格...第三章 使用说明..."
                    ↓
1. 分句处理
   ["第一章 产品介绍", "本产品是...", "第二章 技术规格", ...]
                    ↓
2. 计算每句 PPL
   [12.5, 15.2, 45.8, 18.3, ...]  ← 45.8 突变！
                    ↓
3. 检测突变点 (threshold=20.0)
   在 PPL 变化 > 20 的位置切分
                    ↓
4. 输出语义块
   块1: "第一章 产品介绍..."
   块2: "第二章 技术规格..."
   块3: "第三章 使用说明..."
```

**引擎切换能力：**

| 引擎 | 速度 | 精度 | 成本 | 适用场景 |
|------|------|------|------|---------|
| ONNX (qwen2.5-0.5b) | 快 | 中 | 免费 | 日常使用 |
| Ollama (qwen2.5:0.5b) | 快 | 中 | 免费 | 简单部署 |
| OpenAI API | 慢 | 高 | 收费 | 高精度需求 |
| LLM 直接切分 | 慢 | 最高 | 收费 | 重要文档 |

---

## 三、知识库问答流程 (RAG)

### 3.1 完整问答流程

```
┌─────────────────────────────────────────────────────────────────┐
│                     知识库问答流程                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  用户提问: "这个产品的价格是多少？"                              │
│                        ↓                                         │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ Step 0: 相似问题推荐                                      │   │
│  │ SimilarQAService.findSimilar()                            │   │
│  │ ├── 搜索历史高分问答                                      │   │
│  │ ├── 如果找到相似问题 → 直接展示历史答案供参考             │   │
│  │ └── 用户可选择采用历史答案或继续新查询                    │   │
│  └──────────────────────────────────────────────────────────┘   │
│                        ↓                                         │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ Step 1: 混合检索                                          │   │
│  │ HybridSearchService.hybridSearch()                        │   │
│  │                                                            │   │
│  │ 1.1 关键词检索 (Lucene)                                   │   │
│  │     └── lucene-top-k: 100 个候选                          │   │
│  │                                                            │   │
│  │ 1.2 向量检索 ★★★ 可切换嵌入模型 ★★★                      │   │
│  │     ├── 使用 EmbeddingEngine 编码问题                     │   │
│  │     ├── 计算与文档向量的余弦相似度                        │   │
│  │     └── vector-top-k: 50 个候选                           │   │
│  │                                                            │   │
│  │ 1.3 融合去重                                              │   │
│  │     └── hybrid-top-k: 30 个最终候选                       │   │
│  └──────────────────────────────────────────────────────────┘   │
│                        ↓                                         │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ Step 1.5: PPL Rerank (可选) ★★★ 可切换引擎 ★★★           │   │
│  │ PPLServiceFacade.rerank()                                 │   │
│  │ ├── 计算每个文档相对于问题的困惑度                        │   │
│  │ ├── 困惑度越低 → 越相关                                   │   │
│  │ ├── 重新排序，top-k: 8                                    │   │
│  │ └── 引擎: ONNX / Ollama / OpenAI                          │   │
│  └──────────────────────────────────────────────────────────┘   │
│                        ↓                                         │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ Step 2: 智能上下文构建                                    │   │
│  │ SmartContextBuilder.buildSmartContext()                   │   │
│  │                                                            │   │
│  │ 2.1 文档切分策略 ★★★ 可切换 ★★★                          │   │
│  │     ├── SIMPLE: 固定长度切分                              │   │
│  │     ├── SMART_KEYWORD: 关键词优先 (推荐)                  │   │
│  │     └── AI_SEMANTIC: AI语义切分 (高成本)                  │   │
│  │                                                            │   │
│  │ 2.2 长度控制                                              │   │
│  │     ├── max-context-length: 20000 字符                    │   │
│  │     └── max-doc-length: 5000 字符/文档                    │   │
│  │                                                            │   │
│  │ 2.3 相关性保留                                            │   │
│  │     └── 优先保留包含关键词的内容                          │   │
│  └──────────────────────────────────────────────────────────┘   │
│                        ↓                                         │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ Step 3: 图片信息收集                                      │   │
│  │ ImageStorageService.listImages()                          │   │
│  │ └── 收集相关文档的图片URL，附加到上下文                   │   │
│  └──────────────────────────────────────────────────────────┘   │
│                        ↓                                         │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ Step 4: Prompt 构建                                       │   │
│  │ buildEnhancedPrompt()                                     │   │
│  │ ├── 系统提示词                                            │   │
│  │ ├── 用户问题                                              │   │
│  │ ├── 相关文档上下文                                        │   │
│  │ ├── 图片信息（如有）                                      │   │
│  │ └── 文档来源说明                                          │   │
│  └──────────────────────────────────────────────────────────┘   │
│                        ↓                                         │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ Step 5: LLM 生成答案 ★★★ 可切换引擎 ★★★                  │   │
│  │ LLMClient.generate()                                      │   │
│  │ ├── DeepSeek (默认，性价比高)                             │   │
│  │ ├── OpenAI GPT-4o (高质量)                                │   │
│  │ ├── Qwen (国产)                                           │   │
│  │ └── Ollama (本地部署)                                     │   │
│  └──────────────────────────────────────────────────────────┘   │
│                        ↓                                         │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ Step 6: 保存问答记录                                      │   │
│  │ QARecordService.saveRecord()                              │   │
│  │ └── 用于后续反馈和相似问题推荐                            │   │
│  └──────────────────────────────────────────────────────────┘   │
│                        ↓                                         │
│  返回答案 + 引用来源 + 相似问题推荐                              │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 3.2 分批引用机制

当检索到大量相关文档时，系统支持分批引用：

```
检索到 30 个相关文档
        ↓
第一次问答：使用前 5 个文档
        ↓
用户点击"下一批"
        ↓
第二次问答：使用第 6-10 个文档
        ↓
... 循环直到所有文档被引用
```

---

## 四、反馈系统与精度提升

### 4.1 反馈系统架构

```
┌─────────────────────────────────────────────────────────────────┐
│                      反馈系统架构                                │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌────────────────────────────────────────────────────────┐     │
│  │                  用户反馈入口                           │     │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐     │     │
│  │  │ 整体评分    │  │ 文档评分    │  │ 表情评价    │     │     │
│  │  │ 1-5星      │  │ 每个文档    │  │ 😀😊😐😞😢  │     │     │
│  │  └─────────────┘  └─────────────┘  └─────────────┘     │     │
│  └────────────────────────────────────────────────────────┘     │
│                              ↓                                   │
│  ┌────────────────────────────────────────────────────────┐     │
│  │              FeedbackController                         │     │
│  │  ├── /api/feedback/overall/rate    → 整体评分          │     │
│  │  ├── /api/feedback/document/rate   → 文档评分          │     │
│  │  └── /api/feedback/document        → 有帮助/无帮助     │     │
│  └────────────────────────────────────────────────────────┘     │
│                              ↓                                   │
│  ┌────────────────────────────────────────────────────────┐     │
│  │              反馈处理与优化                             │     │
│  │                                                         │     │
│  │  1. 动态权重调整                                        │     │
│  │     FeedbackService.adjustDocumentWeight()              │     │
│  │     ├── 高评分文档 → 权重 +0.1 (最高2.0)               │     │
│  │     └── 低评分文档 → 权重 -0.15 (最低0.1)              │     │
│  │                                                         │     │
│  │  2. 问答归档 (高分答案)                                 │     │
│  │     QAArchiveService                                    │     │
│  │     ├── 评分 >= 4 的问答 → 归档为文档                  │     │
│  │     ├── 保存到 ./data/rag 目录                         │     │
│  │     └── auto-index: true → 自动加入知识库              │     │
│  │                                                         │     │
│  │  3. 相似问题索引                                        │     │
│  │     SimilarQAService                                    │     │
│  │     └── 提取关键词，建立相似度索引                     │     │
│  │                                                         │     │
│  └────────────────────────────────────────────────────────┘     │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 4.2 精度提升机制

#### 机制一：动态文档权重

```
初始状态: 所有文档权重 = 1.0

用户反馈后:
  - 文档A 获得5星 → 权重 1.0 + 0.1 = 1.1
  - 文档B 获得1星 → 权重 1.0 - 0.15 = 0.85

下次检索时:
  - 文档A 的相关性分数 × 1.1 → 排名提升
  - 文档B 的相关性分数 × 0.85 → 排名下降

效果: 好文档自动置顶，差文档自动降权
```

#### 机制二：高分问答归档

```
问答完成 → 用户给5星评价
                ↓
          rating >= 4 ?
                ↓ 是
    创建 Markdown 文档:
    ---
    问题: xxx
    答案: xxx
    引用: xxx
    评分: 5
    ---
                ↓
    保存到 ./data/rag/qa-archive-xxx.md
                ↓
    auto-index: true → 加入知识库索引
                ↓
    下次有人问相似问题 → 可以直接检索到这个高质量答案
```

#### 机制三：相似问题推荐

```
用户提问: "产品怎么安装？"
                ↓
    SimilarQAService.findSimilar()
                ↓
    搜索历史问答，计算相似度:
    - "如何安装产品？" → 相似度 85%
    - "安装步骤是什么？" → 相似度 78%
                ↓
    展示给用户:
    "您可能想问：
     • 如何安装产品？ (85% 相似)
     • 安装步骤是什么？ (78% 相似)"
                ↓
    用户可直接采用历史高分答案，无需重新生成
```

### 4.3 少量交互快速提升精度的设计

| 优化措施 | 减少交互次数 | 原理 |
|---------|------------|------|
| 相似问题推荐 | -2~3次 | 复用历史高分答案 |
| PPL Rerank | -1~2次 | 提升首次检索准确率 |
| 查询扩展 | -1~2次 | 同义词自动补充 |
| 动态权重 | -1次 | 好文档自动置顶 |
| 高分归档 | -2~3次 | 知识自动积累 |

**效果估算：**
- 传统 RAG：平均需要 8-10 次交互达到满意答案
- 优化后：平均需要 3-5 次交互达到满意答案
- 提升：减少约 50% 的交互次数

---

## 五、知识库越用越智能的机制

### 5.1 智能积累闭环

```
┌─────────────────────────────────────────────────────────────────┐
│                   知识库智能积累闭环                             │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│     ┌──────────────┐                                            │
│     │   用户提问   │                                            │
│     └──────┬───────┘                                            │
│            ↓                                                     │
│     ┌──────────────┐     ┌──────────────┐                       │
│     │  RAG 检索    │ ←── │ 相似问题库   │ ←──┐                  │
│     └──────┬───────┘     └──────────────┘    │                  │
│            ↓                                  │                  │
│     ┌──────────────┐                         │                  │
│     │  LLM 生成    │                         │                  │
│     └──────┬───────┘                         │                  │
│            ↓                                  │                  │
│     ┌──────────────┐                         │                  │
│     │  返回答案    │                         │                  │
│     └──────┬───────┘                         │                  │
│            ↓                                  │                  │
│     ┌──────────────┐                         │                  │
│     │  用户反馈    │                         │                  │
│     └──────┬───────┘                         │                  │
│            ↓                                  │                  │
│     ┌──────────────────────────────────┐    │                  │
│     │         反馈处理                  │    │                  │
│     │  ├── 高分(>=4) → 归档到知识库 ───────┘                  │
│     │  ├── 调整文档权重                │                       │
│     │  └── 更新相似问题索引 ───────────────→ 相似问题库        │
│     └──────────────────────────────────┘                       │
│                                                                  │
│  ═══════════════════════════════════════════════════════════    │
│  效果: 使用越多 → 高质量问答越多 → 检索越精准 → 体验越好        │
│  ═══════════════════════════════════════════════════════════    │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 5.2 LLM 结果文档化

每次 AI 分析的结果都会被保存：

```
AI 分析完成
      ↓
LLMResultDocumentService.save()
      ↓
保存为结构化文档:
{
  "id": "llm-result-xxx",
  "type": "document-analysis",
  "question": "总结文档要点",
  "answer": "...",
  "sourceDocuments": ["产品手册.pdf"],
  "rating": null,
  "createdAt": "2025-12-07T10:30:00"
}
      ↓
可选: auto-add-to-knowledge-base: true
      → 自动加入知识库
```

---

## 六、文档 AI 分析功能

### 6.1 单文档分析

```
┌─────────────────────────────────────────────────────────────────┐
│                     单文档 AI 分析                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  用户选择: "产品手册.pdf" + 提示词: "总结核心内容"               │
│                        ↓                                         │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ 模式选择                                                  │   │
│  │ ├── 直接分析模式 (推荐)                                  │   │
│  │ │   └── 直接将文档内容发送给 LLM                         │   │
│  │ │                                                         │   │
│  │ └── 知识库增强模式                                       │   │
│  │     └── 结合知识库中的相关内容一起分析                   │   │
│  └──────────────────────────────────────────────────────────┘   │
│                        ↓                                         │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ 大文档处理                                                │   │
│  │ ├── 文档 <= 20000字 → 直接发送                           │   │
│  │ └── 文档 > 20000字 → 渐进式分析                          │   │
│  │     ├── 分成多个批次                                     │   │
│  │     ├── 每批次提取关键点                                 │   │
│  │     ├── 维护记忆窗口 (memory-window-size: 3)             │   │
│  │     └── 最终合并生成总结                                 │   │
│  └──────────────────────────────────────────────────────────┘   │
│                        ↓                                         │
│  LLM 生成分析结果 ★★★ 可切换引擎 ★★★                           │
│                        ↓                                         │
│  保存结果 + 可选加入知识库                                       │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 6.2 多文档联合分析

```
┌─────────────────────────────────────────────────────────────────┐
│                   多文档联合分析                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  用户选择: ["方案A.docx", "方案B.docx", "方案C.docx"]           │
│  提示词: "对比这三个方案的优缺点"                                │
│                        ↓                                         │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ Step 1: 文档预处理                                        │   │
│  │ ├── 解析每个文档                                         │   │
│  │ ├── 提取关键内容                                         │   │
│  │ └── 处理图片 (Vision LLM)                                │   │
│  └──────────────────────────────────────────────────────────┘   │
│                        ↓                                         │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ Step 2: 内容整合策略                                      │   │
│  │                                                           │   │
│  │ 总内容 <= 上下文限制?                                     │   │
│  │ ├── 是 → 直接拼接所有文档                                │   │
│  │ └── 否 → 智能压缩                                        │   │
│  │     ├── 提取每个文档的核心摘要                           │   │
│  │     └── 保留与问题最相关的部分                           │   │
│  └──────────────────────────────────────────────────────────┘   │
│                        ↓                                         │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ Step 3: 联合分析                                          │   │
│  │                                                           │   │
│  │ Prompt 结构:                                              │   │
│  │ ┌─────────────────────────────────────────────────────┐  │   │
│  │ │ 系统提示: 你是多文档分析专家...                      │  │   │
│  │ │                                                      │  │   │
│  │ │ 文档1 [方案A.docx]:                                  │  │   │
│  │ │ {内容摘要}                                           │  │   │
│  │ │                                                      │  │   │
│  │ │ 文档2 [方案B.docx]:                                  │  │   │
│  │ │ {内容摘要}                                           │  │   │
│  │ │                                                      │  │   │
│  │ │ 文档3 [方案C.docx]:                                  │  │   │
│  │ │ {内容摘要}                                           │  │   │
│  │ │                                                      │  │   │
│  │ │ 用户问题: 对比这三个方案的优缺点                     │  │   │
│  │ └─────────────────────────────────────────────────────┘  │   │
│  └──────────────────────────────────────────────────────────┘   │
│                        ↓                                         │
│  LLM 生成对比分析报告                                            │
│                        ↓                                         │
│  输出: 对比表格 + 优缺点分析 + 建议                              │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### 6.3 PPT 渐进式分析

针对 PPT 这种多页文档的特殊处理：

```
PPT: 50 页演示文稿
        ↓
┌─────────────────────────────────────────────────────────────────┐
│ 渐进式分析流程                                                   │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  批次1: 幻灯片 1-10                                              │
│  ├── 提取图片 → Vision LLM 识别                                 │
│  ├── 提取文本                                                    │
│  ├── LLM 分析 → 生成关键点                                      │
│  └── 保存到记忆窗口                                              │
│                        ↓                                         │
│  批次2: 幻灯片 11-20                                             │
│  ├── 携带批次1的关键点作为上下文                                │
│  ├── LLM 分析 → 生成新的关键点                                  │
│  └── 更新记忆窗口（保留最近3批次）                              │
│                        ↓                                         │
│  ... 继续处理 ...                                                │
│                        ↓                                         │
│  最终整合:                                                       │
│  ├── 汇总所有批次的关键点                                       │
│  ├── LLM 生成综合总结                                           │
│  └── 输出: 总结 + 每页详情                                      │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

---

## 七、思维导图格式

以下内容可直接复制到 XMind、MindMaster 等工具转换为思维导图：

```markdown
# RAG智能知识库系统

## 一、系统架构
### 可插拔AI引擎
- 文档分块: ONNX/Ollama/在线LLM
- 向量嵌入: BGE-Base-ZH/BGE-M3
- 文档重排: PPL Rerank
- 问答生成: DeepSeek/OpenAI/Qwen
- 图片理解: Qwen-VL/GPT-4o

### 存储层
- 文档存储: ./data/documents
- 向量索引: ./data/vector-index
- 反馈记录: ./data/feedback
- 问答归档: ./data/rag

## 二、文档索引流程
### 入库方式
- Web上传(支持自动索引)
- 本地复制+手动索引

### 处理步骤
- 文件扫描(增量检测)
- 文档解析(多格式)
- 图片处理(Vision LLM可选)
- 智能分块(PPL/LLM可切换)
- 建立索引(Lucene+向量)
- 记录追踪

### PPL智能分块
- ONNX本地(快速免费)
- Ollama本地(简单部署)
- 在线API(高精度)
- LLM直接切分(最高精度)

## 三、知识库问答(RAG)
### 问答流程
- Step0: 相似问题推荐
- Step1: 混合检索(Lucene+向量)
- Step1.5: PPL Rerank(可选)
- Step2: 智能上下文构建
- Step3: 图片信息收集
- Step4: Prompt构建
- Step5: LLM生成答案
- Step6: 保存问答记录

### 检索优化
- lucene-top-k: 100
- vector-top-k: 50
- hybrid-top-k: 30
- documents-per-query: 5

## 四、反馈系统
### 反馈类型
- 整体评分(1-5星)
- 文档评分
- 表情评价

### 精度提升机制
- 动态文档权重
- 高分问答归档
- 相似问题推荐

### 效果
- 减少50%交互次数

## 五、知识积累闭环
### 自动积累
- 高分答案→归档→加入知识库
- 权重调整→好文档置顶
- 相似问题索引→复用历史

### LLM结果文档化
- 保存每次分析结果
- 可选加入知识库

## 六、AI分析功能
### 单文档分析
- 直接分析模式
- 知识库增强模式
- 大文档渐进式分析

### 多文档联合分析
- 关联分析
- 对比分析
- 因果分析
- 综合报告

### PPT渐进式分析
- 批次处理
- 记忆窗口
- 最终整合
```

---

## 八、配置快速参考

### 8.1 引擎切换配置

```yaml
# PPL 引擎切换
knowledge.qa.ppl:
  default-provider: onnx  # 可选: onnx, ollama, openai
  
# 分块策略切换
knowledge.qa.ppl.chunking:
  strategy: ppl  # 可选: ppl, llm, auto
  
# 问答切分策略切换
knowledge.qa.llm:
  chunking-strategy: SMART_KEYWORD  # 可选: SIMPLE, SMART_KEYWORD, AI_SEMANTIC

# 向量模型切换
knowledge.qa.vector-search.model:
  name: bge-base-zh  # 可选: bge-base-zh, bge-m3, text2vec-base-chinese

# LLM 引擎切换
knowledge.qa.llm:
  provider: openai
  api-url: https://api.deepseek.com/v1/chat/completions
  model: deepseek-chat

# Vision LLM 切换
knowledge.qa.image-processing:
  strategy: vision-llm
  vision-llm:
    model: qwen-vl-plus  # 可选: qwen-vl-plus, gpt-4o, llava
```

### 8.2 推荐配置组合

| 场景 | PPL | 分块 | LLM | Vision |
|------|-----|------|-----|--------|
| 经济优先 | onnx | ppl | deepseek | qwen-vl |
| 质量优先 | openai | llm | gpt-4o | gpt-4o |
| 离线部署 | ollama | ppl | ollama | ollama |

---

> 文档结束

