# 多文档联合分析策略方案

> 创建日期: 2025-12-06
> 目标: 解决多文档分析中的上下文限制、信息过载、成本控制和关联保持问题

---

## 📋 核心挑战

| # | 挑战 | 描述 | 影响 |
|---|------|------|------|
| 1 | **上下文窗口限制** | 多个文档内容可能超过模型上下文窗口 | 无法一次性处理所有内容 |
| 2 | **信息过载** | 内容过多导致答非所问 | 模型难以聚焦核心问题 |
| 3 | **Token 成本** | 需要节约 token，控制成本 | 大量文档分析成本高昂 |
| 4 | **关联保持** | 需要让模型理解文档间的关系 | 跨文档推理能力下降 |

---

## 🔬 策略对比分析

### 策略一览表

#### 基础策略（已详细分析）

| 策略 | 适用场景 | Token消耗 | 关联保持 | 实现复杂度 | 响应速度 |
|------|----------|-----------|----------|------------|----------|
| 📄 串行摘要法 | 文档数量少(2-3个) | ⭐⭐⭐ 中等 | ⭐⭐⭐ 良好 | ⭐ 简单 | ⭐⭐ 较慢 |
| 🔀 并行摘要法 | 文档数量多(4-10个) | ⭐⭐⭐ 中等 | ⭐⭐ 一般 | ⭐⭐ 中等 | ⭐⭐⭐⭐ 快速 |
| 🧠 渐进式记忆法 | 超长文档 | ⭐⭐ 较低 | ⭐⭐⭐⭐ 优秀 | ⭐⭐⭐ 较复杂 | ⭐⭐ 较慢 |
| 🗺️ 思维导图法 | 复杂关联分析 | ⭐⭐⭐ 中等 | ⭐⭐⭐⭐⭐ 最佳 | ⭐⭐⭐⭐ 复杂 | ⭐⭐ 较慢 |
| 🎯 问题导向检索法 | 精确问答 | ⭐⭐⭐⭐⭐ 最低 | ⭐⭐⭐ 良好 | ⭐⭐ 中等 | ⭐⭐⭐⭐⭐ 最快 |
| 🔗 实体关联法 | 因果分析 | ⭐⭐⭐ 中等 | ⭐⭐⭐⭐ 优秀 | ⭐⭐⭐⭐ 复杂 | ⭐⭐⭐ 中等 |

#### 前沿策略（来自学术研究）

| 策略 | 适用场景 | Token消耗 | 关联保持 | 实现复杂度 | 响应速度 | 论文来源 |
|------|----------|-----------|----------|------------|----------|----------|
| 🌲 层次聚类法 | 大规模文档集(100+) | ⭐⭐⭐⭐ 较低 | ⭐⭐⭐⭐ 优秀 | ⭐⭐⭐ 较复杂 | ⭐⭐⭐ 中等 | HiStruct+ (2023) |
| 🔄 迭代精炼法 | 高质量综合报告 | ⭐⭐ 较高 | ⭐⭐⭐⭐⭐ 最佳 | ⭐⭐⭐ 较复杂 | ⭐ 最慢 | Refine & Iterate (2024) |
| 📐 图神经网络法 | 复杂结构文档 | ⭐⭐⭐ 中等 | ⭐⭐⭐⭐⭐ 最佳 | ⭐⭐⭐⭐⭐ 最复杂 | ⭐⭐⭐ 中等 | GraphRAG (Microsoft) |
| 🎭 多Agent协作法 | 多角度深度分析 | ⭐⭐⭐ 中等 | ⭐⭐⭐⭐ 优秀 | ⭐⭐⭐⭐ 复杂 | ⭐⭐⭐ 中等 | AutoGen/CrewAI |
| 🔮 压缩提示法 | 极限Token节省 | ⭐⭐⭐⭐⭐ 最低 | ⭐⭐⭐ 良好 | ⭐⭐ 中等 | ⭐⭐⭐⭐ 快速 | LLMLingua (2023) |
| 🧬 跨文档注意力法 | 深度关联挖掘 | ⭐⭐⭐ 中等 | ⭐⭐⭐⭐⭐ 最佳 | ⭐⭐⭐⭐⭐ 最复杂 | ⭐⭐ 较慢 | CDT (2023) |
| 🎪 混合检索增强法 | 通用场景 | ⭐⭐⭐⭐ 较低 | ⭐⭐⭐⭐ 优秀 | ⭐⭐⭐ 较复杂 | ⭐⭐⭐⭐ 快速 | HyDE/RAPTOR |
| 🔬 自我一致性法 | 需要验证的分析 | ⭐⭐ 较高 | ⭐⭐⭐⭐ 优秀 | ⭐⭐⭐ 较复杂 | ⭐⭐ 较慢 | Self-Consistency |

---

## 📊 各策略详细分析

### 1. 📄 串行摘要法 (Sequential Summary)

```
文档A → 摘要A → 文档B + 摘要A → 摘要B → 文档C + 摘要B → 最终综合
```

**原理**: 按顺序处理每个文档，每次分析时携带前序文档的摘要作为上下文。

**优点**:
- ✅ 实现简单，逻辑清晰
- ✅ 保持文档间的递进关系
- ✅ 适合有时间线关系的文档

**缺点**:
- ❌ 处理速度慢（必须串行）
- ❌ 顺序依赖可能引入偏见
- ❌ 后面文档受限于前面的摘要质量

**适用场景**: 
- 文档数量少（2-3个）
- 文档间有明确的时间或逻辑顺序
- 需要追溯推理过程

**Token 消耗估算**:
```
3个文档，每个10000字：
- 第1轮: 10000 (原文) + 500 (输出摘要) = 10500
- 第2轮: 10000 (原文) + 500 (前序摘要) + 500 (输出) = 11000
- 第3轮: 10000 (原文) + 1000 (前序摘要) + 500 (输出) = 11500
- 最终综合: 1500 (所有摘要) + 800 (综合报告) = 2300
总计: ~35300 tokens
```

---

### 2. 🔀 并行摘要法 (Parallel Summary)

```
       ┌→ 文档A → 摘要A ─┐
开始 → ├→ 文档B → 摘要B ─┼→ 摘要合并 → 综合分析
       └→ 文档C → 摘要C ─┘
```

**原理**: 并行处理所有文档生成独立摘要，然后合并摘要进行综合分析。

**优点**:
- ✅ 处理速度快（可并行）
- ✅ 各文档独立分析，无顺序偏见
- ✅ 适合大量文档处理

**缺点**:
- ❌ 第一阶段无法感知文档间关联
- ❌ 需要设计良好的摘要合并策略
- ❌ 可能丢失跨文档的细节关联

**适用场景**:
- 文档数量多（4-10个）
- 文档间相对独立
- 对速度要求较高

**Token 消耗估算**:
```
3个文档，每个10000字：
- 并行阶段: 3 × (10000 + 500) = 31500 (可并行，实际时间只算一个)
- 合并阶段: 1500 (所有摘要) + 800 (综合报告) = 2300
总计: ~33800 tokens
时间优势: 串行需3倍时间，并行只需1倍
```

---

### 3. 🧠 渐进式记忆法 (Progressive Memory)

```
┌─────────────────────────────────────────────────────┐
│                    记忆窗口 (最近3轮)                │
│  ┌─────────┐  ┌─────────┐  ┌─────────┐            │
│  │ 关键点1 │  │ 关键点2 │  │ 关键点3 │ ← 滑动窗口 │
│  └─────────┘  └─────────┘  └─────────┘            │
└─────────────────────────────────────────────────────┘
         ↓
    当前处理块 + 记忆上下文 → LLM → 新关键点 → 更新记忆
```

**原理**: 模拟人类阅读记忆，只保留最近N轮的关键信息，实现"选择性遗忘"。

**优点**:
- ✅ 可处理任意长度的内容
- ✅ Token 消耗可控（固定窗口大小）
- ✅ 保持上下文连贯性
- ✅ 自然实现重要信息筛选

**缺点**:
- ❌ 早期信息可能被遗忘
- ❌ 关键点提取质量影响整体效果
- ❌ 需要精心设计记忆管理策略

**适用场景**:
- 超长单文档或文档集合
- 需要追踪主线的分析
- 资源受限环境

**Token 消耗估算**:
```
总内容50000字，分10批处理，记忆窗口保留3轮：
- 每批: 5000 (当前块) + 1500 (3轮记忆) + 500 (输出) = 7000
- 10批总计: 70000 tokens
- 最终总结: 3000 (关键记忆汇总) + 800 = 3800
总计: ~73800 tokens
对比直接处理50000字: 不可能（超出上下文窗口）
```

---

### 4. 🗺️ 思维导图法 (Mind Map)

```
                    ┌─────────────────┐
                    │   核心主题      │
                    └────────┬────────┘
           ┌─────────────────┼─────────────────┐
           ↓                 ↓                 ↓
    ┌──────────┐      ┌──────────┐      ┌──────────┐
    │ 分支A    │      │ 分支B    │      │ 分支C    │
    │(文档1,3) │←────→│(文档2,3) │←────→│(文档1,2) │
    └──────────┘      └──────────┘      └──────────┘
         ↓                 ↓                 ↓
    [子节点...]       [子节点...]       [子节点...]
```

**原理**: 先构建文档的结构化思维导图，识别主题分支，然后基于导图进行跨文档关联分析。

**优点**:
- ✅ 最强的关联保持能力
- ✅ 可视化理解文档结构
- ✅ 支持复杂的多维度分析
- ✅ 便于人工审核和调整

**缺点**:
- ❌ 实现复杂度高
- ❌ 构建导图本身消耗资源
- ❌ 对文档结构依赖较大

**适用场景**:
- 需要深度理解文档关系
- 复杂的多维度分析
- 需要可视化输出的场景

**实现步骤**:
```
1. 结构提取: 每个文档 → 提取标题/章节/关键点 → 局部导图
2. 导图合并: 识别同一主题的节点 → 建立跨文档连接
3. 关联分析: 基于导图结构，分析节点间的关系
4. 综合生成: 沿导图路径生成综合报告
```

---

### 5. 🎯 问题导向检索法 (Question-Driven Retrieval)

```
用户问题
    ↓
┌─────────────┐
│ 问题分析    │ → 提取关键词/意图
└──────┬──────┘
       ↓
┌─────────────┐     ┌─────────────────┐
│ 相关性检索  │ ←── │ 所有文档的块索引 │
└──────┬──────┘     └─────────────────┘
       ↓
只加载 TOP-K 相关块 → LLM → 回答
```

**原理**: 不处理全部内容，而是基于问题检索最相关的文档片段进行分析。

**优点**:
- ✅ Token 消耗最低
- ✅ 响应速度最快
- ✅ 高度聚焦用户问题
- ✅ 与现有 RAG 系统无缝集成

**缺点**:
- ❌ 可能遗漏间接相关的内容
- ❌ 依赖检索质量
- ❌ 难以进行全面的综合分析

**适用场景**:
- 精确问答
- 对速度要求极高
- 有明确问题的场景

**Token 消耗估算**:
```
总内容50000字，检索TOP-5相关块（每块1000字）：
- 检索阶段: 0 (向量计算，不消耗LLM tokens)
- 分析阶段: 5000 (5个块) + 500 (问题) + 800 (回答) = 6300
总计: ~6300 tokens
节省: 相比处理全部内容，节省 90%+ tokens
```

---

### 6. 🔗 实体关联法 (Entity Relation)

```
文档A ──提取──→ 实体集A {人物, 组织, 事件, 概念...}
文档B ──提取──→ 实体集B {人物, 组织, 事件, 概念...}
文档C ──提取──→ 实体集C {人物, 组织, 事件, 概念...}
                          ↓
              实体共现分析 & 关系推理
                          ↓
              ┌──────────────────────┐
              │    实体关系图谱      │
              │  A ─→ B ─→ C        │
              │  ↑    ↓              │
              │  D ←─ E              │
              └──────────────────────┘
                          ↓
              基于图谱的因果/关联分析
```

**原理**: 从各文档提取关键实体，构建跨文档的实体关系图谱，基于图谱进行分析。

**优点**:
- ✅ 精确的实体级关联
- ✅ 支持复杂的因果推理
- ✅ 结构化知识表示
- ✅ 可复用的知识图谱

**缺点**:
- ❌ 实体提取需要专门模型或规则
- ❌ 实现复杂度最高
- ❌ 对非结构化内容效果受限

**适用场景**:
- 因果分析
- 人物/事件关系分析
- 需要精确推理的场景

---

## 🔬 前沿学术策略详解

以下策略来自近年来的学术研究和工业实践，代表了多文档分析领域的最新进展。

### 7. 🌲 层次聚类法 (Hierarchical Clustering)

> **论文来源**: HiStruct+: Hierarchical Structure for Long Document Summarization (ACL 2023)

```
                        ┌───────────────┐
                        │  全局主题层   │ ← 最高抽象
                        └───────┬───────┘
                ┌───────────────┼───────────────┐
                ↓               ↓               ↓
         ┌──────────┐    ┌──────────┐    ┌──────────┐
         │ 主题簇A  │    │ 主题簇B  │    │ 主题簇C  │ ← 聚类层
         └────┬─────┘    └────┬─────┘    └────┬─────┘
              │               │               │
        ┌─────┴─────┐   ┌─────┴─────┐   ┌─────┴─────┐
        │文档1,3,5  │   │文档2,4    │   │文档6,7,8  │ ← 文档层
        └───────────┘   └───────────┘   └───────────┘
```

**原理**: 
1. 对所有文档进行语义聚类，形成主题簇
2. 自底向上构建层次结构
3. 在每一层进行摘要合并
4. 最终在顶层生成综合报告

**优点**:
- ✅ 可处理大规模文档集（100+）
- ✅ 自动发现文档间的主题关系
- ✅ 层次结构便于理解和导航
- ✅ Token 消耗随层次递减

**缺点**:
- ❌ 聚类质量影响最终结果
- ❌ 对稀疏主题可能处理不当
- ❌ 需要预先计算文档相似度

**实现要点**:
```python
# 伪代码
def hierarchical_analysis(documents, question):
    # 1. 计算文档嵌入
    embeddings = embed_documents(documents)
    
    # 2. 层次聚类
    clusters = hierarchical_clustering(embeddings, threshold=0.7)
    
    # 3. 自底向上摘要
    for level in clusters.levels():
        for cluster in level:
            cluster.summary = summarize(cluster.documents, question)
    
    # 4. 顶层综合
    return synthesize(clusters.root, question)
```

---

### 8. 🔄 迭代精炼法 (Iterative Refinement)

> **论文来源**: Self-Refine: Iterative Refinement with Self-Feedback (NeurIPS 2023)

```
初始分析
    ↓
┌─────────────────────────────────────────────┐
│             迭代精炼循环                     │
│  ┌─────────┐    ┌─────────┐    ┌─────────┐ │
│  │ 生成    │ →  │ 评估    │ →  │ 精炼    │ │
│  │ (Draft) │    │(Critique)│   │(Refine) │ │
│  └─────────┘    └─────────┘    └────┬────┘ │
│       ↑                              │      │
│       └──────────────────────────────┘      │
│              直到质量达标                    │
└─────────────────────────────────────────────┘
    ↓
最终输出
```

**原理**:
1. 首先生成初步分析结果
2. 对结果进行自我评估，识别问题
3. 基于评估反馈进行精炼
4. 重复直到达到质量标准或迭代上限

**优点**:
- ✅ 输出质量最高
- ✅ 可自动发现和修复问题
- ✅ 模拟人类的修改过程
- ✅ 适合高质量要求的场景

**缺点**:
- ❌ Token 消耗最高（多轮迭代）
- ❌ 响应时间最长
- ❌ 可能陷入过度优化

**适用场景**:
- 生成正式报告
- 需要高准确性的分析
- 不赶时间的深度分析

---

### 9. 📐 图神经网络法 (Graph Neural Network / GraphRAG)

> **论文来源**: GraphRAG - Microsoft Research (2024)

```
┌─────────────────────────────────────────────────────────────┐
│                    知识图谱构建                              │
│                                                             │
│   文档1 ──→ 实体/关系提取 ──┐                               │
│   文档2 ──→ 实体/关系提取 ──┼──→ 知识图谱                   │
│   文档3 ──→ 实体/关系提取 ──┘      │                        │
│                                    ↓                        │
│                           ┌──────────────────┐             │
│                           │  社区检测        │             │
│                           │  (Leiden算法)   │             │
│                           └────────┬─────────┘             │
│                                    ↓                        │
│                           ┌──────────────────┐             │
│                           │  社区摘要生成    │             │
│                           └────────┬─────────┘             │
│                                    ↓                        │
│                           ┌──────────────────┐             │
│                           │  全局/局部搜索   │             │
│                           └──────────────────┘             │
└─────────────────────────────────────────────────────────────┘
```

**原理**:
1. 从文档中提取实体和关系，构建知识图谱
2. 使用图算法进行社区检测，识别主题群组
3. 为每个社区生成摘要
4. 查询时，根据问题类型选择全局或局部搜索

**优点**:
- ✅ 最强的跨文档关联能力
- ✅ 支持复杂的推理任务
- ✅ 全局视角理解文档集
- ✅ 索引可复用

**缺点**:
- ❌ 实现复杂度最高
- ❌ 需要大量预处理
- ❌ 图谱构建消耗资源

**Microsoft GraphRAG 核心特点**:
- **两级索引**: 社区级 + 实体级
- **两种搜索**: 全局搜索（综合问题）+ 局部搜索（精确问题）
- **Map-Reduce**: 并行处理社区摘要

---

### 10. 🎭 多Agent协作法 (Multi-Agent Collaboration)

> **论文来源**: AutoGen (Microsoft), CrewAI, LangGraph

```
                    ┌─────────────────┐
                    │   协调者Agent   │
                    │  (Coordinator)  │
                    └────────┬────────┘
           ┌─────────────────┼─────────────────┐
           ↓                 ↓                 ↓
    ┌──────────────┐  ┌──────────────┐  ┌──────────────┐
    │  分析师Agent │  │  批评者Agent │  │  综合者Agent │
    │  (Analyst)   │  │  (Critic)    │  │  (Synthesizer)│
    └──────────────┘  └──────────────┘  └──────────────┘
           │                 │                 │
           ↓                 ↓                 ↓
    从不同角度分析     质疑和验证       整合观点
```

**原理**:
1. 设计多个具有不同角色的 Agent
2. 分析师 Agent 从不同角度分析文档
3. 批评者 Agent 质疑和验证分析结果
4. 综合者 Agent 整合多方观点
5. 协调者 Agent 管理流程和冲突

**角色设计示例**:
```
- 📊 数据分析师: 关注数据和数字
- 🔍 细节审查员: 关注具体细节
- 🌐 全局观察者: 关注整体趋势
- ⚖️ 批判者: 质疑和反驳
- 📝 综合者: 整合各方观点
```

**优点**:
- ✅ 多角度深度分析
- ✅ 自动发现问题和矛盾
- ✅ 模拟专家团队讨论
- ✅ 结果更全面可靠

**缺点**:
- ❌ Token 消耗较高
- ❌ 需要精心设计 Agent 角色
- ❌ Agent 间协作复杂

---

### 11. 🔮 压缩提示法 (Prompt Compression)

> **论文来源**: LLMLingua: Compressing Prompts for Accelerated Inference (ACL 2023)

```
原始文档内容 (10000 tokens)
         ↓
┌─────────────────────────────────┐
│       提示压缩器                 │
│   - 移除冗余信息                 │
│   - 保留关键语义                 │
│   - 基于 PPL 的信息量评估        │
└─────────────────────────────────┘
         ↓
压缩后内容 (2000 tokens) → LLM → 回答
         
压缩率: 80%
```

**原理**:
1. 使用小模型计算每个 token 的困惑度 (PPL)
2. PPL 高的 token 包含更多信息
3. 移除 PPL 低的 token（冗余信息）
4. 保持语义完整性的同时大幅压缩

**优点**:
- ✅ Token 节省最多（可达 80%+）
- ✅ 与其他策略可叠加使用
- ✅ 不需要修改模型
- ✅ 响应速度快

**缺点**:
- ❌ 需要额外的小模型计算 PPL
- ❌ 过度压缩可能丢失重要信息
- ❌ 压缩率与质量需要平衡

**与我们系统的结合**:
- 我们的 PPL Chunking 已经实现了类似思想
- 可以进一步增加压缩级别

---

### 12. 🧬 跨文档注意力法 (Cross-Document Attention)

> **论文来源**: CDT - Cross-Document Transformer (EMNLP 2023)

```
           文档A              文档B              文档C
             │                  │                  │
             ↓                  ↓                  ↓
        ┌─────────┐        ┌─────────┐        ┌─────────┐
        │Encoder  │   ←──→ │Encoder  │   ←──→ │Encoder  │
        │   A     │   注意力 │   B     │   注意力│   C     │
        └────┬────┘        └────┬────┘        └────┬────┘
             │                  │                  │
             └──────────────────┼──────────────────┘
                                ↓
                    ┌───────────────────┐
                    │  跨文档注意力层   │
                    │  (识别关联)       │
                    └─────────┬─────────┘
                              ↓
                    ┌───────────────────┐
                    │     Decoder       │
                    │   (生成输出)      │
                    └───────────────────┘
```

**原理**:
1. 使用 Transformer 编码器编码各文档
2. 在编码器之间添加跨文档注意力机制
3. 让模型直接学习文档间的关联
4. 在解码阶段生成综合输出

**优点**:
- ✅ 最深层次的关联理解
- ✅ 端到端学习
- ✅ 可处理复杂的语义关系

**缺点**:
- ❌ 需要专门的模型架构
- ❌ 训练成本高
- ❌ 难以使用现有 API

**实际应用**:
- 更适合作为预训练模型的能力
- API 调用场景可用其他策略模拟

---

### 13. 🎪 混合检索增强法 (Hybrid Retrieval Augmentation)

> **论文来源**: HyDE, RAPTOR (2023-2024)

```
用户问题
    ↓
┌─────────────────────────────────────────────────┐
│              HyDE (假设文档)                     │
│  问题 → LLM → 生成假设答案 → 用假设答案检索      │
└─────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────┐
│              RAPTOR (树状检索)                   │
│                                                 │
│              ┌───────┐                          │
│              │ Root  │ ← 最高层摘要             │
│              └───┬───┘                          │
│           ┌─────┴─────┐                         │
│           ↓           ↓                         │
│       ┌───────┐   ┌───────┐                     │
│       │Level 1│   │Level 1│ ← 中层摘要          │
│       └───┬───┘   └───┬───┘                     │
│     ┌─────┴─────┐   ┌─────┴─────┐               │
│     ↓     ↓     ↓   ↓     ↓     ↓               │
│   [原始文档块] [原始文档块] [原始文档块]         │
└─────────────────────────────────────────────────┘
    ↓
组合检索结果 → LLM → 回答
```

**HyDE 原理**:
1. 先让 LLM 生成问题的假设答案
2. 用假设答案去检索真实文档
3. 假设答案更接近文档语义，检索更准

**RAPTOR 原理**:
1. 构建文档的层次摘要树
2. 检索时从多个层次获取信息
3. 既有细节（叶节点）又有全局视角（高层）

**优点**:
- ✅ 显著提升检索质量
- ✅ 通用性强
- ✅ 与问题导向法完美结合
- ✅ Token 消耗适中

**缺点**:
- ❌ 需要预构建索引
- ❌ HyDE 增加一次 LLM 调用

---

### 14. 🔬 自我一致性法 (Self-Consistency)

> **论文来源**: Self-Consistency Improves Chain of Thought (ICLR 2023)

```
同一问题
    │
    ├──→ 推理路径 1 → 结论 A
    │
    ├──→ 推理路径 2 → 结论 A
    │
    ├──→ 推理路径 3 → 结论 B
    │
    ├──→ 推理路径 4 → 结论 A
    │
    └──→ 推理路径 5 → 结论 C
                    
投票结果: A (3/5) ← 最终答案
```

**原理**:
1. 对同一问题生成多个独立的推理路径
2. 每条路径可能得出不同结论
3. 通过投票或加权选择最一致的结论
4. 提高结果的可靠性

**在多文档分析中的应用**:
```
文档集 + 问题
    │
    ├──→ 策略A分析 → 结论1
    │
    ├──→ 策略B分析 → 结论2
    │
    └──→ 策略C分析 → 结论3
                    
一致性验证 → 最终报告
```

**优点**:
- ✅ 提高结果可靠性
- ✅ 可发现不确定性
- ✅ 适合重要决策场景

**缺点**:
- ❌ Token 消耗翻倍
- ❌ 结论冲突时处理复杂

## 🎨 智能策略混合方案

### 设计理念

将多种策略组合使用，根据**文档特征**和**问题类型**智能选择最优策略组合。

```
┌─────────────────────────────────────────────────────────────────┐
│                    智能策略调度器                                │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  输入分析                                                        │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐             │
│  │ 文档数量    │  │ 总内容长度  │  │ 问题类型    │             │
│  │ ≤3 / >3    │  │ ≤窗口 / >窗口│  │ 分类识别    │             │
│  └──────┬──────┘  └──────┬──────┘  └──────┬──────┘             │
│         │                │                │                     │
│         └────────────────┼────────────────┘                     │
│                          ↓                                      │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │                    决策矩阵                              │   │
│  │                                                         │   │
│  │  内容短 + 文档少 + 关联分析 → 串行摘要法                │   │
│  │  内容短 + 文档多 + 快速总结 → 并行摘要法                │   │
│  │  内容长 + 任意   + 追踪主线 → 渐进式记忆法              │   │
│  │  任意   + 任意   + 复杂关联 → 思维导图法                │   │
│  │  任意   + 任意   + 精确问答 → 问题导向检索法            │   │
│  │  任意   + 任意   + 因果分析 → 实体关联法                │   │
│  │                                                         │   │
│  └─────────────────────────────────────────────────────────┘   │
│                          ↓                                      │
│  策略执行 → 结果评估 → 必要时切换/补充策略                      │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 决策流程图

```
                        开始
                         │
                         ↓
              ┌─────────────────────┐
              │ 分析文档总内容长度  │
              └──────────┬──────────┘
                         │
            ┌────────────┴────────────┐
            ↓                         ↓
    内容 ≤ 上下文窗口70%      内容 > 上下文窗口70%
            │                         │
            ↓                         ↓
    ┌───────────────┐        ┌───────────────┐
    │ 可直接处理    │        │ 需要分块策略  │
    └───────┬───────┘        └───────┬───────┘
            │                         │
            ↓                         ↓
    识别问题类型              识别问题类型
            │                         │
    ┌───────┴───────┐         ┌───────┴───────┐
    ↓               ↓         ↓               ↓
精确问答      全面分析   精确问答        全面分析
    │               │         │               │
    ↓               ↓         ↓               ↓
问题导向    串行/并行    问题导向      渐进式记忆
检索法      摘要法       检索法       + 思维导图
```

### 问题类型识别

| 问题类型 | 关键词特征 | 推荐策略 | 优先级 |
|----------|------------|----------|--------|
| **精确查询** | "哪个"、"什么时候"、"多少" | 问题导向检索 | 最高 |
| **总结概括** | "总结"、"概括"、"概述" | 并行摘要 | 高 |
| **关联分析** | "关联"、"共同点"、"差异" | 思维导图 | 中高 |
| **因果分析** | "为什么"、"因果"、"导致" | 实体关联 | 中高 |
| **对比分析** | "对比"、"比较"、"优劣" | 并行摘要 + 结构化输出 | 中 |
| **综合报告** | "综合"、"全面"、"详细" | 渐进式记忆 + 思维导图 | 低（最全面） |

### 混合策略示例

#### 示例1: 3份合同对比分析

```
问题: "对比这三份合同的付款条款差异"

策略选择:
1. 文档数量: 3个 ✓ 适合串行/并行
2. 内容长度: 假设每份5000字，总计15000字 ✓ 可直接处理
3. 问题类型: 对比分析

执行策略: 并行摘要法 + 结构化输出

流程:
┌─────────────────────────────────────────┐
│ Step 1: 并行提取付款条款               │
│   合同A → 付款条款摘要A                │
│   合同B → 付款条款摘要B (并行)         │
│   合同C → 付款条款摘要C                │
├─────────────────────────────────────────┤
│ Step 2: 结构化对比                      │
│   | 条款    | 合同A | 合同B | 合同C |  │
│   |---------|-------|-------|-------|  │
│   | 付款期限 | 30天  | 45天  | 60天  |  │
│   | 付款方式 | ...   | ...   | ...   |  │
├─────────────────────────────────────────┤
│ Step 3: 差异分析与建议                  │
│   生成差异总结和建议                    │
└─────────────────────────────────────────┘

预估Token: ~8000 (聚焦付款条款，非全文)
```

#### 示例2: 10份研究报告综合分析

```
问题: "综合分析这些报告对AI发展趋势的观点"

策略选择:
1. 文档数量: 10个 ✓ 较多，需并行
2. 内容长度: 假设每份8000字，总计80000字 ✗ 超出窗口
3. 问题类型: 综合分析

执行策略: 并行摘要 + 渐进式记忆 + 思维导图

流程:
┌──────────────────────────────────────────────────┐
│ Phase 1: 并行摘要 (节省时间)                      │
│   10份报告并行 → 10份AI趋势观点摘要 (各500字)    │
├──────────────────────────────────────────────────┤
│ Phase 2: 思维导图构建                            │
│   识别主题分支: 技术趋势/应用场景/挑战/预测      │
│   将10份摘要映射到各分支                         │
├──────────────────────────────────────────────────┤
│ Phase 3: 渐进式综合 (按分支)                     │
│   技术趋势分支 → 综合3-4份相关摘要 → 分支结论   │
│   应用场景分支 → 综合3-4份相关摘要 → 分支结论   │
│   ... (记忆窗口保持分支间连贯)                   │
├──────────────────────────────────────────────────┤
│ Phase 4: 最终报告                                │
│   基于各分支结论 + 思维导图结构 → 综合报告       │
└──────────────────────────────────────────────────┘

预估Token: 
- Phase 1: 10 × 2000 = 20000 (可并行)
- Phase 2: ~3000 (导图构建)
- Phase 3: 4分支 × 3000 = 12000
- Phase 4: ~3000
总计: ~38000 tokens (vs 直接处理80000: 节省50%+)
```

---

## 🔧 实现建议

### 1. 策略调度器接口

```java
public interface MultiDocAnalysisStrategy {
    /**
     * 分析文档
     * @param documents 文档列表
     * @param question 用户问题
     * @param context 上下文（记忆、配置等）
     * @return 分析结果
     */
    AnalysisResult analyze(List<Document> documents, String question, AnalysisContext context);
    
    /**
     * 评估策略适用性
     * @return 适用性评分 0-100
     */
    int evaluateSuitability(List<Document> documents, String question);
    
    /**
     * 预估Token消耗
     */
    TokenEstimate estimateTokens(List<Document> documents);
}
```

### 2. 智能调度器

```java
public class SmartStrategyDispatcher {
    private List<MultiDocAnalysisStrategy> strategies;
    
    public AnalysisResult dispatch(List<Document> documents, String question) {
        // 1. 分析输入特征
        InputFeatures features = analyzeInput(documents, question);
        
        // 2. 评估各策略适用性
        Map<MultiDocAnalysisStrategy, Integer> scores = new HashMap<>();
        for (MultiDocAnalysisStrategy strategy : strategies) {
            scores.put(strategy, strategy.evaluateSuitability(documents, question));
        }
        
        // 3. 选择最优策略（或组合）
        StrategyPlan plan = selectBestPlan(scores, features);
        
        // 4. 执行并返回结果
        return executePlan(plan, documents, question);
    }
}
```

### 3. 配置化策略权重

```yaml
multi-doc-analysis:
  strategies:
    sequential-summary:
      enabled: true
      max-documents: 3
      weight: 0.8
    parallel-summary:
      enabled: true
      min-documents: 2
      weight: 1.0
    progressive-memory:
      enabled: true
      memory-window: 3
      weight: 0.9
    mind-map:
      enabled: true
      complexity-threshold: high
      weight: 0.7
    question-driven:
      enabled: true
      top-k: 5
      weight: 1.2  # 优先使用
    entity-relation:
      enabled: false  # 需要额外NER模型
      weight: 0.6
```

---

## 📈 性能与成本优化建议

### Token 节省技巧

1. **提前过滤**: 根据问题类型，只处理相关章节
2. **分层摘要**: 先生成超短摘要(100字)筛选，再对相关文档生成详细摘要
3. **缓存复用**: 缓存文档摘要，相同文档不重复处理
4. **批量处理**: 相似问题合并处理

### 响应速度优化

1. **并行化**: 独立任务并行执行
2. **流式输出**: 渐进式返回结果
3. **预计算**: 文档上传时预生成摘要和索引

### 质量保证

1. **结果评估**: 自动评估回答与问题的相关性
2. **策略回退**: 当前策略效果不佳时自动切换
3. **人工反馈**: 收集用户反馈优化策略选择

---

## 🎯 推荐实现路线

### Phase 1: 基础功能 (1-2周)
- [x] UI: 多文档选择和联合分析入口
- [ ] 实现并行摘要法（最通用）
- [ ] 实现问题导向检索法（最省Token）

### Phase 2: 智能调度 (2-3周)
- [ ] 实现策略调度器
- [ ] 问题类型识别
- [ ] 文档特征分析

### Phase 3: 高级策略 (3-4周)
- [ ] 实现渐进式记忆法
- [ ] 实现思维导图法
- [ ] 策略混合执行

### Phase 4: 优化迭代 (持续)
- [ ] 性能优化
- [ ] 成本优化
- [ ] 基于反馈的策略调优

---

## 📝 总结

| 目标 | 推荐策略 | 备注 |
|------|----------|------|
| 解决上下文限制 | 渐进式记忆 + 并行摘要 | 分而治之 |
| 避免答非所问 | 问题导向检索 + 思维导图 | 聚焦+结构化 |
| 控制成本 | 问题导向检索 + 分层摘要 | 按需加载 |
| 保持关联 | 思维导图 + 实体关联 | 结构化知识 |

**最终建议**: 实现**智能策略调度器**，根据具体场景自动选择和组合策略，在质量、速度、成本之间取得最优平衡。

