# 从 messages_en.yml（英文）转换的扁平化消息
# 生成以支持 I18n.get(key) 查找
api:
  started: "API 服务器已在端口 {0} 启动"
banner:
  supports: "支持: {0}"
  title: "AI 审阅者 - 知识库智能问答系统"
  version: "版本: {0}"
batch:
  failed: "批量处理失败"
context:
  initialized: "SmartContextBuilder 已初始化：maxContext={0} 字符，maxDoc={1} 字符，preserveFullContent={2}"
document_management:
  api:
    error:
      delete_failed: "删除失败：{0}"
      file_empty: "文件为空"
      index_failed: "索引建立失败：{0}"
      list_failed: "获取列表失败：{0}"
      not_found: "文档不存在"
      upload_failed: "上传失败：{0}"
    success:
      batch_result: "成功：{0}，失败：{1}"
      batch_upload: "批量上传完成"
      delete: "文档删除成功"
      index: "文档索引建立成功"
      list_loaded: "文档列表获取成功：返回 {0} 个文档，总计 {1} 个"
      upload: "文档上传成功"
  log:
    scanned_types: "已扫描文件类型：{0}"
    batch_upload: "批量上传文档: {0}"
    upload_success: "文档上传成功: {0}"
    upload_failed: "文档上传失败"
    file_upload_failed: "文件上传失败: {0}"
    list_documents: "获取文档列表: 页码={0}, 每页数量={1}, 排序字段={2}, 排序方向={3}"
    list_failed: "获取文档列表失败"
    auto_index_trigger: "📦 自动触发增量索引..."
    auto_index_success: "✅ 自动增量索引完成"
    auto_index_failed: "⚠️ 自动增量索引失败: {0}"
    trigger_auto_index_failed: "⚠️ 触发自动索引失败: {0}"
document_service:
  error:
    cannot_create_dir: "创建文档目录失败：{0}"
    filename_empty: "文件名为空"
    file_too_large: "文件过大：{0} MB（最大：{1} MB）"
    illegal_path: "非法文件路径"
    unsupported_format: "不支持的文件格式：{0}"
  log:
    scanned_types: "已扫描文件类型：{0}"
error:
  auth:
    invalid_credentials: "凭据无效"
    permission_denied: "权限拒绝：{0}"
    user_exists: "用户已存在"
  chunk:
    expected_json_array: "期望 JSON 数组，但收到：{0}"
    no_valid_chunks: "AI 响应中未找到有效分片"
    no_valid_json: "响应中未找到有效 JSON"
  docs:
    create_failed: "创建文档失败：{0}"
  file:
    directory_not_exists: "目录不存在：{0}"
    empty: "文件内容为空：{0}"
    index_failed: "文件索引建立失败：{0}"
    not_a_directory: "非目录：{0}"
    not_a_file: "非文件：{0}"
    not_exists: "文件不存在：{0}"
feedback:
  api:
    emoji:
      "1": "😞 完全无用"
      "2": "🙁 帮助不大"
      "3": "😐 一般"
      "4": "😊 非常有帮助"
      "5": "🤩 极其有用"
    error:
      invalid_feedback_type: "feedbackType 必须是 LIKE 或 DISLIKE"
      invalid_rating: "评分必须在 1-5 之间"
      missing_params: "{0} 不能为空"
      processing_failed: "处理失败：{0}"
      record_not_found: "记录不存在"
    impact:
      document:
        "1": "该文档无帮助，系统将大幅降低其推荐权重 ⚠️"
        "2": "该文档帮助有限，系统将降低其推荐权重 📉"
        "3": "该文档表现一般，系统将保持其当前权重 ➡️"
        "4": "该文档非常有帮助，系统将提高其推荐权重 📈"
        "5": "该文档极其有用！系统将优先推荐 🚀"
      overall:
        "1": "很抱歉未能帮到您！我们将重点改进 🙏"
        "2": "感谢您的反馈！我们将分析并优化 🔧"
        "3": "感谢您的评分！我们将持续优化 💡"
        "4": "感谢您的反馈！这将帮助我们提升回答质量 👍"
        "5": "太棒了！该回答将推荐给其他用户 🌟"
    success:
      feedback_received: "感谢您的反馈！"
      thank_you: "感谢您的评分！"
image:
  log:
    get_failed: "获取图片失败：{0}/{1}"
    list_failed: "获取文档图片列表失败：{0}"
  saved: "图片已保存：{0}（文档：{1}）"
  service:
    saved: "图片已保存：{0}"
knowledge_qa_service:
  doc_item: "{0}. {1}"
  error_processing: "处理问答时发生错误: {0}"
  found_chunks_images: "📦 找到 {0} 个分片和 {1} 张图片"
  image_guide_1: "1. 下方提供了相关文档的图片资源，每张图片都有可直接使用的 Markdown 链接（📷 标记）。"
  image_guide_2: "2. 【重要】当你的回答涉及图片中的内容时，请务必在回答中引用该图片，直接复制 📷 后的链接代码。"
  image_guide_3: "3. 引用图片可帮助用户直观理解你的回答，便于用户判断回答质量。"
  image_guide_4: "4. 示例：如果图片展示了架构图，回答中提到架构时应引用：![架构图](/api/images/xxx)"
  doc_images_header: "文档「{0}」的相关图片（共 {1} 张）："
  image_desc_default: "图片{0}"
  images_in_context: "🖼️ 上下文包含 {0} 张图片信息"
  # 新增请求的键
  destroy_start: "正在销毁知识问答服务..."
  kb_closed_safe: "知识库已安全关闭"
  system_closed: "知识问答系统已关闭"
  close_existing_kb: "正在关闭现有知识库..."
  kb_closed: "知识库已关闭"
  rebuild_start: "正在开始知识库重建..."
  log:
    build_complete: "   ✅ 知识库构建完成"
    failed_files: "      - 失败文件：{0}"
    kb_ready: "   ✅ 知识库已就绪"
    processed_files: "      - 已处理文件：{0}"
    total_documents: "      - 文档总数：{0}"
    total_files: "      - 文件总数：{0}"
    chunk_overlap_chars: "分片重叠：{0} 字符"
    chunk_size_chars: "分片大小：{0} 字符"
    chunking_strategy: "分片策略：{0}"
    create_qa_system: "正在创建问答系统..."
    document_count: "文档数：{0}"
    index_count: "索引条目数：{0}"
    init_llm: "正在初始化 LLM 客户端..."
    init_vector_engine: "正在初始化向量引擎：{0}"
    llm_client_ready: "LLM 客户端已就绪"
    llm_client_type: "LLM 客户端类型：{0}"
    llm_provider: "LLM 提供商：{0}"
    max_context_chars: "最大上下文字符数：{0}"
    max_doc_length_chars: "最大文档长度字符数：{0}"
    smart_context_initialized: "智能上下文已初始化：maxContext={0}，maxDoc={1}"
    vector_init_failed_hint: "⚠️ 向量搜索初始化失败，系统将仅使用文本搜索功能"
    vector_init_model_hint: "💡 提示：embedding 模型文件不完整或损坏"
    vector_init_solution: "📝 解决方案："
    vector_init_solution_1: "   1. 在 application.yml 中设置 knowledge.qa.vector-search.enabled: false"
    vector_init_solution_2: "   2. 或下载完整的 ONNX 模型文件（包含 .onnx 和 .onnx_data 文件）"
    llm_call: "🤖 调用 LLM，提示词长度: {0} 字符"
    llm_call_failed: "❌ LLM 调用失败"
    llm_call_error: "LLM 调用失败: {0}"
    direct_qa_mode: "📄 直接问答模式（不使用知识库检索）"
    prompt_length: "提示词长度: {0} 字符"
    direct_qa_complete: "✅ 直接问答完成，耗时: {0}ms"
    direct_qa_failed: "❌ 直接问答失败"
    direct_qa_error: "直接问答处理失败: {0}"
    context_info: "上下文信息："
    using_keyword_mode: "上下文构建使用关键词模式"
    record_saved: "问答记录已保存：{0}"
    using_vector_enhancement: "检索使用向量增强"
    vector_count: "向量索引包含 {0} 个向量"
    vector_dimension: "向量维度：{0}"
    vector_engine_loaded: "向量引擎已加载：{0}"
    vector_index_loaded: "向量索引已加载：{0}"
    vector_index_path: "向量索引路径：{0}"
    vector_model: "向量模型：{0}"
  model_doc_hint: "提示：请将模型文件放置在 {0} 目录"
  model_download_hint: "提示：请从 {0} 下载模型"
  more_images: "  ... 还有 {0} 张图片"
  question_prompt: "❓ 问题：{0}"
  question_separator: "\n================================================================================\n"
  referenced_docs: "\n\n**引用文档**："
  related_image: "相关图片"
  remaining_docs: "ℹ️ 另有 {0} 个相关文档未包含在本次回答中"
  remaining_docs_unprocessed: "ℹ️ 另有 {0} 个相关文档未包含在本次回答中"
  response_time: "\n⏱️  响应时间：{0}ms"
  separator: "================================================================================="
  sources_label: "\n📚 数据来源（共 {0} 个文档）："
  too_many_docs_retrieved: "⚠️ 已获取 {0} 个文档，将处理前 {1} 个（配置项：documents-per-query）"
  using_docs: "📚 使用 {0} 个文档生成此回答"
  using_hybrid_search: "✅ 使用混合搜索（Lucene + 向量）"
  using_strategy_dispatcher: "🎯 使用检索策略调度器"
  answer_label: "\n💡 回答："
  available_images: "可用图片：{0}"
  context_stats: "上下文：来自 {1} 个文档的 {0} 个字符"
  create_session: "正在创建问答会话：{0}"
  image_item: "图片 {0}：{1}（来源：{2}）"
  important_notice: "重要提示：{0}"
  using_keyword_search: "使用关键词搜索模式"
  classpath_prefix: "类路径：{0}"
  closing_existing_kb: "继续操作前正在关闭现有知识库..."
  debug_enhanced_stats: "📊 统计信息：文件系统={0}个文件, 已索引={1}个文档, 未索引={2}个, 完成度={3}%"
  debug_enhanced_stats_v2: "📊 详细统计：文件系统={0}个文件, 唯一文档={1}个, 索引块={2}个, 未索引={3}个, 完成度={4}%"
  existing_kb_closed: "现有知识库已关闭"
  failed_files: "      - 失败文件：{0}"
  incremental_index_start: "正在启动增量索引..."
  more_docs_notice: "\nℹ️ 另有 {0} 个相关文档未包含在本次回答中"
  question_label: "❓ 问题："
  success_files: "      - 成功文件：{0}"
  total_documents: "      - 文档总数：{0}"
  using_session_docs: "使用会话存储的文档：{0}"

# 文件系统存储引擎 (File System Storage Engine)
storage_engine:
  log:
    initialized: "文件系统存储引擎已初始化：{}"
    failed_init_dirs: "初始化目录失败"
    failed_init_storage_dirs: "初始化存储目录失败"
    document_with_same_content: "相同内容的文档已存在：{}"
    document_stored: "文档已存储：{}"
    failed_store: "存储文档失败"
    failed_store_batch: "批量存储文档失败：{}"
    document_file_not_found: "文档文件不存在：{}"
    failed_retrieve: "检索文档失败：{}"
    document_deleted: "文档已删除：{}"
    failed_delete: "删除文档失败：{}"
    document_updated: "文档已更新：{}"
    storage_cleared: "存储已清除"
    clear_storage_failed: "清除存储失败"
  error:
    failed_init_dirs: "初始化目录失败"
    failed_init_storage_dirs: "初始化存储目录失败"
    failed_store_document: "存储文档失败"
    failed_retrieve_document: "检索文档失败：{}"
    failed_delete_document: "删除文档失败：{}"
    clear_storage: "清除存储失败"

# 审计事件 (Audit Event)
audit:
  event:
    title: "审计事件"
    event_id: "事件ID"
    event_type: "事件类型"
    user_id: "用户ID"
    username: "用户名"
    action: "操作"
    resource: "资源"
    details: "详情"
    success: "是否成功"
    timestamp: "时间戳"
    ip_address: "IP地址"

# 审计日志服务 (Audit Log Service)
audit_log:
  log:
    logged: "审计日志已记录：{}"
    write_failed: "审计日志写入失败"
    init_failed: "审计日志初始化失败"
  document_operation: "文档操作"
  search_operation: "搜索操作"
  auth_event: "认证事件"

# 文档切分器 (Document Chunker)
document_chunker:
  interface:
    title: "文档切分器接口"
    chunk_method: "切分文档"
    chunk_method_desc: "将文档内容切分为多个文档块"
    chunk_method_no_query: "切分文档（无查询上下文）"
    chunk_method_no_query_desc: "不带查询上下文切分文档"
    get_name: "获取切分器名称"
    get_description: "获取切分器描述"
  param:
    content: "文档内容"
    query: "用户查询（可选，用于智能切分）"
    return: "文档块列表"

# 文档块 (Document Chunk)
document_chunk:
  class:
    title: "文档块"
    description: "表示切分后的文档片段"
  field:
    content: "块内容"
    title: "块标题（可选）"
    index: "块索引（从0开始）"
    total_chunks: "总块数"
    start_position: "起始位置（在原文档中的字符偏移）"
    end_position: "结束位置（在原文档中的字符偏移）"

# 缓存引擎 (Cache Engine)
cache_engine:
  interface:
    title: "缓存引擎接口"
    description: "提供多级缓存支持"
  method:
    get_document: "获取缓存的文档"
    put_document: "缓存文档"
    get_query_result: "获取缓存的查询结果"
    put_query_result: "缓存查询结果"
    invalidate_document: "使文档缓存失效"
  param:
    doc_id: "文档ID"
    query_key: "查询键"
    result: "查询结果"
    document: "文档对象"

# 索引引擎 (Index Engine)
index_engine:
  interface:
    title: "索引引擎接口"
    description: "负责文档的索引构建和搜索"
  method:
    index_document: "索引文档"
    index_batch: "批量索引文档"
    update_index: "更新索引"
    delete_from_index: "从索引中删除文档"
    search: "搜索文档"
  param:
    documents: "文档列表"
    new_document: "新的文档对象"
    query: "查询对象"
    return: "搜索结果"

# SQLite元数据管理器 (SQLite Metadata Manager)
sqlite_metadata_manager:
  class:
    title: "SQLite元数据管理器"
    description: "使用SQLite数据库存储文档元数据"
  log:
    initialized: "SQLite元数据管理器已初始化：{}"
    failed_init: "初始化SQLite数据库失败"
    failed_execute_update: "执行更新失败：{}"
    document_saved: "文档元数据已保存：{}"
    failed_save: "保存文档元数据失败：{}"
    document_found: "文档元数据已找到：{}"
    failed_find: "查找文档元数据失败：{}"
    document_updated: "文档元数据已更新：{}"
    failed_update: "更新文档元数据失败：{}"
    document_deleted: "文档元数据已删除：{}"
    failed_delete: "删除文档元数据失败：{}"
    cleared: "元数据表已清空"
    failed_clear: "清空元数据表失败"
    failed_exists: "检查文档存在性失败"
    failed_count: "获取文档计数失败"
    failed_get_all_ids: "获取所有文档ID失败"
    failed_find_by_hash: "按哈希查找文档失败"
    failed_close: "关闭数据库连接失败"
    retrieved_ids: "已检索 {} 个文档ID"
    connection_closed: "SQLite连接已关闭"
    connection_close_failed: "关闭SQLite连接失败"
    all_cleared: "所有文档元数据已清空"
    clear_failed: "清空文档元数据失败"

# SHA-256文档哈希器 (SHA-256 Document Hasher)
sha256_document_hasher:
  class:
    title: "SHA-256文档哈希器"
    description: "用于计算文档内容的哈希值，实现去重功能"
  method:
    compute_hash: "计算内容哈希"
    compute_hash_string: "计算字符串内容哈希"
  param:
    content_bytes: "内容字节数组"
    content_string: "内容字符串"
    return: "Base64编码的哈希值"
  log:
    failed_compute: "计算哈希失败：算法未找到"
  error:
    failed_compute: "计算哈希失败"
    connection_closed: "数据库连接已关闭"

# 应用程序 (Application)
app:
  log:
    started: "✅ 应用启动成功，地址：{0}"
    start_failed: "❌ 应用启动失败"
    startup_failed: "应用启动失败"

# 文档问答服务 (Document QA Service)
doc_qa:
  log:
    create_temp_dir: "创建文档问答临时目录: {0}"
    create_temp_dir_failed: "创建临时目录失败"
    start_qa: "📄 开始文档问答: {0} (会话ID: {1})"
    question: "❓ 问题: {0}"
    batch_mode: "📦 文档较大，启用分批处理模式"
    direct_mode: "📝 文档较小，直接处理"
    qa_complete: "✅ 文档问答完成: {0} (耗时: {1}ms)"
    qa_error: "❌ 文档问答失败"
    direct_start: "📄 开始直接文档分析（不使用知识库）: 文档={0}, 会话ID={1}"
    direct_question: "❓ 分析问题: {0}"
    direct_content_length: "📏 文档内容长度: {0} 字符"
    direct_exceed_limit: "📦 文档内容超过限制（{0}），使用备忘录机制分批处理"
    direct_full_analysis: "📝 直接完整分析文档"
    direct_split_batches: "📦 文档分割为 {0} 个批次进行分析"
    direct_process_batch: "🔄 处理第 {0}/{1} 批次，内容长度: {2} 字符"
    direct_complete: "✅ 直接文档分析完成: 文档={0}, 耗时={1}ms"
    direct_failed: "❌ 直接文档分析失败"
    split_batches: "📦 文档已分割为 {0} 个批次"
    process_batch: "🔄 处理批次 {0}/{1} (大小: {2} 字符)"
    batch_key_points: "💡 批次 {0} 关键信息已提取 ({1}字符)"
    batch_complete: "✅ 批次 {0}/{1} 处理完成"
    analysis_failed: "分析失败"
    final_report_failed: "生成最终报告失败"
    direct_process_failed: "直接处理文档失败"
  error:
    document_not_found: "文档不存在: {0}"
    processing_failed: "文档处理失败"
  prompt:
    analysis_task: "# 文档分析任务\n\n"
    document_info: "## 文档信息\n"
    filename: "- 文件名: {0}\n"
    content_length: "- 内容长度: {0} 字符\n\n"
    user_question: "## 用户问题\n"
    full_content: "## 完整文档内容\n"
    analysis_requirements: "\n\n## 分析要求\n"
    req_read_content: "1. 仔细阅读以上完整文档内容\n"
    req_answer_question: "2. 直接针对文档内容回答用户问题\n"
    req_structured_answer: "3. 提供结构化、有条理的回答\n"
    req_quote_data: "4. 如有关键数据，请准确引用\n"
    req_organize_content: "5. 使用标题、列表等组织内容\n"

# PPT分析服务 (PPT Analysis Service)
ppt_analysis:
  log:
    start_analysis: "📊 开始渐进式分析PPT: {0} ({1} 张幻灯片)"
    analyze_slide: "🔍 分析幻灯片 {0}/{1}"
    slide_complete: "✅ 幻灯片 {0} 分析完成，关键点: {1}"
    analysis_complete: "🎉 PPT渐进式分析完成，耗时: {0}ms"
    analysis_failed: "PPT分析失败"
    slide_failed: "幻灯片 {0} 分析失败"
    generate_summary: "📊 生成PPT综合总结..."
    summary_complete: "✅ 综合总结生成完成"
    summary_failed: "生成综合总结失败"

# 知识库服务 (Knowledge Base Service)
kb_service:
  log:
    vector_disabled: "向量检索已启用。"
    progress: "处理进度："
    path_not_exists: "路径不存在：{0}"
    scan_classpath: "扫描 classpath 资源：{0}"
    classpath_not_exists: "classpath 资源不存在：{0}"
    resource_found: "找到资源：{0}"
    resource_file_not_exists: "资源文件不存在：{0}"
    resource_path: "资源路径：{0}"
    scan_directory: "扫描目录中的文件。"
    files_found: "共找到 {0} 个文件。"
    add_file: "添加文件：{0}"
    scan_classpath_failed: "扫描 classpath 资源失败：{0}"
    file_not_exists: "文件不存在：{0}"
    index_single_file: "开始索引单个文件：{0}"
    file_indexed: "文件已成功索引：{0}"
    index_file_failed: "索引文件失败：{0}"
    file_too_large: "文件过大，大小：{0} MB，最大允许大小：{1} MB"
    content_empty: "文档内容为空。"
    image_extraction_failed: "图片提取失败：{0}"
    force_chunk: "文档内容过大，强制分块，大小：{0} MB"
    auto_chunk: "文档内容较大，自动分块，大小：{0} KB"
    chunked: "文档已分块，分块数量：{0}"
    processing_failed: "文档处理失败。"
    file_process_failed: "处理文件失败：{0}"
    batch_task_failed: "批量任务执行失败。"
    vector_generation_failed: "向量生成失败：{0}"
    incremental_start: "开始增量索引。"
    incremental_complete: "增量索引完成。"
    incremental_files: "增量索引文件数量：{0}"
    build_complete: "知识库构建完成"
    build_failed: "知识库构建失败"
    build_memory: "知识库构建内存使用"
    build_separator: "----------------------------------------"
    build_success: "知识库构建成功"
    build_time: "知识库构建耗时：{0} ms"
    build_total: "处理总条目数：{0}"
    memory_after: "构建后内存使用：{0} MB"
    memory_before: "构建前内存使用：{0} MB"
    old_kb_cleared: "旧知识库已清除"
    rebuild_prepare: "正在准备知识库重建..."
    tracking_cleared: "知识库跟踪信息已清除"
    tracking_saved: "知识库跟踪信息已保存：{0}"
    batch_processing: "📦 批量处理：{0} 个文档（{1} / {2}）"
    batch_commit: "📝 提交批量索引"
    content_extracted: "✅ 内容提取完成：{0}"
    content_too_large: "⚠️  内容过大（{0} 字符）"
    content_truncated: "✂️  内容已截断至 {0} 字符"
    exists: "📚 检测到已存在知识库（{0} 个文档）"
    files_to_index: "📝 待索引文件数：{0}"
    final_batch: "📦 处理最后一批：{0} 个文档"
    first_create: "📚 首次创建知识库"
    found_files: "✅ 找到 {0} 个文档文件"
    gc_before: "🗑️  执行垃圾回收释放内存"
    hint_put_docs: "💡 提示：请将文档放置在 {0} 目录"
    images_added: "➕ {0} 张图片已添加至索引"
    images_extracted: "🖼️  已提取 {0} 张图片"
    incremental_done: "\n✅ 增量索引完成！"
    incremental_failed: "❌ 增量索引失败"
    incremental_stats: "   - 已处理文件：{0}/{1}，失败：{2}，文档总数：{3}，耗时：{4}秒"
    indexation_complete: "✅ 索引建立完成：{0}"
    indexing_complete: "✅ 知识库索引建立完成：{0}"
    no_documents: "⚠️  未找到支持的文档文件"
    parallel_mode: "🚀 使用并行处理模式（{0} 个线程）"
    parallel_progress: "📊 并行进度：{0}%"
    parallel_memory: "💾 内存使用：{0} MB"
    processing_file: "📄 正在处理文件：{0}，大小：{0} KB"
    processing_start: "\n📝 开始文档处理..."
    scanning: "📂 正在扫描文档：{0}"
    serial_mode: "📝 使用串行处理模式"
    source_path: "   - 文档路径：{0}"
    supported_formats: "      支持格式：{0}"
    up_to_date: "✅ 所有文件均为最新，无需更新"
    vector_init_failed: "❌ 向量搜索引擎初始化失败"
    files_to_update: "📝 需要更新的文件数：{0}"
    saved_chunks: "✅ 已为文档 {1} 保存 {0} 个 chunks"
    save_chunks_failed: "⚠️ 保存 chunks 失败（文档：{0}）：{1}"
    preprocess_start: "🔄 开始文档预处理（图片提取 + 文本转换）..."
    preprocess_complete: "✅ 文档预处理完成，最终内容长度：{0}"
    preprocess_failed: "⚠️ 文档预处理失败：{0}"
    ppl_chunking_start: "🧠 使用 PPL 智能分块..."
    ppl_chunking_complete: "✅ PPL 分块完成：{0} 个分块"
    ppl_chunking_failed: "⚠️ PPL 分块失败，回退到传统分块：{0}"
    file_item: "   - {0}"

# 知识问答服务日志 (Knowledge QA Service Logs)
log:
  kqa:
    sep: "================================================================================="
    init_start: "🚀 正在初始化知识问答服务"
    init_done: "✅ 知识库问答系统初始化成功！"
    init_failed: "❌ 知识问答服务初始化失败"
    step: "\n🚀 步骤 {0}：{1}"
    init_kb: "正在初始化知识库"
    rebuild_mode: "   🚀 开始知识库全量重建..."
    incremental_mode: "   🔄 开始知识库增量索引..."
    storage_path: "   - 存储路径：{0}"
    source_path: "   - 源路径：{0}"
    build_failed: "知识库构建失败：{0}"
  kb:
    vector_init_failed: "向量搜索初始化失败"
    scanned_files_count: "📂 文件系统扫描完成，找到 {0} 个支持的文档"
    scan_failed: "❌ 文件系统扫描失败"

# 文档问答服务提示词 (Document QA Service Prompts)
doc_qa:
  log:
    create_temp_dir: "创建文档问答临时目录: {0}"
    create_temp_dir_failed: "创建临时目录失败"
    start_qa: "📄 开始文档问答: {0} (会话ID: {1})"
    question: "❓ 问题: {0}"
    batch_mode: "📦 文档较大，启用分批处理模式"
    direct_mode: "📝 文档较小，直接处理"
    qa_complete: "✅ 文档问答完成: {0} (耗时: {1}ms)"
    qa_error: "❌ 文档问答失败"
    direct_start: "📄 开始直接文档分析（不使用知识库）: 文档={0}, 会话ID={1}"
    direct_question: "❓ 分析问题: {0}"
    direct_content_length: "📏 文档内容长度: {0} 字符"
    direct_exceed_limit: "📦 文档内容超过限制（{0}），使用备忘录机制分批处理"
    direct_full_analysis: "📝 直接完整分析文档"
    direct_split_batches: "📦 文档分割为 {0} 个批次进行分析"
    direct_process_batch: "🔄 处理第 {0}/{1} 批次，内容长度: {2} 字符"
    direct_complete: "✅ 直接文档分析完成: 文档={0}, 耗时={1}ms"
    direct_failed: "❌ 直接文档分析失败"
    split_batches: "📦 文档已分割为 {0} 个批次"
    process_batch: "🔄 处理批次 {0}/{1} (大小: {2} 字符)"
    batch_key_points: "💡 批次 {0} 关键信息已提取 ({1}字符)"
    batch_complete: "✅ 批次 {0}/{1} 处理完成"
    analysis_failed: "分析失败"
    final_report_failed: "生成最终报告失败"
    direct_process_failed: "直接处理文档失败"
  error:
    document_not_found: "文档不存在: {0}"
    processing_failed: "文档处理失败"
  prompt:
    analysis_task: "# 文档分析任务\\n\\n"
    document_info: "## 文档信息\\n"
    filename: "- 文件名: {0}\\n"
    content_length: "- 内容长度: {0} 字符\\n\\n"
    user_question: "## 用户问题\\n"
    full_content: "## 完整文档内容\\n"
    analysis_requirements: "\\n\\n## 分析要求\\n"
    req_read_content: "1. 仔细阅读以上完整文档内容\\n"
    req_answer_question: "2. 直接针对文档内容回答用户问题\\n"
    req_structured_answer: "3. 提供结构化、有条理的回答\\n"
    req_quote_data: "4. 如有关键数据，请准确引用\\n"
    req_organize_content: "5. 使用标题、列表等组织内容\\n"
    batch_analysis_task: "# 文档分批分析任务\\n\\n"
    background_info: "## 背景信息\\n"
    current_batch: "## 当前批次内容\\n"
    analysis_req: "## 分析要求\\n"
    req_analyze_current: "1. 仔细分析当前批次的内容\\n"
    req_combine_memory: "2. 结合之前的关键要点理解整体脉络\\n"
    req_extract_key: "3. 提取本批次最重要的 3-5 个关键信息\\n"
    req_focus_question: "4. 重点关注与用户问题相关的内容\\n"
    req_keep_open: "5. 这不是最后一部分，保持开放性\\n"
    req_final_summary: "5. 这是最后一部分，可以做出完整总结\\n"
    output_format: "\\n请按以下格式输出：\\n"
    output_format_analysis: "### 本批次分析\\n[你的分析]\\n\\n"
    output_format_key: "### 关键要点\\n[用 - 列出 3-5 个关键点]\\n\\n"
    previous_memory: "## 之前内容的关键要点（记忆上下文）\\n"
    final_summary_task: "# 文档分析最终总结任务\\n\\n"
    background_summary: "## 背景\\n"
    background_description: "你已经分批分析完一份文档的所有内容，现在需要生成最终综合报告。\\n\\n"
    doc_info: "## 文档信息\\n"
    analysis_batches: "- 分析批次数: {0}\\n\\n"
    key_points_summary: "## 各批次关键要点汇总\\n"
    current_part: "### 第 {0} 部分\\n"
    final_requirements: "## 生成要求\\n"
    req_overall_understand: "1. **整体把握**: 综合所有批次的关键信息\\n"
    req_answer_question_directly: "2. **回答问题**: 直接、清晰地回答用户的问题\\n"
    req_structure_clear: "3. **结构清晰**: 使用标题、列表等组织内容\\n"
    req_extract_core: "4. **要点提炼**: 突出最核心的 3-5 个观点\\n"
    req_coherent_expression: "5. **连贯表达**: 确保内容前后连贯，逻辑通顺\\n"
    generate_final_report: "请生成最终综合分析报告：\\n"

# 查询扩展服务 (Query Expansion Service)
query_expansion:
  init: "📊 查询扩展服务初始化: 同义词词典{}个词条, 停用词{}个"
  reverse_index: "🔄 构建同义词反向索引完成: {} 个词条"
  log:
    init: "查询扩展服务初始化: 同义词词典{}个词条, 停用词{}个"
    reverse_index: "构建同义词反向索引完成: {} 个词条"
    expand_query: "扩展查询: {}"
    add_synonyms: "添加同义词: {}"
    llm_rewrite_success: "LLM改写成功: {}"
    llm_rewrite_failed: "LLM改写失败: {}"
    synonym_replace: "同义词替换: {} -> {}"
    filter_stopwords: "过滤停用词: {}"
    add_phrases: "添加短语: {}"
    expansion_complete: "查询扩展完成: {} -> {}"

# 主动学习服务 (Active Learning Service)
active_learning:
  log:
    init: "主动学习服务初始化"
    recommendation_generated: "生成主动学习推荐: 不确定文档={}, 潜在相关={}, 历史推荐={}"
    uncertain_docs_found: "发现不确定文档: {} 个"
    potential_docs_found: "发现潜在相关文档: {} 个"
    history_recommendations: "基于历史的推荐: {} 个"
    confidence_calculated: "推荐置信度: {}"
    reason_generated: "生成推荐理由: {}"
    save_history: "保存查询历史: {}"
    cache_updated: "更新查询缓存: {}"

# 日志相关 (Log Related)
log:
  image:
    service:
      init: "图片提取服务初始化: 提取器数量={}, AI分析启用={}"
      extract_failed: "提取图片失败: {}"
      start: "开始提取图片: {}"
      no_extractor: "未找到支持该文档类型的提取器: {}"
      using_extractor: "使用提取器: {}"
      no_images: "文档中未找到图片: {}"
      extracted: "已提取图片数量: {}"
      saved: "已保存图片: {} (类型: {}, 大小: {}KB)"
      save_failed: "保存图片失败: {}"
      success: "图片提取完成: 共{}张图片 (文档: {})"
      failed: "图片提取失败: {}"
  query_expansion:
    init: "查询扩展服务初始化: 同义词词典{}个词条, 停用词{}个"
    reverse_index: "构建同义词反向索引完成: {} 个词条"
    expand_query: "扩展查询: {}"
    add_synonyms: "添加同义词: {}"
    llm_rewrite_success: "LLM改写成功: {}"
    llm_rewrite_failed: "LLM改写失败: {}"
    synonym_replace: "同义词替换: {} -> {}"
    filter_stopwords: "过滤停用词: {}"
    add_phrases: "添加短语: {}"
    expansion_complete: "查询扩展完成: {} -> {}"
  feedback:
    weight_disabled: "动态权重调整已禁用"
    weight_updated: "文档权重更新: {} 权重={} (点赞:{}, 踩:{})"
  qa:
    record_saved: "问答记录已保存: {} (文件: {})"
    save_failed: "保存问答记录失败"

# 主动学习服务反馈 (Active Learning Service Feedback)
active_learning:
  feedback:
    relevant: "相关"
    irrelevant: "不相关"
    processed: "🎯 主动学习反馈: {} -> {} ({})"
  log:
    potential_doc_reason: "该文档历史上获得过高评分，但未出现在当前检索结果中"