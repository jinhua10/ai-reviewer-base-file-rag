error:
  chunk:
    chunk_size_positive: "chunk-size must be positive"
    expected_json_array: "Expected JSON array, got: {0}"
    no_valid_chunks: "No valid chunks found in AI response"
    no_valid_json: "No valid JSON found in response"
    overlap_less_than_size: "chunk-overlap must be less than chunk-size"
    overlap_non_negative: "chunk-overlap must be non-negative"
  invalid_admin_endpoint: "Invalid admin endpoint"
  invalid_document_endpoint: "Invalid document endpoint"
  invalid_search_endpoint: "Invalid search endpoint"
  unknown_endpoint: "Unknown endpoint: {0}"
log:
  admin:
    cache_cleared: "Cache cleared"
    cache_cleared_success: "Cache cleared successfully"
    clear_cache_failed: "Failed to clear cache"
    clear_cache_failed_detail: "Failed to clear cache: {0}"
    index_optimize_failed: "Failed to optimize index"
    index_optimize_failed_detail: "Failed to optimize index: {0}"
    index_optimized: "Index optimized"
    index_optimized_success: "Index optimized successfully"
    stats_failed: "Failed to get statistics"
    stats_failed_detail: "Failed to get statistics: {0}"
  api:
    started: "API Server started on port {0}"
    stopped: "API Server stopped"
  audit:
    init_failed: "Failed to initialize audit log"
    logged: "Audit logged: {0}"
    write_failed: "Failed to write audit log"
  auth:
    logged_in: "User logged in: {0}"
    logged_out: "User logged out: {0}"
    registered: "User registered: {0}"
  batch:
    failed: "Batch processing failed"
  channel:
    exception: "Exception in channel"
  chunk:
    ai_completed: "AI semantic chunking completed: {0} chars -> {1} chunks in {2}ms"
    ai_failed: "AI semantic chunking failed, falling back to smart keyword chunking"
    ai_not_enabled: "AI chunking is not enabled in config"
    ai_parse_failed: "Failed to parse AI chunking response: {0}"
    ai_start: "Starting AI semantic chunking for {0} chars"
    content_truncate: "Content too large ({0} chars), truncating to {1} chars"
    coverage_low: "Coverage too low, adding sequential chunks"
    display_part: "Part {0}/{1}"
    keywords_extracted: "Extracted {0} keywords from query: {1}"
    max_chunks_reached: "Reached maximum chunk limit ({0}), stopping chunking"
    no_keywords_fallback: "No keywords found, falling back to simple chunking"
    simple_summary: "Simple chunking: {0} chars -> {1} chunks (size={2}, overlap={3})"
    smart_summary: "Smart keyword chunking: {0} chars -> {1} chunks with {2} keywords"
    truncate_warning: "Content too long ({0} chars), truncating to {1} chars for AI chunking"
  chunker:
    ai_disabled: "AI chunking is not enabled, falling back to SMART_KEYWORD strategy"
    creating: "Creating document chunker: strategy={0}, chunkSize={1}, overlap={2}"
    llm_null: "LLM client is null, falling back to SMART_KEYWORD strategy"
    unknown_strategy: "Unknown chunking strategy: {0}, using SMART_KEYWORD"
  default:
    missingKey: "Missing log key: {0}"
  docs:
    classpath_in_jar: "Classpath path is inside a JAR, write is not supported"
    classpath_load_failed: "Failed to load resource from classpath: {0} - {1}"
    classpath_not_exists: "Classpath resource not found: {0}"
    classpath_realpath: "Using classpath real path: {0}"
    classpath_resource_found: "Found resource in classpath: {0}"
    create:
      failed: "Failed to create document: {0}"
      success: Document created successfully
    create_failed: "Failed to create documents directory: {0}"
    created: "Document created: {0}"
    delete:
      failed: "Failed to delete document: {0}"
      success: Document deleted successfully
    deleted: "Document deleted: {0}"
    directory_ready: "Documents directory ready: {0}"
    file_exists_renamed: "File exists, renamed to: {0}"
    get:
      failed: "Failed to get document: {0}"
    invalid_directory: "Invalid directory: {0}"
    list:
      exception: "Exception while listing documents: {0}"
      failed: "Failed to list documents: {0}"
    not_found: "Document not found: {0}"
    notfound: "Document not found: {0}"
    process_failed: "Failed to process file: {0}"
    saved: "Document saved: {0}"
    scanned_types: "Scanned file types: {0}"
    total: "Total documents: {0}"
    update:
      failed: "Failed to update document: {0}"
      success: Document updated successfully
    updated: "Document updated: {0}"
    upload_to_external: "Uploads will be saved to external path: ./data/documents"
    using_default_path: "Using default path: ./data/documents"
    using_filesystem: "Using filesystem path: {0}"
    walk_failed: "Failed to walk directory: {0}"
  factory:
    create_caffeine: "Creating CaffeineCacheEngine"
    create_filesystem: "Creating FileSystemStorageEngine"
    create_lucene: "Creating LuceneIndexEngine"
  feedback:
    document_failed: "Failed to process document feedback"
    document_received: "Received document feedback {0}: recordId={1}, document={2}"
    get_pending_failed: "Failed to get pending QA records"
    get_recent_failed: "Failed to get recent QA records"
    get_record_failed: "Failed to get QA record"
    get_statistics_failed: "Failed to get QA statistics"
    overall_failed: "Failed to process overall feedback"
    overall_received: "Received overall feedback: recordId={0}, rating={1}"
    rating_failed: "Failed to process rating"
    rating_submitted: "Rating submitted {0} [{1}]: {2} - {3} stars (impact: {4})"
  filetracking:
    check_failed: "Failed to check file status: {0}"
    clear_failed: "Failed to clear file tracking info: {0}"
    cleared: "Cleared file tracking information"
    load_failed: "Failed to load file tracking info: {0}"
    loaded: "Loaded file tracking info: {0} files"
    mark_failed: "Failed to mark file as indexed: {0}"
    save_failed: "Failed to save file tracking info: {0}"
    saved: "Saved file tracking info: {0} files"
  http:
    bad_request: "Bad request: {0}"
    internal_server_error: "Internal server error"
    processing_error: "Error processing HTTP request"
    received_request: "Received HTTP request: {0} {1}"
    shutdown: "HTTP server shutdown"
    start_failed: "Failed to start HTTP server"
    started: "HTTP server started on port {0}"
  hybrid:
    cannot_get_doc: "Cannot get document: id={0}, score={1}"
    completed: "Hybrid search completed: returned {0} documents in {1}ms"
    could_not_get_doc: "Could not get document for entry #{0} id={1} (score: {2})"
    detail_item: "{0}. {1} (hybrid: {2} = Lucene rank#{3} + vector:{4})"
    doc_id_list: "Document ID list: {0}"
    extract_keywords: "Extracted keywords: {0}"
    failed: "Hybrid search failed, falling back to keyword search"
    filtered: "Filtered out {0} low-score documents (score < {1}), keeping {2}"
    found_docs: "Found {0} documents"
    keyword_search: "Keyword search: {0}"
    lucene_found: "Lucene found {0} documents (total hits: {1}, limit={2})"
    lucene_top_header: "Lucene Top-10 documents (by relevance):"
    lucene_top_item: "{0}. {1} - {2} chars (Lucene rank score: {3,number,#.###})"
    severe_no_docs: "Severe: {0} scored docs but no document objects could be retrieved"
    top5_header: "Hybrid score Top-5 (before filtering, threshold={0}, topK={1}):"
    top5_item: "{0} {1}. {2} (score: {3})"
    topk_header: "Hybrid Top-{0} (Lucene weight:0.3 + Vector weight:0.7):"
    total_nulls: "Total {0} documents could not be retrieved (out of {1} scored docs)"
    vector_found: "Vector search found {0} documents (limit={1})"
    vector_top_header: "Vector Top-10 documents:"
    vector_top_item: "- {0} (similarity: {1,number,#.###})"
  image:
    delete_failed: "Failed to delete: {0}"
    deleted_all: "Deleted all images for document: {0}"
    read_info_failed: "Failed to read image info: {0}"
    saved: "Saved image: {0} for document: {1}"
    storage:
      created: "Created image storage directory: {0}"
      init_failed: "Failed to initialize image storage"
  imageproc:
    activated: "Image processing strategy activated: {0}"
    add_ocr: "Adding OCR strategy"
    add_vision: "Adding Vision LLM strategy"
    init: "Initializing image processing features..."
    language: "Recognition language: {0}"
    ocr_available: "OCR strategy available"
    ocr_hint: "Hint: add dependency net.sourceforge.tess4j:tess4j:5.9.0"
    ocr_unavailable: "OCR strategy unavailable: tess4j missing"
    placeholder: "Using placeholder strategy (default)"
    strategy: "Image processing strategy: {0}"
    tessdata: "Tessdata path: {0}"
    vision_apikey_hint: "Hint: set environment variable VISION_LLM_API_KEY or config knowledge.qa.image-processing.vision-llm.api-key"
    vision_available: "Vision LLM strategy available"
    vision_endpoint: "Vision LLM endpoint: {0}"
    vision_model: "Vision LLM model: {0}"
    vision_no_apikey: "Vision LLM enabled but API key not configured"
    vision_unavailable: "Vision LLM strategy unavailable"
  kb:
    batch_processing: "Batch processing: {0} docs ({1} / {2})"
    exists: "Existing knowledge base detected ({0} documents)"
    file_process_failed: "Failed to process file: {0}"
    files_to_index: "Files to index: {0}"
    final_batch: "Processing final batch: {0} docs"
    first_create: "First-time knowledge base creation"
    found_files: "Found {0} document files"
    hint_put_docs: "Hint: please put documents into {0}"
    incremental_done: "Incremental indexing completed!"
    incremental_failed: "Incremental indexing failed"
    incremental_stats: "Processed files: {0}/{1}, failed: {2}, total docs: {3}, time: {4}s"
    no_documents: "No supported documents found"
    parallel_mode: "Using parallel processing mode ({0} threads)"
    processing_start: "Start processing documents..."
    scanning: "Scanning documents: {0}"
    serial_mode: "Using serial processing mode"
    supported_formats: "Supported formats: {0}"
    up_to_date: "All files are up-to-date, no update needed"
    vector_enabled: "Vector search enabled"
    vector_init_failed: "Vector search init failed, falling back to keyword search"
  kqa:
    answer_header: "Answer:"
    found_chunks_images: "Found {0} chunks and {1} images for document"
    images_in_context: "Context contains {0} images"
    incremental_mode: "Rebuild mode: Incremental indexing"
    init_done: "Knowledge QA system initialized"
    init_failed: "Knowledge QA initialization failed"
    init_start: "Knowledge QA system initializing..."
    load_chunks_images_failed: "Failed to load chunks/images info"
    more_docs_available: "{0} more documents are available"
    rebuild_mode: "Rebuild mode: Full rebuild"
    response_time: "Response time: {0}ms"
    sep: "============================================================"
    source_path: "Source path: {0}"
    sources_header: "Sources (total {0} documents):"
    step: "Step {0}: {1}"
    storage_path: "Storage path: {0}"
    used_docs_count: "Using {0} documents for this answer"
  memory:
    critical: "Phase {0} - Critical memory usage: {1}% - OOM risk!"
    gc_done: "GC completed: before={0}% -> after={1}%"
    gc_trigger: "Memory usage {0}% exceeds threshold, triggering GC"
    usage: "Phase {0} - Used memory: {1} MB/ Max: {2} MB ({3}%)"
    usage_phase: "Phase {0} - Used memory: {1} MB/ Max: {2} MB ({3}%)"
    warning: "Phase {0} - High memory usage: {1}%"
  optimizer:
    commit: "Committing RAG changes"
    done: "Commit and optimization completed"
    embedding_closed: "Embedding engine closed"
    optimize: "Optimizing index"
    save_failed: "Failed to save vector index"
    saving_vectors: "Saving vector index..."
    vectors_saved: "Vector index saved successfully"
  qa:
    archive_failed: "Failed to archive QA record"
    archived: "High rating QA archived: rating={0}, path={1}"
    document_feedback: "Document feedback {0} [{1}]: {2} - {3}"
    feedback_applied: "Feedback applied to document weight: {0}"
    feedback_pending: "Feedback pending review: {0}"
    find_failed: "Failed to find record: {0}"
    load_failed: "Failed to load QA record: {0}"
    pending_failed: "Failed to get pending records"
    rating_applied: "Rating applied to document weight: {0} ({1} stars -> adjust {2})"
    rating_pending: "Rating pending review: {0} ({1} stars)"
    rating_submitted: "Rating submitted {0} [{1}]: {2} - {3} stars (adjust: {4})"
    recent_failed: "Failed to get recent records"
    record_notfound: "Record not found: {0}"
    record_save_failed: "Failed to save QA record"
    record_saved: "Saved QA record: {0} - {1}"
    record_update_failed: "Failed to update QA record: {0}"
    record_updated: "Updated QA record: {0}"
    records_dir: "QA records directory: {0}"
    records_dir_failed: "Failed to create QA records directory: {0}"
    stats_failed: "Failed to compute QA statistics"
    user_feedback: "User feedback [{0}]: rating={1}, content={2}"
  query:
    cache_cleared: "Query cache cleared"
    cache_hit: "Cache hit for query: {0}"
    processed: "Query processed: text='{0}', hits={1}, time={2}ms"
    unknown_sort: "Unknown sort field: {0}, using relevance"
  rag:
    batch_indexed: "Batch indexed {0} documents"
    cache_hit: "Query result retrieved from cache: {0}"
    close_error: "Error closing Local File RAG"
    closed: "Local File RAG closed successfully"
    closing: "Closing Local File RAG..."
    delete_failed: "Failed to delete document: {0}"
    deleted_count: "Deleted {0} documents"
    deleting_all: "Deleting all documents..."
    doc_deleted: "Document deleted: {0}"
    doc_indexed: "Document indexed successfully: {0}"
    doc_updated: "Document updated: {0}"
    found_to_delete: "Found {0} documents to delete"
    initialized: "Local File RAG initialized with configuration: {0}"
    load_content_failed: "Failed to load content for document: {0}"
    loaded_content: "Loaded content for document: {0}, length: {1}"
    no_documents: "No documents to delete"
    optimized: "Index optimization completed"
    optimizing: "Optimizing index..."
    search_completed: "Search completed in {0}ms, found {1} results"
  session:
    cleaned: "Cleaned expired session: sessionId={0}"
    cleaned_count: "Cleaned {0} expired sessions"
    create: "Created search session: sessionId={0}, totalDocs={1}, perQuery={2}"
    deleted: "Deleted search session: sessionId={0}"
    goto_page: "Goto page {0}: sessionId={1}, offset={2}"
    next: "Switched to next batch: sessionId={0}, offset={1}"
    no_next: "No next batch available for session {0}"
    no_prev: "No previous batch available for session {0}"
    prev: "Switched to previous batch: sessionId={0}, offset={1}"
  similar:
    failed: "Failed to find similar QAs"
    found: "Found {0} similar QAs (keywords: {1})"
  simple:
    batch_index_files_complete: "Batch indexing completed: success {0}, fail {1}"
    batch_indexed: "Batch indexed {0} documents"
    commit: "Commit index changes"
    doc_indexed: "Document indexed: {0} -> {1}"
    file_empty: "File content empty: {0}"
    index_file: "Indexed file: {0} -> {1} ({2} bytes)"
    index_file_failed: "Failed to index file: {0}"
    optimized: "Index optimization completed"
    scanned_files: "Scanned {0} files"
    search_results: "Search '{0}' found {1} results"
    shutdown: "Shutting down RAG service"
