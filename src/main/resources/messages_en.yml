# Flattened messages converted from messages_en.yml (English)
# Generated to support I18n.get(key) lookups
api:
  started: "API server started on port {0}"
banner:
  supports: "Supports: {0}"
  title: "AI Reviewer - Knowledge Base Intelligent Q&A System"
  version: "Version: {0}"
batch:
  failed: "Batch processing failed"
context:
  initialized: "SmartContextBuilder initialized: maxContext={0} chars, maxDoc={1} chars, preserveFullContent={2}"
document_management:
  api:
    error:
      delete_failed: "Deletion failed: {0}"
      file_empty: "File is empty"
      index_failed: "Indexing failed: {0}"
      list_failed: "Failed to retrieve list: {0}"
      not_found: "Document not found"
      upload_failed: "Upload failed: {0}"
    success:
      batch_result: "Success: {0}, Failed: {1}"
      batch_upload: "Batch upload completed"
      delete: "Document deleted successfully"
      index: "Document indexed successfully"
      list_loaded: "Document list retrieved successfully: Returned {0} documents, Total {1}"
      upload: "Document uploaded successfully"
  log:
    scanned_types: "Scanned file types: {0}"
    batch_upload: "Batch upload documents: {0}"
    upload_success: "Document uploaded successfully: {0}"
    upload_failed: "Document upload failed"
    file_upload_failed: "File upload failed: {0}"
    list_documents: "Get document list: page={0}, pageSize={1}, sortBy={2}, sortOrder={3}"
    list_failed: "Failed to get document list"
    auto_index_trigger: "üì¶ Auto-triggering incremental index..."
    auto_index_success: "‚úÖ Auto incremental index completed"
    auto_index_failed: "‚ö†Ô∏è Auto incremental index failed: {0}"
    trigger_auto_index_failed: "‚ö†Ô∏è Failed to trigger auto index: {0}"
document_service:
  error:
    cannot_create_dir: "Failed to create document directory: {0}"
    filename_empty: "Filename is empty"
    file_too_large: "File too large: {0} MB (Max: {1} MB)"
    illegal_path: "Illegal file path"
    unsupported_format: "Unsupported file format: {0}"
  log:
    scanned_types: "Scanned file types: {0}"
error:
  auth:
    invalid_credentials: "Invalid credentials"
    permission_denied: "Permission denied: {0}"
    user_exists: "User already exists"
  chunk:
    expected_json_array: "Expected JSON array, but got: {0}"
    no_valid_chunks: "No valid chunks found in AI response"
    no_valid_json: "No valid JSON found in response"
  docs:
    create_failed: "Failed to create document: {0}"
  file:
    directory_not_exists: "Directory does not exist: {0}"
    empty: "File content is empty: {0}"
    index_failed: "File indexing failed: {0}"
    not_a_directory: "Not a directory: {0}"
    not_a_file: "Not a file: {0}"
    not_exists: "File does not exist: {0}"
feedback:
  api:
    emoji:
      "1": "üòû Completely useless"
      "2": "üôÅ Not helpful"
      "3": "üòê Average"
      "4": "üòä Very helpful"
      "5": "ü§© Extremely useful"
    error:
      invalid_feedback_type: "feedbackType must be LIKE or DISLIKE"
      invalid_rating: "Rating must be between 1-5"
      missing_params: "{0} cannot be empty"
      processing_failed: "Processing failed: {0}"
      record_not_found: "Record not found"
    impact:
      document:
        "1": "This document is not helpful, the system will significantly reduce its recommendation weight ‚ö†Ô∏è"
        "2": "This document is not very helpful, the system will reduce its recommendation weight üìâ"
        "3": "This document is average, the system will keep its current weight ‚û°Ô∏è"
        "4": "This document is very helpful, the system will increase its recommendation weight üìà"
        "5": "This document is extremely useful! The system will prioritize recommending it üöÄ"
      overall:
        "1": "Sorry we couldn't help you! We will focus on improvement üôè"
        "2": "Thank you for your feedback! We will analyze and improve üîß"
        "3": "Thank you for your rating! We will continue to optimize üí°"
        "4": "Thank you for your feedback! This helps us improve answer quality üëç"
        "5": "Great! This answer will be recommended to other users üåü"
    success:
      feedback_received: "Thank you for your feedback!"
      thank_you: "Thank you for your rating!"
image:
  log:
    get_failed: "Failed to retrieve image: {0}/{1}"
    list_failed: "Failed to retrieve document image list: {0}"
  saved: "Image saved: {0} (Document: {1})"
  service:
    saved: "Image saved: {0}"
knowledge_qa_service:
  doc_item: "{0}. {1}"
  error_processing: "Error occurred while processing Q&A: {0}"
  found_chunks_images: "üì¶ Found {0} chunks and {1} images"
  image_guide_1: "1. Related images are provided below with ready-to-use Markdown links (marked with üì∑)."
  image_guide_2: "2. [IMPORTANT] When your answer involves image content, you MUST reference the image by copying the link code after üì∑."
  image_guide_3: "3. Referencing images helps users visually understand your answer and judge its quality."
  image_guide_4: "4. Example: If an image shows architecture diagram, mention it as: ![Architecture](/api/images/xxx)"
  doc_images_header: "Images from document \"{0}\" ({1} total):"
  image_desc_default: "Image {0}"
  images_in_context: "üñºÔ∏è Context contains {0} images of information"
  # Added keys requested
  close_existing_kb: "Closing existing knowledge base..."
  destroy_start: "Destroying knowledge Q&A service..."
  kb_closed: "Knowledge base closed"
  kb_closed_safe: "Knowledge base closed safely"
  rebuild_start: "Starting knowledge base rebuild..."
  system_closed: "Knowledge Q&A system closed"
  log:
    build_complete: "   ‚úÖ Knowledge base build completed"
    failed_files: "      - Failed files: {0}"
    kb_ready: "   ‚úÖ Knowledge base is ready"
    processed_files: "      - Processed files: {0}"
    total_documents: "      - Total documents: {0}"
    total_files: "      - Total files: {0}"
    chunk_overlap_chars: "Chunk overlap: {0} chars"
    chunk_size_chars: "Chunk size: {0} chars"
    chunking_strategy: "Chunking strategy: {0}"
    create_qa_system: "Creating QA system..."
    document_count: "Documents: {0}"
    index_count: "Index entries: {0}"
    init_llm: "Initializing LLM client..."
    init_vector_engine: "Initializing vector engine: {0}"
    llm_client_ready: "LLM client ready"
    llm_client_type: "LLM client type: {0}"
    llm_provider: "LLM provider: {0}"
    max_context_chars: "Max context chars: {0}"
    max_doc_length_chars: "Max document length chars: {0}"
    smart_context_initialized: "Smart context initialized: maxContext={0}, maxDoc={1}"
    vector_init_failed_hint: "‚ö†Ô∏è Vector search initialization failed, system will use text search only"
    vector_init_model_hint: "üí° Hint: embedding model file is incomplete or corrupted"
    vector_init_solution: "üìù Solutions:"
    vector_init_solution_1: "   1. Set knowledge.qa.vector-search.enabled: false in application.yml"
    vector_init_solution_2: "   2. Or download complete ONNX model files (including .onnx and .onnx_data files)"
    llm_call: "ü§ñ Calling LLM, prompt length: {0} characters"
    llm_call_failed: "‚ùå LLM call failed"
    llm_call_error: "LLM call failed: {0}"
    direct_qa_mode: "üìÑ Direct QA mode (without knowledge base retrieval)"
    prompt_length: "Prompt length: {0} characters"
    direct_qa_complete: "‚úÖ Direct QA complete, time: {0}ms"
    direct_qa_failed: "‚ùå Direct QA failed"
    direct_qa_error: "Direct QA processing failed: {0}"
    context_info: "Context information:"
    using_keyword_mode: "Using keyword mode for context building"
    record_saved: "QA record saved: {0}"
    using_vector_enhancement: "Using vector enhancement for retrieval"
    vector_count: "Vector index contains {0} vectors"
    vector_dimension: "Vector dimension: {0}"
    vector_engine_loaded: "Vector engine loaded: {0}"
    vector_index_loaded: "Vector index loaded: {0}"
    vector_index_path: "Vector index path: {0}"
    vector_model: "Vector model: {0}"
  model_doc_hint: "Hint: Place model files in {0}"
  model_download_hint: "Hint: Download the model from {0}"
  more_images: "  ... {0} more images"
  question_prompt: "‚ùì Question: {0}"
  question_separator: "\n================================================================================\n"
  referenced_docs: "\n\n**Referenced Documents**:"
  related_image: "Related Images"
  remaining_docs: "‚ÑπÔ∏è {0} more related documents not included in this answer"
  remaining_docs_unprocessed: "‚ÑπÔ∏è {0} more related documents not included in this answer"
  response_time: "\n‚è±Ô∏è  Response time: {0}ms"
  separator: "================================================================================="
  sources_label: "\nüìö Data Sources (Total {0} documents):"
  too_many_docs_retrieved: "‚ö†Ô∏è Retrieved {0} documents, processing first {1} (Config: documents-per-query)"
  using_docs: "üìö Used {0} documents to generate this answer"
  using_hybrid_search: "‚úÖ Using hybrid search (Lucene + Vector)"
  using_strategy_dispatcher: "üéØ Using search strategy dispatcher"
  answer_label: "\nüí° Answer:"
  available_images: "Available images: {0}"
  context_stats: "Context: {0} chars from {1} documents"
  create_session: "Creating QA session: {0}"
  image_item: "Image {0}: {1} (Source: {2})"
  important_notice: "Important: {0}"
  using_keyword_search: "Using keyword search mode"
  classpath_prefix: "Classpath: {0}"
  closing_existing_kb: "Closing existing knowledge base before proceeding..."
  debug_enhanced_stats: "üìä Statistics: Filesystem={0} files, Indexed={1} docs, Unindexed={2}, Progress={3}%"
  debug_enhanced_stats_v2: "üìä Detailed Stats: Filesystem={0} files, Unique docs={1}, Index chunks={2}, Unindexed={3}, Progress={4}%"
  existing_kb_closed: "Existing knowledge base closed"
  failed_files: "      - Failed files: {0}"
  incremental_index_start: "Starting incremental indexing..."
  more_docs_notice: "\n‚ÑπÔ∏è {0} more related documents not included in this answer"
  question_label: "‚ùì Question:"
  success_files: "      - Successful files: {0}"
  total_documents: "      - Total documents: {0}"
  using_session_docs: "Using session-stored documents: {0}"

# File System Storage Engine
storage_engine:
  log:
    initialized: "FileSystemStorageEngine initialized at: {}"
    failed_init_dirs: "Failed to initialize directories"
    failed_init_storage_dirs: "Failed to initialize storage directories"
    document_with_same_content: "Document with same content already exists: {}"
    document_stored: "Document stored: {}"
    failed_store: "Failed to store document"
    failed_store_batch: "Failed to store document in batch: {}"
    document_file_not_found: "Document file not found: {}"
    failed_retrieve: "Failed to retrieve document: {}"
    document_deleted: "Document deleted: {}"
    failed_delete: "Failed to delete document: {}"
    document_updated: "Document updated: {}"
    storage_cleared: "Storage cleared"
    clear_storage_failed: "Failed to clear storage"
  error:
    failed_init_dirs: "Failed to initialize directories"
    failed_init_storage_dirs: "Failed to initialize storage directories"
    failed_store_document: "Failed to store document"
    failed_retrieve_document: "Failed to retrieve document: {}"
    failed_delete_document: "Failed to delete document: {}"
    clear_storage: "Failed to clear storage"

# Audit Event
audit:
  event:
    title: "Audit Event"
    event_id: "Event ID"
    event_type: "Event Type"
    user_id: "User ID"
    username: "Username"
    action: "Action"
    resource: "Resource"
    details: "Details"
    success: "Success"
    timestamp: "Timestamp"
    ip_address: "IP Address"

# Audit Log Service
audit_log:
  log:
    logged: "Audit logged: {}"
    write_failed: "Failed to write audit log"
    init_failed: "Audit log initialization failed"
  document_operation: "Document operation"
  search_operation: "Search operation"
  auth_event: "Authentication event"

# Document Chunker
document_chunker:
  interface:
    title: "Document chunker interface"
    chunk_method: "Chunk a document"
    chunk_method_desc: "Split document content into multiple document chunks"
    chunk_method_no_query: "Chunk a document without query context"
    chunk_method_no_query_desc: "Split document content without query context"
    get_name: "Get chunker name"
    get_description: "Get chunker description"
  param:
    content: "Document content"
    query: "User query (optional - used by smart chunkers)"
    return: "List of document chunks"

# Document Chunk
document_chunk:
  class:
    title: "Document chunk"
    description: "Represents a fragment of a chunked document"
  field:
    content: "Chunk content"
    title: "Chunk title (optional)"
    index: "Chunk index (zero-based)"
    total_chunks: "Total number of chunks"
    start_position: "Start position in original document"
    end_position: "End position in original document"

# Cache Engine
cache_engine:
  interface:
    title: "Cache engine interface"
    description: "Provides multi-level cache support"
  method:
    get_document: "Get cached document"
    put_document: "Cache document"
    get_query_result: "Get cached query result"
    put_query_result: "Cache query result"
    invalidate_document: "Invalidate document cache"
  param:
    doc_id: "Document ID"
    query_key: "Query key"
    result: "Query result"
    document: "Document object"

# Index Engine
index_engine:
  interface:
    title: "Index engine interface"
    description: "Responsible for document indexing and search"
  method:
    index_document: "Index document"
    index_batch: "Batch index documents"
    update_index: "Update index"
    delete_from_index: "Delete document from index"
    search: "Search documents"
  param:
    documents: "List of documents"
    new_document: "New document object"
    query: "Query object"
    return: "Search result"

# SQLite Metadata Manager
sqlite_metadata_manager:
  class:
    title: "SQLite Metadata Manager"
    description: "Stores document metadata using SQLite database"
  log:
    initialized: "SQLite metadata manager initialized: {}"
    failed_init: "Failed to initialize SQLite database"
    failed_execute_update: "Failed to execute update: {}"
    document_saved: "Document metadata saved: {}"
    failed_save: "Failed to save document metadata: {}"
    document_found: "Document metadata found: {}"
    failed_find: "Failed to find document metadata: {}"
    document_updated: "Document metadata updated: {}"
    failed_update: "Failed to update document metadata: {}"
    document_deleted: "Document metadata deleted: {}"
    failed_delete: "Failed to delete document metadata: {}"
    cleared: "Metadata table cleared"
    failed_clear: "Failed to clear metadata table"
    failed_exists: "Failed to check document existence"
    failed_count: "Failed to get document count"
    failed_get_all_ids: "Failed to get all document IDs"
    failed_find_by_hash: "Failed to find documents by hash"
    failed_close: "Failed to close database connection"
    retrieved_ids: "Retrieved {} document IDs"
    connection_closed: "SQLite connection closed"
    connection_close_failed: "Failed to close SQLite connection"
    all_cleared: "All document metadata cleared"
    clear_failed: "Failed to clear document metadata"

# SHA-256 Document Hasher
sha256_document_hasher:
  class:
    title: "SHA-256 Document Hasher"
    description: "Computes hash values of document content for deduplication"
  method:
    compute_hash: "Compute content hash"
    compute_hash_string: "Compute string content hash"
  param:
    content_bytes: "Content byte array"
    content_string: "Content string"
    return: "Base64 encoded hash value"
  log:
    failed_compute: "Failed to compute hash: algorithm not found"
  error:
    failed_compute: "Failed to compute hash"
    connection_closed: "Database connection closed"

# Application
app:
  log:
    started: "‚úÖ Application started successfully, Address: {0}"
    start_failed: "‚ùå Application startup failed"
    startup_failed: "Application startup failed"