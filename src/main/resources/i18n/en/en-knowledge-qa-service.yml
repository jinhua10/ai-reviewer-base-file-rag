knowledge_qa_service:
  doc_item: "{0}. {1}"
  error_processing: "Error occurred during Q&A processing: {0}"
  found_chunks_images: "ğŸ“¦ Found {0} chunks and {1} images"
  image_guide_1: "1. Below are image resources from related documents, each image has a directly usable Markdown link (marked with ğŸ“·)."
  image_guide_2: "2. ã€Importantã€‘When your answer involves content from images, please be sure to reference the image in your answer by copying the link code after ğŸ“·."
  image_guide_3: "3. Referencing images helps users intuitively understand your answer and makes it easier for users to judge answer quality."
  image_guide_4: "4. Example: If the image shows an architecture diagram, when mentioning the architecture in your answer, reference: ![Architecture Diagram](/api/images/xxx)"
  doc_images_header: "Related images for document \"{0}\" (total {1} images):"
  image_desc_default: "Image{0}"
  images_in_context: "ğŸ–¼ï¸ Context contains {0} image information"
  # Newly requested keys
  destroy_start: "Destroying knowledge Q&A service..."
  kb_closed_safe: "Knowledge base closed safely"
  system_closed: "Knowledge Q&A system closed"
  close_existing_kb: "Closing existing knowledge base..."
  kb_closed: "Knowledge base closed"
  rebuild_start: "Starting knowledge base rebuild..."
  log:
    build_complete: "   âœ… Knowledge base build complete"
    failed_files: "      - Failed files: {0}"
    kb_ready: "   âœ… Knowledge base ready"
    processed_files: "      - Processed files: {0}"
    total_documents: "      - Total documents: {0}"
    total_files: "      - Total files: {0}"
    chunk_overlap_chars: "Chunk overlap: {0} characters"
    chunk_size_chars: "Chunk size: {0} characters"
    chunking_strategy: "Chunking strategy: {0}"
    create_qa_system: "Creating Q&A system..."
    document_count: "Document count: {0}"
    index_count: "Index entry count: {0}"
    init_llm: "Initializing LLM client..."
    init_vector_engine: "Initializing vector engine: {0}"
    llm_client_ready: "LLM client ready"
    llm_client_type: "LLM client type: {0}"
    llm_provider: "LLM provider: {0}"
    max_context_chars: "Max context characters: {0}"
    max_doc_length_chars: "Max document length characters: {0}"
    smart_context_initialized: "Smart context initialized: maxContext={0}, maxDoc={1}"
    vector_init_failed_hint: "âš ï¸ Vector search initialization failed, system will use text search only"
    vector_init_model_hint: "ğŸ’¡ Hint: embedding model file is incomplete or corrupted"
    vector_init_solution: "ğŸ“ Solutions:"
    vector_init_solution_1: "   1. Set knowledge.qa.vector-search.enabled: false in application.yml"
    vector_init_solution_2: "   2. Or download complete ONNX model files (including .onnx and .onnx_data files)"
    llm_call: "ğŸ¤– Calling LLM, prompt length: {0} characters"
    llm_call_failed: "âŒ LLM call failed"
    llm_call_error: "LLM call failed: {0}"
    direct_qa_mode: "ğŸ“„ Direct Q&A mode (without knowledge base retrieval)"
    prompt_length: "Prompt length: {0} characters"
    direct_qa_complete: "âœ… Direct Q&A complete, time: {0}ms"
    direct_qa_failed: "âŒ Direct Q&A failed"
    direct_qa_error: "Direct Q&A processing failed: {0}"
    context_info: "Context information:"
    using_keyword_mode: "Context building using keyword mode"
    record_saved: "Q&A record saved: {0}"
    using_vector_enhancement: "Retrieval using vector enhancement"
    vector_count: "Vector index contains {0} vectors"
    vector_dimension: "Vector dimension: {0}"
    vector_engine_loaded: "Vector engine loaded: {0}"
    vector_index_loaded: "Vector index loaded: {0}"
    vector_index_path: "Vector index path: {0}"
    vector_model: "Vector model: {0}"
  model_doc_hint: "Hint: Please place model files in {0} directory"
  model_download_hint: "Hint: Please download model from {0}"
  more_images: "  ... {0} more images"
  more_images_notice: "({0} more images not shown)"
  question_prompt: "â“ Question: {0}"
  question_separator: "\n================================================================================\n"
  referenced_docs: "\n\n**Referenced Documents**:"
  related_image: "Related Image"
  remaining_docs: "â„¹ï¸ Another {0} related documents not included in this answer"
  remaining_docs_unprocessed: "â„¹ï¸ Another {0} related documents not included in this answer"
  response_time: "\nâ±ï¸  Response time: {0}ms"
  separator: "================================================================================="
  sources_label: "\nğŸ“š Data sources (total {0} documents):"
  too_many_docs_retrieved: "âš ï¸ Retrieved {0} documents, will process first {1} (configuration: documents-per-query)"
  using_docs: "ğŸ“š Using {0} documents to generate this answer"
  using_hybrid_search: "âœ… Using hybrid search (Lucene + Vector)"
  using_strategy_dispatcher: "ğŸ¯ Using retrieval strategy dispatcher"
  answer_label: "\nğŸ’¡ Answer:"
  available_images: "Available images: {0}"
  context_stats: "Context: {0} characters from {1} documents"
  create_session: "Creating Q&A session: {0}"
  image_item: "Image {0}: {1} (Source: {2})"
  important_notice: "Important notice: {0}"
  using_keyword_search: "Using keyword search mode"
  classpath_prefix: "Classpath: {0}"
  closing_existing_kb: "Closing existing knowledge base before continuing..."
  debug_enhanced_stats: "ğŸ“Š Statistics: filesystem={0} files, indexed={1} documents, unindexed={2}, completion={3}%"
  debug_enhanced_stats_v2: "ğŸ“Š Detailed statistics: filesystem={0} files, unique documents={1}, indexed chunks={2}, unindexed={3}, completion={4}%"
  existing_kb_closed: "Existing knowledge base closed"
  failed_files: "      - Failed files: {0}"
  incremental_index_start: "Starting incremental indexing..."
  more_docs_notice: "\nâ„¹ï¸ Another {0} related documents not included in this answer"
  question_label: "â“ Question:"
  success_files: "      - Success files: {0}"
  total_documents: "      - Total documents: {0}"
  using_session_docs: "Using session stored documents: {0}"