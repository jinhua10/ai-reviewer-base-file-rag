package top.yumbo.ai.rag.spring.boot.streaming;

import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;
import org.springframework.web.servlet.mvc.method.annotation.SseEmitter;
import top.yumbo.ai.rag.model.Document;
import top.yumbo.ai.rag.spring.boot.llm.LLMClient;
import top.yumbo.ai.rag.spring.boot.streaming.model.HOPEAnswer;
import top.yumbo.ai.rag.spring.boot.streaming.model.SessionStatus;
import top.yumbo.ai.rag.spring.boot.streaming.model.StreamingSession;
import top.yumbo.ai.rag.spring.boot.streaming.model.StreamingResponse;
import top.yumbo.ai.rag.optimization.SmartContextBuilder;

import java.io.IOException;
import java.util.List;
import java.util.Map;
import java.util.UUID;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ConcurrentHashMap;

/**
 * æ··åˆæµå¼å“åº”æœåŠ¡
 * (Hybrid Streaming Response Service)
 *
 * æä¾›åŒè½¨å“åº”ï¼š
 * 1. HOPE å¿«é€Ÿç­”æ¡ˆ (<300ms)
 * 2. LLM æµå¼ç”Ÿæˆ (TTFB <1s)
 *
 * @author AI Reviewer Team
 * @since 2025-12-08
 */
@Slf4j
@Service
public class HybridStreamingService {

    private final HOPEFastQueryService hopeFastQueryService;
    private final LLMClient llmClient;
    private final StreamingSessionMonitor sessionMonitor;
    private final SmartContextBuilder contextBuilder;

    // æ´»è·ƒä¼šè¯ç®¡ç†
    // (Active session management)
    private final Map<String, StreamingSession> activeSessions = new ConcurrentHashMap<>();

    /**
     * æ„é€ å‡½æ•°
     * (Constructor)
     *
     * @param hopeFastQueryService HOPE å¿«é€ŸæŸ¥è¯¢æœåŠ¡
     * @param llmClient LLM å®¢æˆ·ç«¯
     * @param sessionMonitor ä¼šè¯ç›‘æ§å™¨
     * @param contextBuilder ä¸Šä¸‹æ–‡æ„å»ºå™¨
     */
    public HybridStreamingService(
            HOPEFastQueryService hopeFastQueryService,
            LLMClient llmClient,
            StreamingSessionMonitor sessionMonitor,
            SmartContextBuilder contextBuilder) {
        this.hopeFastQueryService = hopeFastQueryService;
        this.llmClient = llmClient;
        this.sessionMonitor = sessionMonitor;
        this.contextBuilder = contextBuilder;

        log.info("HybridStreamingService initialized (æ··åˆæµå¼æœåŠ¡å·²åˆå§‹åŒ–)");
    }

    /**
     * åŒè½¨å“åº”ï¼šåŒæ—¶æä¾› HOPE å¿«é€Ÿç­”æ¡ˆå’Œ LLM æµå¼ç”Ÿæˆ
     * (Dual-track response: HOPE fast answer + LLM streaming)
     *
     * @param question ç”¨æˆ·é—®é¢˜
     * @param userId ç”¨æˆ·ID
     * @return æµå¼å“åº”å¯¹è±¡
     */
    public StreamingResponse ask(String question, String userId) {
        long startTime = System.currentTimeMillis();
        String sessionId = UUID.randomUUID().toString();

        log.info("ğŸš€ å¯åŠ¨åŒè½¨å“åº” (Starting dual-track response): sessionId={}, question={}",
            sessionId, question);

        // 1. å¿«é€ŸæŸ¥è¯¢ HOPEï¼ˆç›®æ ‡ <300msï¼‰
        // (Quick query HOPE, target <300ms)
        CompletableFuture<HOPEAnswer> hopeFuture = CompletableFuture.supplyAsync(() -> {
            try {
                return hopeFastQueryService.queryFast(question, sessionId);
            } catch (Exception e) {
                log.warn("HOPE å¿«é€ŸæŸ¥è¯¢å¤±è´¥ (HOPE fast query failed): {}", e.getMessage());
                return HOPEAnswer.builder()
                    .canDirectAnswer(false)
                    .source(HOPEAnswer.SourceType.NONE)
                    .build();
            }
        });

        // 2. å¯åŠ¨ LLM æµå¼ç”Ÿæˆï¼ˆç›®æ ‡ TTFB <1sï¼‰
        // (Start LLM streaming, target TTFB <1s)
        StreamingSession llmSession = startLLMStreaming(question, sessionId, userId);

        // 3. åˆ›å»ºå“åº”å¯¹è±¡
        // (Create response object)
        StreamingResponse response = new StreamingResponse();
        response.setSessionId(sessionId);
        response.setQuestion(question);
        response.setHopeFuture(hopeFuture);
        response.setLlmSession(llmSession);

        log.info("âœ… åŒè½¨å“åº”å·²å¯åŠ¨ (Dual-track response started): sessionId={}, duration={}ms",
            sessionId, System.currentTimeMillis() - startTime);

        return response;
    }

    /**
     * å¯åŠ¨ LLM æµå¼ç”Ÿæˆ
     * (Start LLM streaming generation)
     */
    private StreamingSession startLLMStreaming(String question, String sessionId, String userId) {
        StreamingSession session = new StreamingSession(sessionId, question);
        session.setUserId(userId);

        // æ³¨å†Œä¼šè¯åˆ°ç›‘æ§å™¨
        // (Register session to monitor)
        activeSessions.put(sessionId, session);
        sessionMonitor.registerSession(session);

        // å¼‚æ­¥å¯åŠ¨æµå¼ç”Ÿæˆ
        // (Start streaming generation asynchronously)
        CompletableFuture.runAsync(() -> {
            try {
                log.debug("å¼€å§‹ LLM æµå¼ç”Ÿæˆ (Starting LLM streaming): sessionId={}", sessionId);

                // ç›´æ¥ä½¿ç”¨ LLM æµå¼æ¥å£ç”Ÿæˆç­”æ¡ˆ
                // (Directly use LLM streaming interface to generate answer)
                // æ³¨æ„ï¼šå®é™…çš„ RAG æ£€ç´¢åº”è¯¥åœ¨è°ƒç”¨æ­¤æœåŠ¡ä¹‹å‰å®Œæˆ
                // (Note: Actual RAG retrieval should be done before calling this service)

                // ç®€å•çš„æç¤ºè¯ï¼ˆå®é™…ä½¿ç”¨ä¸­åº”è¯¥åŒ…å«æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ï¼‰
                // (Simple prompt - should include retrieved context in actual use)
                String prompt = buildPrompt(question);

                // è°ƒç”¨ LLM æµå¼æ¥å£
                // (Call LLM streaming interface)
                streamFromLLM(session, prompt);


            } catch (Exception e) {
                log.error("LLM æµå¼ç”Ÿæˆå¤±è´¥ (LLM streaming failed): sessionId={}, error={}",
                    sessionId, e.getMessage(), e);
                session.markError(e);
                sessionMonitor.onSessionComplete(sessionId);
            }
        });

        return session;
    }

    /**
     * æ„å»ºæç¤ºè¯
     * (Build prompt)
     */
    private String buildPrompt(String question) {
        // ç®€åŒ–ç‰ˆï¼šç›´æ¥ä½¿ç”¨é—®é¢˜
        // (Simplified: directly use question)
        // å®é™…ä½¿ç”¨ä¸­åº”è¯¥åŒ…å«ä» RAG æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
        // (Should include context retrieved from RAG in actual use)
        return String.format("è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š\n\n%s", question);
    }

    /**
     * ä» LLM æµå¼è·å–å“åº”
     * (Stream response from LLM)
     *
     * ä½¿ç”¨ LLMClient çš„ Flux æµå¼æ¥å£ï¼ˆå“åº”å¼æµï¼‰
     * (Use LLMClient's Flux streaming interface - Reactive Streams)
     */
    private void streamFromLLM(StreamingSession session, String prompt) {
        // æ£€æŸ¥æ˜¯å¦æ”¯æŒæµå¼
        // (Check if streaming is supported)
        if (!llmClient.supportsStreaming()) {
            log.warn("âš ï¸ LLM å®¢æˆ·ç«¯ä¸æ”¯æŒæµå¼è¾“å‡º (LLM client doesn't support streaming): sessionId={}",
                session.getSessionId());

            // é™çº§ï¼šä½¿ç”¨åŒæ­¥æ–¹å¼
            // (Fallback: use synchronous method)
            try {
                String fullAnswer = llmClient.generate(prompt);

                // ä¸€æ¬¡æ€§å‘é€å®Œæ•´ç­”æ¡ˆ
                // (Send full answer at once)
                session.appendChunk(fullAnswer);
                session.notifySubscribers(fullAnswer);
                session.markComplete();
                sessionMonitor.onSessionComplete(session.getSessionId());

                log.info("âœ… ä½¿ç”¨åŒæ­¥æ–¹å¼å®Œæˆ (Completed with synchronous mode): sessionId={}",
                    session.getSessionId());
            } catch (Exception e) {
                log.error("âŒ åŒæ­¥ç”Ÿæˆé”™è¯¯ (Synchronous generation error): sessionId={}, error={}",
                    session.getSessionId(), e.getMessage());
                session.markError(e);
                sessionMonitor.onSessionComplete(session.getSessionId());
            }
            return;
        }


        // ä½¿ç”¨ Flux å“åº”å¼æµæ¥å£
        // (Use Flux reactive streaming interface)
        llmClient.generateStream(prompt)
            .subscribe(
                // onNext: æ¯ä¸ªæ–‡æœ¬å—åˆ°è¾¾æ—¶
                // (onNext: when each text chunk arrives)
                chunk -> {
                    session.appendChunk(chunk);
                    session.notifySubscribers(chunk);
                },
                // onError: é”™è¯¯æ—¶
                // (onError: when error occurs)
                error -> {
                    log.error("âŒ LLM æµå¼ç”Ÿæˆé”™è¯¯ (LLM streaming error): sessionId={}, error={}",
                        session.getSessionId(), error.getMessage());
                    session.markError(error instanceof Exception ?
                        (Exception) error : new RuntimeException(error));
                    sessionMonitor.onSessionComplete(session.getSessionId());
                },
                // onComplete: å®Œæˆæ—¶
                // (onComplete: when completed)
                () -> {
                    session.markComplete();
                    sessionMonitor.onSessionComplete(session.getSessionId());
                    log.debug("âœ… LLM æµå¼ç”Ÿæˆå®Œæˆ (LLM streaming completed): sessionId={}",
                        session.getSessionId());
                }
            );
    }

    /**
     * åˆ›å»º SSE æµ
     * (Create SSE stream)
     *
     * ç”¨äºå‰ç«¯è®¢é˜… LLM æµå¼è¾“å‡º
     * (For frontend to subscribe to LLM streaming output)
     */
    public SseEmitter createSSEStream(String sessionId) {
        StreamingSession session = activeSessions.get(sessionId);
        if (session == null) {
            log.warn("ä¼šè¯ä¸å­˜åœ¨ (Session not found): sessionId={}", sessionId);
            return null;
        }

        SseEmitter emitter = new SseEmitter(300000L);  // 5åˆ†é’Ÿè¶…æ—¶

        // è®¢é˜…ä¼šè¯çš„è¾“å‡º
        // (Subscribe to session output)
        session.addSubscriber(chunk -> {
            try {
                emitter.send(SseEmitter.event()
                    .name("chunk")
                    .data(chunk));
            } catch (IOException e) {
                log.warn("å‘é€ SSE æ•°æ®å¤±è´¥ (Failed to send SSE data): {}", e.getMessage());
                emitter.completeWithError(e);
            }
        });

        // ä¼šè¯å®Œæˆæ—¶å…³é—­ SSE
        // (Close SSE when session completes)
        CompletableFuture.runAsync(() -> {
            while (session.getStatus() == SessionStatus.STREAMING) {
                try {
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    break;
                }
            }

            try {
                emitter.send(SseEmitter.event()
                    .name("complete")
                    .data("done"));
                emitter.complete();
            } catch (IOException e) {
                log.warn("å…³é—­ SSE å¤±è´¥ (Failed to close SSE): {}", e.getMessage());
            }
        });

        // å¤„ç†å®¢æˆ·ç«¯æ–­å¼€
        // (Handle client disconnect)
        emitter.onCompletion(() -> {
            log.debug("SSE è¿æ¥æ­£å¸¸å…³é—­ (SSE connection closed normally): sessionId={}", sessionId);
        });

        emitter.onTimeout(() -> {
            log.warn("SSE è¿æ¥è¶…æ—¶ (SSE connection timeout): sessionId={}", sessionId);
            sessionMonitor.onClientDisconnect(sessionId, "SSE timeout");
        });

        emitter.onError(throwable -> {
            log.warn("SSE è¿æ¥é”™è¯¯ (SSE connection error): sessionId={}, error={}",
                sessionId, throwable.getMessage());
            sessionMonitor.onClientDisconnect(sessionId, "SSE error: " + throwable.getMessage());
        });

        return emitter;
    }

    /**
     * è·å–ä¼šè¯
     * (Get session)
     */
    public StreamingSession getSession(String sessionId) {
        return activeSessions.get(sessionId);
    }

    /**
     * ç§»é™¤ä¼šè¯
     * (Remove session)
     */
    public void removeSession(String sessionId) {
        activeSessions.remove(sessionId);
    }
}


