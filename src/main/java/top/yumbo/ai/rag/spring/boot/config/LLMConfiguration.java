package top.yumbo.ai.rag.spring.boot.config;

import lombok.extern.slf4j.Slf4j;
import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;
import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import top.yumbo.ai.rag.spring.boot.llm.LLMClient;
import top.yumbo.ai.rag.spring.boot.llm.MockLLMClient;
import top.yumbo.ai.rag.spring.boot.llm.OpenAILLMClient;

/**
 * LLM å®¢æˆ·ç«¯é…ç½®
 *
 * æ”¯æŒå¤šç§ LLM æä¾›å•†ï¼š
 * - openai: OpenAI å…¼å®¹ APIï¼ˆé»˜è®¤ï¼Œæ”¯æŒ OpenAIã€DeepSeek ç­‰ï¼‰
 * - mock: Mock æ¨¡å¼ï¼ˆæµ‹è¯•ç”¨ï¼Œè¿”å›žå›ºå®šå›žç­”ï¼‰
 *
 * OpenAI å…¼å®¹ API è¯´æ˜Žï¼š
 * OpenAILLMClient æ”¯æŒæ‰€æœ‰ OpenAI API å…¼å®¹çš„æœåŠ¡ï¼ŒåŒ…æ‹¬ï¼š
 * - OpenAI (GPT-4o, GPT-4, GPT-3.5)
 * - DeepSeek (deepseek-chat)
 * - å…¶ä»–å…¼å®¹ OpenAI API æ ¼å¼çš„æœåŠ¡
 *
 * é€šè¿‡é…ç½®ä¸åŒçš„ api-url å’Œ model å³å¯åˆ‡æ¢ä¸åŒçš„æœåŠ¡
 *
 * @author AI Reviewer Team
 * @since 2025-11-23
 */
@Slf4j
@Configuration
public class LLMConfiguration {

    private final KnowledgeQAProperties properties;

    public LLMConfiguration(KnowledgeQAProperties properties) {
        this.properties = properties;
    }

    /**
     * OpenAI å…¼å®¹ LLM å®¢æˆ·ç«¯ï¼ˆé»˜è®¤ï¼‰
     * æ”¯æŒ OpenAIã€DeepSeek ç­‰æ‰€æœ‰ OpenAI API å…¼å®¹çš„æœåŠ¡
     */
    @Bean
    @ConditionalOnProperty(
        prefix = "knowledge.qa.llm",
        name = "provider",
        havingValue = "openai",
        matchIfMissing = true  // é»˜è®¤ä½¿ç”¨ openaiï¼ˆæ”¯æŒæ‰€æœ‰å…¼å®¹ APIï¼‰
    )
    @ConditionalOnMissingBean
    public LLMClient openAILLMClient() {
        String apiKey = resolveEnvVariable(properties.getLlm().getApiKey());
        String model = properties.getLlm().getModel();
        String apiUrl = properties.getLlm().getApiUrl();

        if (apiKey == null || apiKey.isEmpty()) {
            log.warn("âš ï¸  æœªé…ç½® LLM API Key");
            log.warn("ðŸ’¡ æç¤º: è®¾ç½®çŽ¯å¢ƒå˜é‡:");
            log.warn("      - DeepSeek: export AI_API_KEY=your-deepseek-key");
            log.warn("      - OpenAI: export OPENAI_API_KEY=your-openai-key");
            log.warn("ðŸ’¡ å°†é™çº§ä½¿ç”¨ Mock æ¨¡å¼");
            return new MockLLMClient();
        }

        // æ ¹æ® API URL åˆ¤æ–­ä½¿ç”¨çš„æœåŠ¡
        String serviceName = "OpenAI";
        if (apiUrl != null && apiUrl.contains("deepseek")) {
            serviceName = "DeepSeek";
        }

        log.info("ðŸ¤– åˆ›å»º {} LLM å®¢æˆ·ç«¯", serviceName);
        log.info("   - æ¨¡åž‹: {}", model);
        log.info("   - API: {}", apiUrl);

        return new OpenAILLMClient(apiKey, model, apiUrl);
    }

    /**
     * Mock LLM å®¢æˆ·ç«¯ï¼ˆæµ‹è¯•ç”¨ï¼‰
     */
    @Bean
    @ConditionalOnProperty(
        prefix = "knowledge.qa.llm",
        name = "provider",
        havingValue = "mock"
    )
    @ConditionalOnMissingBean
    public LLMClient mockLLMClient() {
        log.info("ðŸ¤– åˆ›å»º Mock LLM å®¢æˆ·ç«¯ï¼ˆä»…ç”¨äºŽæµ‹è¯•ï¼‰");
        log.info("   âš ï¸  Mock æ¨¡å¼å°†è¿”å›žå›ºå®šçš„æ¨¡æ‹Ÿå›žç­”");
        log.info("   ðŸ’¡ å¦‚éœ€ä½¿ç”¨çœŸå®ž LLMï¼Œè¯·é…ç½®:");
        log.info("      knowledge.qa.llm.provider=openai");
        log.info("      å¹¶è®¾ç½®ç›¸åº”çš„ API Key å’Œ URL");
        return new MockLLMClient();
    }

    /**
     * è§£æžçŽ¯å¢ƒå˜é‡å ä½ç¬¦
     */
    private String resolveEnvVariable(String value) {
        if (value == null || value.isEmpty()) {
            return null;
        }

        // å¤„ç† ${VAR:default} æ ¼å¼
        if (value.startsWith("${") && value.endsWith("}")) {
            String content = value.substring(2, value.length() - 1);
            String[] parts = content.split(":", 2);
            String envVar = parts[0];
            String defaultValue = parts.length > 1 ? parts[1] : "";

            String envValue = System.getenv(envVar);
            return envValue != null && !envValue.isEmpty() ? envValue : defaultValue;
        }

        return value;
    }
}

