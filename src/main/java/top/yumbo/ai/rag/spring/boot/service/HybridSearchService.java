package top.yumbo.ai.rag.spring.boot.service;

import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import top.yumbo.ai.rag.service.LocalFileRAG;
import top.yumbo.ai.rag.spring.boot.config.KnowledgeQAProperties;
import top.yumbo.ai.rag.impl.embedding.LocalEmbeddingEngine;
import top.yumbo.ai.rag.impl.index.SimpleVectorIndexEngine;
import top.yumbo.ai.rag.model.Document;
import top.yumbo.ai.rag.model.Query;
import top.yumbo.ai.rag.model.SearchResult;
import top.yumbo.ai.rag.model.ScoredDocument;
import top.yumbo.ai.rag.i18n.I18N;
import top.yumbo.ai.rag.feedback.DocumentWeightService;

import java.util.*;
import java.util.stream.Collectors;

/**
 * æ··åˆæ£€ç´¢æœåŠ¡ï¼ˆHybrid search serviceï¼‰
 * ç»“åˆ Lucene å…³é”®è¯æ£€ç´¢å’Œå‘é‡è¯­ä¹‰æ£€ç´¢ï¼ˆCombines Lucene keyword search and vector semantic searchï¼‰
 *
 * ğŸ“ˆ ä¼˜åŒ–ï¼ˆ2025-12-05ï¼‰ï¼šé›†æˆæŸ¥è¯¢æ‰©å±•æœåŠ¡ï¼Œæå‡å¬å›ç‡
 * ğŸ“ˆ ä¼˜åŒ–ï¼ˆ2025-12-07ï¼‰ï¼šé›†æˆæ–‡æ¡£æƒé‡æœåŠ¡ï¼Œåé¦ˆå½±å“æ£€ç´¢æ’åº
 *
 * @author AI Reviewer Team
 * @since 2025-11-22
 */
@Slf4j
@Service
public class HybridSearchService {

    private final KnowledgeQAProperties properties;
    private final SearchConfigService configService;
    private final QueryExpansionService queryExpansionService;
    private final DocumentWeightService documentWeightService;

    @Autowired
    public HybridSearchService(KnowledgeQAProperties properties,
                               SearchConfigService configService,
                               @Autowired(required = false) QueryExpansionService queryExpansionService,
                               @Autowired(required = false) DocumentWeightService documentWeightService) {
        this.properties = properties;
        this.configService = configService;
        this.queryExpansionService = queryExpansionService;
        this.documentWeightService = documentWeightService;
    }

    /**
     * æ··åˆæ£€ç´¢ï¼šç»“åˆ Lucene å…³é”®è¯æ£€ç´¢å’Œå‘é‡è¯­ä¹‰æ£€ç´¢ï¼ˆHybrid search: combines Lucene keyword search and vector semantic searchï¼‰
     *
     * @param question æŸ¥è¯¢é—®é¢˜ï¼ˆQuery questionï¼‰
     * @param rag RAG å®ä¾‹ï¼ˆRAG instanceï¼‰
     * @param embeddingEngine åµŒå…¥å¼•æ“ï¼ˆEmbedding engineï¼‰
     * @param vectorIndexEngine å‘é‡ç´¢å¼•å¼•æ“ï¼ˆVector index engineï¼‰
     * @return æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨ï¼ˆRetrieved document listï¼‰
     */
    public List<Document> hybridSearch(String question, LocalFileRAG rag,
                                      LocalEmbeddingEngine embeddingEngine,
                                      SimpleVectorIndexEngine vectorIndexEngine) {
        try {
            long startTime = System.currentTimeMillis();

            // 0. æŸ¥è¯¢æ‰©å±•ï¼ˆä¼˜åŒ–ï¼šæå‡å¬å›ç‡ï¼‰
            String expandedQuestion = expandQueryIfEnabled(question);

            // 1. Lucene å…³é”®è¯æ£€ç´¢ï¼ˆå¿«é€Ÿç²—ç­›ï¼‰
            String keywords = extractKeywords(expandedQuestion);
            log.info(I18N.get("log.hybrid.extract_keywords", keywords));

            int luceneLimit = configService.getLuceneTopK();
            SearchResult luceneResult = rag.search(Query.builder()
                .queryText(keywords)
                .limit(luceneLimit)
                .build());

            log.info(I18N.get("log.hybrid.lucene_found", luceneResult.getDocuments().size(), luceneResult.getTotalHits(), luceneLimit));

            // æ˜¾ç¤º Lucene Top-10ï¼ˆå¸¦è¯„åˆ†ï¼‰
            if (!luceneResult.getDocuments().isEmpty()) {
                log.info(I18N.get("log.hybrid.lucene_top_header"));
                List<Document> luceneDocs = luceneResult.getDocuments().stream()
                    .map(ScoredDocument::getDocument)
                    .toList();
                // ä»é…ç½®è·å–æ—¥å¿—æ˜¾ç¤ºæ•°é‡ (Get log display limit from config)
                int logLimit = properties.getVectorSearch().getLogDisplayLimit();
                for (int i = 0; i < Math.min(logLimit, luceneDocs.size()); i++) {
                    Document doc = luceneDocs.get(i);
                    double normalizedScore = 1.0 - (i * 1.0 / luceneDocs.size());
                    log.info(I18N.get("log.hybrid.lucene_top_item", i + 1, doc.getTitle(), doc.getContent().length(), normalizedScore));
                }
            }

            // 2. å‘é‡æ£€ç´¢ï¼ˆè¯­ä¹‰ç²¾æ’ï¼‰(Step 2: Vector search for semantic refinement)
            float[] queryVector = embeddingEngine.embed(question);
            float threshold = properties.getVectorSearch().getSimilarityThreshold();
            int vectorLimit = configService.getVectorTopK();

            List<SimpleVectorIndexEngine.VectorSearchResult> vectorResults =
                vectorIndexEngine.search(queryVector, vectorLimit, threshold);

            log.info(I18N.get("log.hybrid.vector_found", vectorResults.size(), vectorLimit));

            if (!vectorResults.isEmpty()) {
                log.info(I18N.get("log.hybrid.vector_top_header"));
                int logLimit = properties.getVectorSearch().getLogDisplayLimit();
                vectorResults.stream().limit(logLimit).forEach(result -> {
                    Document doc = rag.getDocument(result.getDocId());
                    if (doc != null) {
                        log.info(I18N.get("log.hybrid.vector_top_item", doc.getTitle(), result.getSimilarity()));
                    }
                });
            }

            // 3. æ··åˆè¯„åˆ†ï¼šèåˆä¸¤ç§æ£€ç´¢ç»“æœ
            Map<String, Double> hybridScores = new HashMap<>();

            // ä»é…ç½®è·å–æƒé‡ï¼ˆLucene and vector weights from configurationï¼‰
            double luceneWeight = properties.getVectorSearch().getLuceneWeight();
            double vectorWeight = properties.getVectorSearch().getVectorWeight();

            // Lucene ç»“æœï¼ˆä½¿ç”¨é…ç½®çš„æƒé‡ï¼‰
            List<Document> luceneDocs = luceneResult.getDocuments().stream()
                .map(ScoredDocument::getDocument)
                .toList();
            for (int i = 0; i < luceneDocs.size(); i++) {
                String docId = luceneDocs.get(i).getId();
                double normalizedScore = 1.0 - (i * 1.0 / luceneDocs.size());
                hybridScores.put(docId, luceneWeight * normalizedScore);
            }

            // å‘é‡ç»“æœï¼ˆä½¿ç”¨é…ç½®çš„æƒé‡ï¼‰
            for (SimpleVectorIndexEngine.VectorSearchResult result : vectorResults) {
                String docId = result.getDocId();
                double currentScore = hybridScores.getOrDefault(docId, 0.0);
                hybridScores.put(docId, currentScore + vectorWeight * result.getSimilarity());
            }

            // 3.5 åº”ç”¨æ–‡æ¡£åé¦ˆæƒé‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            // (Apply document feedback weights if enabled)
            if (documentWeightService != null) {
                int adjustedCount = 0;
                for (Map.Entry<String, Double> entry : hybridScores.entrySet()) {
                    Document doc = rag.getDocument(entry.getKey());
                    if (doc != null) {
                        double feedbackWeight = documentWeightService.getDocumentWeight(doc.getTitle());
                        if (feedbackWeight != 1.0) {
                            double originalScore = entry.getValue();
                            double adjustedScore = originalScore * feedbackWeight;
                            hybridScores.put(entry.getKey(), adjustedScore);
                            adjustedCount++;
                            log.debug(I18N.get("log.hybrid.feedback_weight_detail",
                                doc.getTitle(),
                                String.format("%.3f", originalScore),
                                String.format("%.2f", feedbackWeight),
                                String.format("%.3f", adjustedScore)));
                        }
                    }
                }
                if (adjustedCount > 0) {
                    log.info(I18N.get("log.hybrid.feedback_weight_applied", adjustedCount));
                }
            }

            // 4. æŒ‰æ··åˆåˆ†æ•°æ’åºå¹¶å»é‡ (Sort by hybrid score and deduplicate)
            int topK = configService.getHybridTopK();
            float minScore = configService.getMinScoreThreshold();

            List<Map.Entry<String, Double>> allSortedScores = hybridScores.entrySet().stream()
                .sorted((a, b) -> Double.compare(b.getValue(), a.getValue()))
                .toList();

            if (!allSortedScores.isEmpty()) {
                log.info(I18N.get("log.hybrid.top5_header", minScore, topK));
                for (int i = 0; i < Math.min(5, allSortedScores.size()); i++) {
                    var entry = allSortedScores.get(i);
                    Document doc = rag.getDocument(entry.getKey());
                    if (doc != null) {
                        String status = entry.getValue() >= minScore ? "âœ…" : "âŒ";
                        log.info(I18N.get("log.hybrid.top5_item", status, i + 1, doc.getTitle(), entry.getValue()));
                    }
                }
            }

            List<Map.Entry<String, Double>> sortedScores = allSortedScores.stream()
                .filter(entry -> entry.getValue() >= minScore)
                .limit(topK)
                .toList();

            if (sortedScores.size() < hybridScores.size()) {
                log.warn(I18N.get("log.hybrid.filtered", hybridScores.size() - sortedScores.size(), minScore, sortedScores.size()));
            }

            log.info(I18N.get("log.hybrid.topk_header", sortedScores.size()));
            int displayCount = 0;
            int logLimit = properties.getVectorSearch().getLogDisplayLimit();
            for (int i = 0; i < Math.min(sortedScores.size(), logLimit * 2); i++) {
                var entry = sortedScores.get(i);
                Document doc = rag.getDocument(entry.getKey());
                if (doc != null) {
                    int luceneRank = -1;
                    for (int j = 0; j < luceneDocs.size(); j++) {
                        if (luceneDocs.get(j).getId().equals(entry.getKey())) {
                            luceneRank = j + 1;
                            break;
                        }
                    }

                    double vectorScore = 0.0;
                    for (SimpleVectorIndexEngine.VectorSearchResult result : vectorResults) {
                        if (result.getDocId().equals(entry.getKey())) {
                            vectorScore = result.getSimilarity();
                            break;
                        }
                    }

                    log.info(I18N.get("log.hybrid.detail_item", i + 1, doc.getTitle(), String.format("%.3f", entry.getValue()), luceneRank > 0 ? luceneRank : "N/A", String.format("%.3f", vectorScore)));
                    displayCount++;
                } else {
                    log.warn(I18N.get("log.hybrid.could_not_get_doc", i + 1, entry.getKey(), String.format("%.3f", entry.getValue())));
                }
            }

            if (displayCount == 0 && !sortedScores.isEmpty()) {
                log.error(I18N.get("log.hybrid.severe_no_docs", sortedScores.size()));
                log.error(I18N.get("log.hybrid.doc_id_list", sortedScores.stream().limit(5).map(Map.Entry::getKey).collect(Collectors.joining(", "))));
            }

            // 5. ä» RAG è·å–å®Œæ•´æ–‡æ¡£ï¼Œå¹¶ä¿å­˜æ£€ç´¢åˆ†æ•°
            // (Get full documents from RAG and save retrieval scores)
            List<Document> finalDocs = new ArrayList<>();
            int nullCount = 0;
            for (var entry : sortedScores) {
                Document doc = rag.getDocument(entry.getKey());
                if (doc != null) {
                    // ä¿å­˜æ£€ç´¢åˆ†æ•°åˆ°æ–‡æ¡£ï¼Œä¾›åç»­ PPL Rerank ä½¿ç”¨
                    // (Save retrieval score to document for PPL Rerank)
                    doc.setScore(entry.getValue());
                    finalDocs.add(doc);
                } else {
                    nullCount++;
                    if (nullCount <= 3) { // åªè¾“å‡ºå‰3ä¸ªnullçš„è¯¦ç»†ä¿¡æ¯ (Only output first 3 nulls)
                        log.warn(I18N.get("log.hybrid.cannot_get_doc", entry.getKey(), String.format("%.3f", entry.getValue())));
                    }
                }
            }

            if (nullCount > 0) {
                log.warn(I18N.get("log.hybrid.total_nulls", nullCount, sortedScores.size()));
            }

            long elapsed = System.currentTimeMillis() - startTime;
            log.info(I18N.get("log.hybrid.completed", finalDocs.size(), elapsed));

            return finalDocs;

        } catch (Exception e) {
            log.error(I18N.get("log.hybrid.failed"), e);
            return fallbackToKeywordSearch(question, rag);
        }
    }

    /**
     * çº¯å…³é”®è¯æ£€ç´¢ï¼ˆå›é€€æ¨¡å¼ï¼‰ï¼ˆPure keyword search (fallback mode)ï¼‰
     */
    public List<Document> keywordSearch(String question, LocalFileRAG rag) {
        String keywords = extractKeywords(question);
        log.info(I18N.get("log.hybrid.keyword_search", keywords));

        SearchResult result = rag.search(Query.builder()
            .queryText(keywords)
            .limit(configService.getHybridTopK())
            .build());

        log.info(I18N.get("log.hybrid.found_docs", result.getDocuments().size()));
        return result.getDocuments().stream()
            .map(ScoredDocument::getDocument)
            .collect(Collectors.toList());
    }

    /**
     * å›é€€åˆ°å…³é”®è¯æ£€ç´¢ï¼ˆFallback to keyword searchï¼‰
     */
    private List<Document> fallbackToKeywordSearch(String question, LocalFileRAG rag) {
        String keywords = extractKeywords(question);
        SearchResult fallbackResult = rag.search(Query.builder()
            .queryText(keywords)
            .limit(configService.getHybridTopK())
            .build());
        return fallbackResult.getDocuments().stream()
            .map(ScoredDocument::getDocument)
            .collect(Collectors.toList());
    }

    /**
     * æå–å…³é”®è¯ï¼ˆExtract keywordsï¼‰
     *
     * æ”¯æŒä¸­è‹±æ–‡åœç”¨è¯è¿‡æ»¤ï¼Œé€šè¿‡ yml é…ç½®å¯è‡ªå®šä¹‰åœç”¨è¯åˆ—è¡¨
     */
    private String extractKeywords(String question) {
        // è·å–é…ç½®çš„åœç”¨è¯
        KnowledgeQAProperties.SearchConfig searchConfig = properties.getSearch();

        // å¦‚æœç¦ç”¨åœç”¨è¯è¿‡æ»¤ï¼Œç›´æ¥è¿”å›åŸæ–‡
        if (!searchConfig.isEnableStopWordsFilter()) {
            return question;
        }

        // åˆå¹¶ä¸­è‹±æ–‡åœç”¨è¯
        Set<String> stopWords = new HashSet<>();
        if (searchConfig.getChineseStopWords() != null) {
            stopWords.addAll(searchConfig.getChineseStopWords());
        }
        if (searchConfig.getEnglishStopWords() != null) {
            // è‹±æ–‡åœç”¨è¯è½¬å°å†™
            searchConfig.getEnglishStopWords().forEach(w -> stopWords.add(w.toLowerCase()));
        }

        int minLength = searchConfig.getMinKeywordLength();

        return Arrays.stream(question.split("\\s+"))
            .filter(word -> {
                String lowerWord = word.toLowerCase();
                // è¿‡æ»¤åœç”¨è¯å’Œè¿‡çŸ­çš„è¯
                return !stopWords.contains(word)
                    && !stopWords.contains(lowerWord)
                    && word.length() >= minLength;
            })
            .collect(Collectors.joining(" "));
    }

    /**
     * æŸ¥è¯¢æ‰©å±•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
     *
     * ğŸ“ˆ ä¼˜åŒ–ï¼ˆ2025-12-05ï¼‰ï¼šé€šè¿‡åŒä¹‰è¯æ‰©å±•æå‡å¬å›ç‡
     */
    private String expandQueryIfEnabled(String question) {
        if (queryExpansionService == null) {
            return question;
        }

        try {
            // ä½¿ç”¨ç®€å•æ‰©å±•ï¼ˆä¸è°ƒç”¨ LLMï¼Œé¿å…å»¶è¿Ÿï¼‰
            String expanded = queryExpansionService.simpleExpand(question);
            if (!expanded.equals(question)) {
                log.debug("ğŸ” æŸ¥è¯¢æ‰©å±•: {} -> {}", question, expanded);
            }
            return expanded;
        } catch (Exception e) {
            log.warn("âš ï¸ æŸ¥è¯¢æ‰©å±•å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢: {}", e.getMessage());
            return question;
        }
    }
}
