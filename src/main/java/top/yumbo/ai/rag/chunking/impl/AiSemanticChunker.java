package top.yumbo.ai.rag.chunking.impl;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import lombok.extern.slf4j.Slf4j;
import top.yumbo.ai.rag.chunking.ChunkingConfig;
import top.yumbo.ai.rag.chunking.DocumentChunk;
import top.yumbo.ai.rag.chunking.DocumentChunker;
import top.yumbo.ai.rag.spring.boot.llm.LLMClient;

import java.util.ArrayList;
import java.util.List;

/**
 * AI è¯­ä¹‰æ–‡æ¡£åˆ‡åˆ†å™¨
 * ä½¿ç”¨ AI æ¨¡å‹è¿›è¡Œæ™ºèƒ½è¯­ä¹‰åˆ‡åˆ†ï¼Œæ•ˆæœæœ€å¥½ä½†æˆæœ¬è¾ƒé«˜
 *
 * @author AI Reviewer Team
 * @since 2025-11-26
 */
@Slf4j
public class AiSemanticChunker implements DocumentChunker {

    private final ChunkingConfig config;
    private final LLMClient llmClient;
    private final ObjectMapper objectMapper;

    public AiSemanticChunker(ChunkingConfig config, LLMClient llmClient) {
        this.config = config;
        this.llmClient = llmClient;
        this.objectMapper = new ObjectMapper();
        config.validate();

        if (!config.getAiChunking().isEnabled()) {
            log.warn("AI chunking is not enabled in config, but AiSemanticChunker is being used");
        }
    }

    @Override
    public List<DocumentChunk> chunk(String content, String query) {
        if (content == null || content.isEmpty()) {
            return List.of();
        }

        // å¦‚æœå†…å®¹ä¸é•¿ï¼Œä¸éœ€è¦AIåˆ‡åˆ†
        if (content.length() <= config.getChunkSize()) {
            return List.of(DocumentChunk.builder()
                    .content(content)
                    .index(0)
                    .totalChunks(1)
                    .startPosition(0)
                    .endPosition(content.length())
                    .build());
        }

        try {
            log.info("ğŸ¤– Starting AI semantic chunking for {} chars", content.length());
            long startTime = System.currentTimeMillis();

            // æ„å»º Prompt
            String prompt = buildChunkingPrompt(content, query);

            // è°ƒç”¨ LLM
            String response = llmClient.generate(prompt);

            // è§£æå“åº”
            List<DocumentChunk> chunks = parseChunkingResponse(response, content);

            long duration = System.currentTimeMillis() - startTime;
            log.info("âœ… AI semantic chunking completed: {} chars -> {} chunks in {}ms",
                    content.length(), chunks.size(), duration);

            return chunks;

        } catch (Exception e) {
            log.error("âŒ AI semantic chunking failed, falling back to smart keyword chunking", e);
            // å¤±è´¥æ—¶é™çº§åˆ°æ™ºèƒ½å…³é”®è¯åˆ‡åˆ†
            return new SmartKeywordChunker(config).chunk(content, query);
        }
    }

    /**
     * æ„å»ºåˆ‡åˆ† Prompt
     */
    private String buildChunkingPrompt(String content, String query) {
        String promptTemplate = config.getAiChunking().getPrompt();
        int chunkSize = config.getChunkSize();

        // æ›¿æ¢å ä½ç¬¦
        String prompt = promptTemplate
                .replace("{chunk_size}", String.valueOf(chunkSize))
                .replace("{content}", truncateIfNeeded(content));

        // å¦‚æœæœ‰æŸ¥è¯¢ä¸Šä¸‹æ–‡ï¼Œæ·»åŠ åˆ° Prompt ä¸­
        if (query != null && !query.isEmpty()) {
            prompt = "ç”¨æˆ·é—®é¢˜ï¼š" + query + "\n\n" + prompt;
        }

        return prompt;
    }

    /**
     * å¦‚æœå†…å®¹å¤ªé•¿ï¼Œæˆªæ–­åˆ°åˆç†é•¿åº¦
     * AI åˆ‡åˆ†æœ¬èº«ä¹Ÿæœ‰ä¸Šä¸‹æ–‡é™åˆ¶
     */
    private String truncateIfNeeded(String content) {
        int maxLength = config.getChunkSize() * 10; // æœ€å¤šå¤„ç†10å€å—å¤§å°

        if (content.length() <= maxLength) {
            return content;
        }

        log.warn("Content too long ({} chars), truncating to {} chars for AI chunking",
                content.length(), maxLength);
        return content.substring(0, maxLength) + "\n\n[å†…å®¹è¿‡é•¿å·²æˆªæ–­...]";
    }

    /**
     * è§£æ AI è¿”å›çš„åˆ‡åˆ†ç»“æœ
     */
    private List<DocumentChunk> parseChunkingResponse(String response, String originalContent) {
        try {
            // å°è¯•ä»å“åº”ä¸­æå– JSON
            String jsonContent = extractJson(response);

            // è§£æ JSON æ•°ç»„
            JsonNode root = objectMapper.readTree(jsonContent);

            if (!root.isArray()) {
                throw new IllegalArgumentException("Expected JSON array, got: " + root.getNodeType());
            }

            List<DocumentChunk> chunks = new ArrayList<>();
            int totalChunks = root.size();

            for (int i = 0; i < totalChunks; i++) {
                JsonNode chunkNode = root.get(i);

                String content = chunkNode.has("content")
                        ? chunkNode.get("content").asText()
                        : "";

                String title = chunkNode.has("title")
                        ? chunkNode.get("title").asText()
                        : null;

                if (!content.isEmpty()) {
                    // åœ¨åŸæ–‡ä¸­æŸ¥æ‰¾ä½ç½®
                    int startPos = originalContent.indexOf(content.substring(0, Math.min(100, content.length())));
                    int endPos = startPos + content.length();

                    chunks.add(DocumentChunk.builder()
                            .content(content)
                            .title(title)
                            .index(i)
                            .totalChunks(totalChunks)
                            .startPosition(Math.max(0, startPos))
                            .endPosition(Math.min(originalContent.length(), endPos))
                            .metadata("ai_semantic")
                            .build());
                }
            }

            if (chunks.isEmpty()) {
                throw new IllegalArgumentException("No valid chunks found in AI response");
            }

            return chunks;

        } catch (Exception e) {
            log.error("Failed to parse AI chunking response: {}", e.getMessage());
            throw new RuntimeException("Failed to parse AI chunking response", e);
        }
    }

    /**
     * ä»å“åº”ä¸­æå– JSON
     * AI å¯èƒ½è¿”å›å¸¦æœ‰è§£é‡Šæ–‡å­—çš„å“åº”ï¼Œéœ€è¦æå–çº¯ JSON éƒ¨åˆ†
     */
    private String extractJson(String response) {
        // å°è¯•æ‰¾åˆ° JSON æ•°ç»„çš„å¼€å§‹å’Œç»“æŸ
        int start = response.indexOf('[');
        int end = response.lastIndexOf(']');

        if (start == -1 || end == -1 || start >= end) {
            // å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯• JSON å¯¹è±¡æ ¼å¼
            start = response.indexOf('{');
            end = response.lastIndexOf('}');

            if (start == -1 || end == -1 || start >= end) {
                throw new IllegalArgumentException("No valid JSON found in response");
            }
        }

        return response.substring(start, end + 1);
    }

    @Override
    public String getName() {
        return "AI Semantic Chunker";
    }

    @Override
    public String getDescription() {
        return "ä½¿ç”¨AIæ¨¡å‹æ™ºèƒ½è¯­ä¹‰åˆ‡åˆ†ï¼Œæ•ˆæœæœ€å¥½";
    }
}

