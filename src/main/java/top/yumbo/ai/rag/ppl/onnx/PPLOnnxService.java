package top.yumbo.ai.rag.ppl.onnx;

import ai.djl.huggingface.tokenizers.Encoding;
import ai.djl.huggingface.tokenizers.HuggingFaceTokenizer;
import ai.onnxruntime.*;
import com.github.benmanes.caffeine.cache.Cache;
import com.github.benmanes.caffeine.cache.Caffeine;
import lombok.extern.slf4j.Slf4j;
import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
import top.yumbo.ai.rag.chunking.DocumentChunk;
import top.yumbo.ai.rag.model.Document;
import top.yumbo.ai.rag.ppl.PPLException;
import top.yumbo.ai.rag.ppl.PPLMetrics;
import top.yumbo.ai.rag.ppl.PPLProviderType;
import top.yumbo.ai.rag.ppl.PPLService;
import top.yumbo.ai.rag.ppl.config.ChunkConfig;
import top.yumbo.ai.rag.ppl.config.PPLConfig;
import top.yumbo.ai.rag.ppl.config.RerankConfig;

import jakarta.annotation.PostConstruct;
import jakarta.annotation.PreDestroy;
import java.nio.file.Paths;
import java.time.Duration;
import java.util.*;
import java.util.stream.Collectors;

/**
 * åŸºäº ONNX Runtime çš„ PPL æœåŠ¡å®ç°
 *
 * ç‰¹ç‚¹ï¼š
 * - æœ¬åœ°åµŒå…¥å¼æ¨ç†ï¼Œæ— ç½‘ç»œå¼€é”€
 * - é€Ÿåº¦å¿«ï¼ˆ30-150msï¼‰
 * - æˆæœ¬ä½ï¼ˆå®Œå…¨å…è´¹ï¼‰
 * - æ”¯æŒ GPU åŠ é€Ÿ
 *
 * @author AI Reviewer Team
 * @since 2025-12-04
 */
@Slf4j
@ConditionalOnProperty(prefix = "knowledge.qa.ppl.onnx", name = "enabled", havingValue = "true", matchIfMissing = true)
public class PPLOnnxService implements PPLService {

    private final PPLConfig config;
    private final PPLMetrics metrics;

    // ONNX Runtime ç»„ä»¶
    private OrtEnvironment env;
    private OrtSession session;
    private HuggingFaceTokenizer tokenizer;

    // PPL ç¼“å­˜
    private Cache<String, Double> pplCache;

    public PPLOnnxService(PPLConfig config) {
        this.config = config;
        this.metrics = new PPLMetrics();
    }

    @PostConstruct
    public void init() {
        log.info("ğŸš€ Initializing ONNX PPL Service...");

        try {
            PPLConfig.OnnxConfig onnxConfig = config.getOnnx();

            log.info("ğŸ“¦ Model path: {}", onnxConfig.getModelPath());
            log.info("ğŸ“¦ Tokenizer path: {}", onnxConfig.getTokenizerPath());

            // 1. åˆå§‹åŒ– ONNX Runtime ç¯å¢ƒ
            this.env = OrtEnvironment.getEnvironment();
            log.info("âœ… ONNX Runtime environment created");

            // 2. åŠ è½½ ONNX æ¨¡å‹
            OrtSession.SessionOptions sessionOptions = new OrtSession.SessionOptions();
            sessionOptions.setOptimizationLevel(OrtSession.SessionOptions.OptLevel.BASIC_OPT);

            this.session = env.createSession(onnxConfig.getModelPath(), sessionOptions);
            log.info("âœ… ONNX model loaded from: {}", onnxConfig.getModelPath());

            // 3. åŠ è½½ Tokenizer
            this.tokenizer = HuggingFaceTokenizer.newInstance(Paths.get(onnxConfig.getTokenizerPath()));
            log.info("âœ… Tokenizer loaded from: {}", onnxConfig.getTokenizerPath());

            // 4. åˆå§‹åŒ–ç¼“å­˜
            if (onnxConfig.isUseCache()) {
                this.pplCache = Caffeine.newBuilder()
                        .maximumSize(onnxConfig.getCacheSize())
                        .expireAfterWrite(Duration.ofSeconds(onnxConfig.getCacheTtl()))
                        .recordStats()
                        .build();
                log.info("âœ… PPL cache initialized (size: {}, TTL: {}s)",
                        onnxConfig.getCacheSize(), onnxConfig.getCacheTtl());
            }

            log.info("âœ… ONNX PPL Service initialized successfully");

        } catch (Exception e) {
            log.error("âŒ Failed to initialize ONNX PPL Service", e);
            throw new RuntimeException("ONNX initialization failed", e);
        }
    }

    @Override
    public double calculatePerplexity(String text) throws PPLException {
        if (text == null || text.trim().isEmpty()) {
            return Double.MAX_VALUE;
        }

        // æ£€æŸ¥ç¼“å­˜
        if (pplCache != null) {
            Double cached = pplCache.getIfPresent(text);
            if (cached != null) {
                metrics.recordCacheHit();
                return cached;
            }
            metrics.recordCacheMiss();
        }

        long startTime = System.currentTimeMillis();

        try {
            // 1. Tokenize - å°†æ–‡æœ¬è½¬æ¢ä¸º Token IDs
            Encoding encoding = tokenizer.encode(text);
            long[] inputIds = encoding.getIds();
            long[] attentionMask = encoding.getAttentionMask();

            if (inputIds.length == 0) {
                return Double.MAX_VALUE;
            }

            // 2. å‡†å¤‡ ONNX è¾“å…¥
            Map<String, OnnxTensor> inputs = new HashMap<>();

            // å°† inputIds è½¬æ¢ä¸º [1, seq_len] çš„å¼ é‡
            long[][] inputIdsArray = new long[1][inputIds.length];
            inputIdsArray[0] = inputIds;

            long[][] attentionMaskArray = new long[1][attentionMask.length];
            attentionMaskArray[0] = attentionMask;

            OnnxTensor inputIdsTensor = OnnxTensor.createTensor(env, inputIdsArray);
            OnnxTensor attentionMaskTensor = OnnxTensor.createTensor(env, attentionMaskArray);

            inputs.put("input_ids", inputIdsTensor);
            inputs.put("attention_mask", attentionMaskTensor);

            // 3. æ¨¡å‹æ¨ç†
            try (OrtSession.Result results = session.run(inputs)) {
                // è·å– logitsï¼ˆæ¨¡å‹è¾“å‡ºï¼‰
                OnnxValue logitsValue = results.get(0);
                float[][][] logits = (float[][][]) logitsValue.getValue();

                // 4. è®¡ç®—å›°æƒ‘åº¦
                double totalLoss = 0.0;
                int validTokens = 0;

                // å¯¹æ¯ä¸ªä½ç½®è®¡ç®— cross-entropy loss
                for (int i = 0; i < inputIds.length - 1; i++) {
                    int targetId = (int) inputIds[i + 1];
                    float[] probs = logits[0][i];

                    // Softmax å½’ä¸€åŒ–
                    float maxLogit = Float.NEGATIVE_INFINITY;
                    for (float logit : probs) {
                        maxLogit = Math.max(maxLogit, logit);
                    }

                    double sumExp = 0.0;
                    for (float logit : probs) {
                        sumExp += Math.exp(logit - maxLogit);
                    }

                    double logProb = probs[targetId] - maxLogit - Math.log(sumExp);
                    totalLoss -= logProb;  // ç­‰ä»·äº += -logProb
                    validTokens++;
                }

                // PPL = exp(average loss)
                double ppl = validTokens > 0 ? Math.exp(totalLoss / validTokens) : Double.MAX_VALUE;

                // æ¸…ç†èµ„æº
                inputIdsTensor.close();
                attentionMaskTensor.close();

                // ç¼“å­˜ç»“æœ
                if (pplCache != null) {
                    pplCache.put(text, ppl);
                }

                metrics.recordSuccess(System.currentTimeMillis() - startTime);
                return ppl;
            }

        } catch (Exception e) {
            metrics.recordFailure(System.currentTimeMillis() - startTime);
            log.error("Failed to calculate perplexity for text: {}", text.substring(0, Math.min(50, text.length())), e);
            throw new PPLException(PPLProviderType.ONNX, "Failed to calculate perplexity", e);
        }
    }

    @Override
    public List<DocumentChunk> chunk(String content, String query, ChunkConfig config) throws PPLException {
        if (content == null || content.trim().isEmpty()) {
            return Collections.emptyList();
        }

        long startTime = System.currentTimeMillis();

        try {
            List<DocumentChunk> chunks = new ArrayList<>();

            // 1. åˆ†å¥ - æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²
            List<String> sentences = splitIntoSentences(content);

            if (sentences.isEmpty()) {
                return Collections.emptyList();
            }

            // 2. å¦‚æœå¯ç”¨ç²—åˆ†å—ï¼Œå…ˆæŒ‰æ®µè½ç²—åˆ†
            List<List<String>> coarseChunks = new ArrayList<>();
            if (config.isEnableCoarseChunking()) {
                coarseChunks = coarseChunk(sentences, config.getMaxChunkSize());
            } else {
                coarseChunks.add(sentences);
            }

            // 3. å¯¹æ¯ä¸ªç²—å—è¿›è¡Œ PPL ç²¾ç»†åˆ‡åˆ†
            int chunkIndex = 0;
            for (List<String> coarseChunk : coarseChunks) {
                List<DocumentChunk> fineChunks = pplBasedChunk(coarseChunk, config);

                // è®¾ç½®ç´¢å¼•
                for (DocumentChunk chunk : fineChunks) {
                    chunk.setIndex(chunkIndex++);
                }

                chunks.addAll(fineChunks);
            }

            metrics.recordSuccess(System.currentTimeMillis() - startTime);
            return chunks;

        } catch (Exception e) {
            metrics.recordFailure(System.currentTimeMillis() - startTime);
            throw new PPLException(PPLProviderType.ONNX, "Failed to chunk document", e);
        }
    }

    /**
     * åˆ†å¥ - æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²
     */
    private List<String> splitIntoSentences(String content) {
        List<String> sentences = new ArrayList<>();

        // æŒ‰ä¸­è‹±æ–‡å¥å·ã€é—®å·ã€æ„Ÿå¹å·åˆ†å‰²
        String[] parts = content.split("(?<=[ã€‚ï¼ï¼Ÿ.!?])\\s*");

        for (String part : parts) {
            if (!part.trim().isEmpty()) {
                sentences.add(part.trim());
            }
        }

        return sentences;
    }

    /**
     * ç²—åˆ†å— - è¯­ä¹‰æ„ŸçŸ¥çš„åˆ†å‰²ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
     *
     * æ”¹è¿›ç‚¹ï¼š
     * 1. åœ¨è¯­ä¹‰è¾¹ç•Œåˆ‡åˆ†ï¼Œè€Œä¸æ˜¯å›ºå®šå­—æ•°
     * 2. æ”¯æŒä¸Šä¸‹æ–‡é‡å ï¼Œé¿å…ä¿¡æ¯ä¸¢å¤±
     * 3. è½¯é™åˆ¶ + ç¡¬é™åˆ¶ï¼Œä¿è¯å—å¤§å°åœ¨åˆç†èŒƒå›´
     */
    private List<List<String>> coarseChunk(List<String> sentences, int maxChunkSize) {
        return semanticCoarseChunk(sentences, maxChunkSize, true, 2);
    }

    /**
     * è¯­ä¹‰æ„ŸçŸ¥çš„ç²—åˆ†å—
     *
     * @param sentences å¥å­åˆ—è¡¨
     * @param maxChunkSize æœ€å¤§å—å¤§å°
     * @param semanticAware æ˜¯å¦å¯ç”¨è¯­ä¹‰æ„ŸçŸ¥
     * @param overlapSentences é‡å å¥å­æ•°
     */
    private List<List<String>> semanticCoarseChunk(List<String> sentences,
            int maxChunkSize, boolean semanticAware, int overlapSentences) {

        List<List<String>> chunks = new ArrayList<>();
        List<String> currentChunk = new ArrayList<>();
        List<String> overlapBuffer = new ArrayList<>();  // é‡å ç¼“å†²åŒº
        int currentSize = 0;

        // ç›®æ ‡å¤§å°ä¸ºæœ€å¤§å¤§å°çš„ 60%ï¼Œè½¯é™åˆ¶
        int targetSize = (int) (maxChunkSize * 0.6);
        // ç¡¬æ€§ä¸Šé™ä¸ºæœ€å¤§å¤§å°çš„ 125%
        int hardLimit = (int) (maxChunkSize * 1.25);

        for (int i = 0; i < sentences.size(); i++) {
            String sentence = sentences.get(i);
            int sentenceLength = sentence.length();

            boolean shouldSplit = false;

            if (semanticAware) {
                // è¯­ä¹‰æ„ŸçŸ¥æ¨¡å¼ï¼šåˆ°è¾¾ç›®æ ‡å¤§å°åï¼Œåœ¨è¯­ä¹‰è¾¹ç•Œåˆ‡åˆ†
                String prevSentence = i > 0 ? sentences.get(i - 1) : null;
                boolean isSemanticBoundary = isSemanticBoundary(sentence, prevSentence);

                if (currentSize >= targetSize && isSemanticBoundary) {
                    shouldSplit = true;
                }
            }

            // ç¡¬æ€§ä¸Šé™ï¼šè¶…è¿‡åˆ™å¼ºåˆ¶åˆ‡åˆ†
            if (currentSize + sentenceLength > hardLimit && !currentChunk.isEmpty()) {
                shouldSplit = true;
            }

            if (shouldSplit && !currentChunk.isEmpty()) {
                // æ·»åŠ å½“å‰å—ï¼ˆåŒ…å«å‰ä¸€å—çš„å°¾éƒ¨ä½œä¸ºä¸Šä¸‹æ–‡ï¼‰
                List<String> chunkWithContext = new ArrayList<>();
                if (!overlapBuffer.isEmpty()) {
                    chunkWithContext.addAll(overlapBuffer);
                }
                chunkWithContext.addAll(currentChunk);
                chunks.add(chunkWithContext);

                // æ›´æ–°é‡å ç¼“å†²åŒºï¼ˆä¿ç•™æœ€å N ä¸ªå¥å­ï¼‰
                overlapBuffer.clear();
                if (overlapSentences > 0) {
                    int overlapStart = Math.max(0, currentChunk.size() - overlapSentences);
                    for (int j = overlapStart; j < currentChunk.size(); j++) {
                        overlapBuffer.add(currentChunk.get(j));
                    }
                }

                currentChunk.clear();
                currentSize = 0;
            }

            currentChunk.add(sentence);
            currentSize += sentenceLength;
        }

        // å¤„ç†æœ€åä¸€å—
        if (!currentChunk.isEmpty()) {
            List<String> chunkWithContext = new ArrayList<>();
            if (!overlapBuffer.isEmpty()) {
                chunkWithContext.addAll(overlapBuffer);
            }
            chunkWithContext.addAll(currentChunk);
            chunks.add(chunkWithContext);
        }

        return chunks;
    }

    /**
     * æ£€æµ‹è¯­ä¹‰è¾¹ç•Œ
     *
     * @param current å½“å‰å¥å­
     * @param previous å‰ä¸€å¥å­
     * @return æ˜¯å¦æ˜¯è¯­ä¹‰è¾¹ç•Œ
     */
    private boolean isSemanticBoundary(String current, String previous) {
        if (current == null || current.isEmpty()) {
            return false;
        }

        String trimmed = current.trim();

        // 1. ç« èŠ‚æ ‡é¢˜ï¼ˆä¸­æ–‡ï¼‰
        if (trimmed.matches("^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒé›¶\\d]+[ç« èŠ‚ç¯‡éƒ¨æ¡æ¬¾é¡¹].*")) {
            return true;
        }

        // 2. Markdown æ ‡é¢˜
        if (trimmed.matches("^#{1,6}\\s+.*")) {
            return true;
        }

        // 3. æ•°å­—ç¼–å·æ ‡é¢˜ï¼ˆå¦‚ "1. xxx", "1.1 xxx"ï¼‰
        if (trimmed.matches("^\\d+(\\.\\d+)*[.ã€\\s].*") && trimmed.length() < 100) {
            return true;
        }

        // 4. æ®µè½å¼€å¤´è¯ï¼ˆè¡¨ç¤ºæ–°ä¸»é¢˜ï¼‰
        if (trimmed.matches("^(é¦–å…ˆ|å…¶æ¬¡|å†æ¬¡|ç„¶å|æ¥ç€|æœ€å|å¦å¤–|æ­¤å¤–|" +
                "ç»¼ä¸Š|æ€»ä¹‹|å› æ­¤|æ‰€ä»¥|æ€»ç»“|ç»“è®º|æ¦‚è¿°|ç®€ä»‹|èƒŒæ™¯|ç›®çš„|" +
                "ä¸€æ–¹é¢|å¦ä¸€æ–¹é¢|ä¸æ­¤åŒæ—¶|éœ€è¦æ³¨æ„|å€¼å¾—ä¸€æ|ç‰¹åˆ«æ˜¯).*")) {
            return true;
        }

        // 5. å‰ä¸€å¥æ˜¯åˆ—è¡¨é¡¹ç»“å°¾ï¼Œå½“å‰ä¸æ˜¯åˆ—è¡¨é¡¹ï¼ˆåˆ—è¡¨ç»“æŸï¼‰
        if (previous != null) {
            boolean prevIsList = previous.trim().matches("^[\\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[.ã€ï¼‰)].*")
                    || previous.trim().matches("^[-*â€¢]\\s.*");
            boolean currIsList = trimmed.matches("^[\\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[.ã€ï¼‰)].*")
                    || trimmed.matches("^[-*â€¢]\\s.*");
            if (prevIsList && !currIsList) {
                return true;
            }
        }

        // 6. æ®µè½åˆ†éš”æ ‡è®°ï¼ˆå¦‚æœåœ¨åˆ†å¥æ—¶ä¿ç•™äº†ï¼‰
        if (trimmed.startsWith("[PARA]") || trimmed.startsWith("---") || trimmed.startsWith("***")) {
            return true;
        }

        return false;
    }

    /**
     * åŸºäº PPL çš„ç²¾ç»†åˆ‡åˆ†
     */
    private List<DocumentChunk> pplBasedChunk(List<String> sentences, ChunkConfig config) throws PPLException {
        List<DocumentChunk> chunks = new ArrayList<>();

        if (sentences.isEmpty()) {
            return chunks;
        }

        // è®¡ç®—æ¯ä¸ªå¥å­çš„ PPL
        List<Double> pplScores = new ArrayList<>();
        for (String sentence : sentences) {
            double ppl = calculatePerplexity(sentence);
            pplScores.add(ppl);
        }

        // æ‰¾åˆ° PPL çªå˜ç‚¹
        List<Integer> splitPoints = new ArrayList<>();
        splitPoints.add(0); // èµ·å§‹ç‚¹

        for (int i = 1; i < pplScores.size(); i++) {
            double currentPPL = pplScores.get(i);
            double prevPPL = pplScores.get(i - 1);

            // PPL å˜åŒ–è¶…è¿‡é˜ˆå€¼ï¼Œä¸”å½“å‰å—ä¸ä¸ºç©º
            if (Math.abs(currentPPL - prevPPL) > config.getPplThreshold()) {
                splitPoints.add(i);
            }
        }

        splitPoints.add(sentences.size()); // ç»“æŸç‚¹

        // æ ¹æ®åˆ‡åˆ†ç‚¹ç”Ÿæˆå—
        for (int i = 0; i < splitPoints.size() - 1; i++) {
            int start = splitPoints.get(i);
            int end = splitPoints.get(i + 1);

            StringBuilder chunkContent = new StringBuilder();
            for (int j = start; j < end; j++) {
                chunkContent.append(sentences.get(j));
                if (j < end - 1) {
                    chunkContent.append(" ");
                }
            }

            String content = chunkContent.toString();

            // åº”ç”¨å¤§å°é™åˆ¶
            if (content.length() >= config.getMinChunkSize() &&
                content.length() <= config.getMaxChunkSize()) {

                DocumentChunk chunk = DocumentChunk.builder()
                        .content(content)
                        .build();
                chunks.add(chunk);
            } else if (content.length() > config.getMaxChunkSize()) {
                // å¤ªå¤§ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†å‰²
                List<DocumentChunk> subChunks = splitLargeChunk(content, config);
                chunks.addAll(subChunks);
            } else if (content.length() < config.getMinChunkSize() && !chunks.isEmpty()) {
                // å¤ªå°ï¼Œåˆå¹¶åˆ°å‰ä¸€ä¸ªå—
                DocumentChunk lastChunk = chunks.getLast();
                lastChunk.setContent(lastChunk.getContent() + " " + content);
            } else if (!content.trim().isEmpty()) {
                // ç¬¬ä¸€ä¸ªå—ï¼Œå³ä½¿å°ä¹Ÿä¿ç•™
                DocumentChunk chunk = DocumentChunk.builder()
                        .content(content)
                        .build();
                chunks.add(chunk);
            }
        }

        return chunks;
    }

    /**
     * åˆ†å‰²è¿‡å¤§çš„å—
     */
    private List<DocumentChunk> splitLargeChunk(String content, ChunkConfig config) {
        List<DocumentChunk> chunks = new ArrayList<>();
        int maxSize = config.getMaxChunkSize();
        int overlapSize = config.getOverlapSize();

        for (int i = 0; i < content.length(); i += maxSize - overlapSize) {
            int end = Math.min(i + maxSize, content.length());
            String chunkContent = content.substring(i, end);

            DocumentChunk chunk = DocumentChunk.builder()
                    .content(chunkContent)
                    .build();
            chunks.add(chunk);

            if (end >= content.length()) {
                break;
            }
        }

        return chunks;
    }

    @Override
    public List<Document> rerank(String question, List<Document> candidates, RerankConfig config) throws PPLException {
        if (candidates == null || candidates.isEmpty()) {
            return candidates;
        }

        long startTime = System.currentTimeMillis();

        try {
            // 1. é€‰æ‹©å‰ K ä¸ªæ–‡æ¡£è¿›è¡Œé‡æ’åº
            int topK = Math.min(config.getTopK(), candidates.size());
            List<Document> toRerank = candidates.subList(0, topK);
            List<Document> remaining = candidates.subList(topK, candidates.size());

            // 2. è®¡ç®—æ¯ä¸ªæ–‡æ¡£çš„ PPL åˆ†æ•°
            List<DocumentWithScore> scoredDocs = new ArrayList<>();

            for (Document doc : toRerank) {
                String content = doc.getContent();

                // æˆªæ–­å†…å®¹ä»¥æ§åˆ¶æˆæœ¬
                if (content.length() > config.getContentTruncateLength()) {
                    content = content.substring(0, config.getContentTruncateLength());
                }

                // è®¡ç®— PPL
                double ppl = calculatePerplexity(content);

                // PPL è½¬æ¢ä¸ºåˆ†æ•°ï¼šåˆ†æ•°è¶Šé«˜è¶Šå¥½ï¼ŒPPL è¶Šä½è¶Šå¥½
                double pplScore = 1.0 / (1.0 + ppl);

                // è·å–åŸå§‹åˆ†æ•°ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                double originalScore = 1.0; // é»˜è®¤åˆ†æ•°

                // æ··åˆè¯„åˆ†ï¼šfinal = (1-weight) * original + weight * ppl_score
                double weight = config.getWeight();
                double finalScore = (1 - weight) * originalScore + weight * pplScore;

                scoredDocs.add(new DocumentWithScore(doc, finalScore));
            }

            // 3. é‡æ–°æ’åº
            scoredDocs.sort((a, b) -> Double.compare(b.score, a.score));

            // 4. åˆå¹¶ç»“æœ
            List<Document> reranked = scoredDocs.stream()
                    .map(ds -> ds.document)
                    .collect(Collectors.toList());
            reranked.addAll(remaining);

            metrics.recordSuccess(System.currentTimeMillis() - startTime);
            return reranked;

        } catch (Exception e) {
            metrics.recordFailure(System.currentTimeMillis() - startTime);
            throw new PPLException(PPLProviderType.ONNX, "Failed to rerank documents", e);
        }
    }

    /**
     * æ–‡æ¡£å’Œåˆ†æ•°çš„åŒ…è£…ç±»
     */
    private static class DocumentWithScore {
        final Document document;
        final double score;

        DocumentWithScore(Document document, double score) {
            this.document = document;
            this.score = score;
        }
    }

    @Override
    public PPLProviderType getProviderType() {
        return PPLProviderType.ONNX;
    }

    @Override
    public boolean isHealthy() {
        try {
            // æ£€æŸ¥å…³é”®ç»„ä»¶æ˜¯å¦å·²åˆå§‹åŒ–
            if (session == null || tokenizer == null) {
                return false;
            }

            // å°è¯•è®¡ç®—ä¸€ä¸ªç®€å•æ–‡æœ¬çš„ PPL
            String testText = "Hello";
            double ppl = calculatePerplexity(testText);

            // PPL åº”è¯¥æ˜¯ä¸€ä¸ªåˆç†çš„æ­£æ•°
            return ppl > 0 && ppl < 10000;

        } catch (Exception e) {
            log.warn("Health check failed", e);
            return false;
        }
    }

    @Override
    public PPLMetrics getMetrics() {
        return metrics;
    }

    @PreDestroy
    public void destroy() {
        log.info("ğŸ›‘ Shutting down ONNX PPL Service...");

        try {
            // é‡Šæ”¾ ONNX Session
            if (session != null) {
                session.close();
                log.info("âœ… ONNX session closed");
            }

            // å…³é—­ Tokenizer
            if (tokenizer != null) {
                tokenizer.close();
                log.info("âœ… Tokenizer closed");
            }

            // æ¸…ç†ç¼“å­˜
            if (pplCache != null) {
                pplCache.invalidateAll();
                log.info("âœ… PPL cache cleared");
            }

            log.info("âœ… ONNX PPL Service shut down successfully");

        } catch (Exception e) {
            log.error("Error during shutdown", e);
        }
    }
}

