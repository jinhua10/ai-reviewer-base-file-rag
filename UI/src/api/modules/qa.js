/**
 * é—®ç­” API æ¨¡å— (Q&A API Module)
 *
 * æä¾›æ™ºèƒ½é—®ç­”ç›¸å…³çš„ API æ¥å£
 * (Provides Q&A-related API interfaces)
 *
 * @author AI Reviewer Team
 * @since 2025-12-12
 */

import { request } from '../index'

const qaApi = {
  /**
   * æé—® (Ask question)
   * @param {Object} params - é—®é¢˜å‚æ•°
   * @param {string} params.question - é—®é¢˜å†…å®¹
   * @param {string} params.hopeSessionId - HOPE ä¼šè¯ IDï¼ˆå¯é€‰ï¼‰
   * @param {boolean} params.useKnowledgeBase - æ˜¯å¦ä½¿ç”¨çŸ¥è¯†åº“ RAGï¼ˆå¯é€‰ï¼Œé»˜è®¤ trueï¼‰
   * @returns {Promise} å›ç­”ç»“æœ
   */
  ask(params) {
    return request.post('/qa/ask', {
      ...params,
      useKnowledgeBase: params.useKnowledgeBase !== undefined ? params.useKnowledgeBase : true
    })
  },

  /**
   * ä½¿ç”¨æŒ‡å®šæ–‡æ¡£æ‰¹æ¬¡è¿›è¡Œé—®ç­” (Ask with specific documents)
   * @param {Object} params - é—®é¢˜å‚æ•°
   * @param {string} params.question - é—®é¢˜å†…å®¹
   * @param {string} params.sessionId - ä¼šè¯ ID
   * @param {boolean} params.useKnowledgeBase - æ˜¯å¦ä½¿ç”¨çŸ¥è¯†åº“ RAGï¼ˆå¯é€‰ï¼Œé»˜è®¤ trueï¼‰
   * @returns {Promise} å›ç­”ç»“æœ
   */
  askWithSession(params) {
    return request.post('/qa/ask-with-session', {
      ...params,
      useKnowledgeBase: params.useKnowledgeBase !== undefined ? params.useKnowledgeBase : true
    })
  },

  /**
   * æµå¼é—®ç­” - åŒè½¨è¾“å‡º (Streaming Q&A - Dual Track)
   * 
   * æ¶æ„ï¼š
   * 1. POST /api/qa/stream â†’ è·å– sessionId å’Œ HOPE å¿«é€Ÿç­”æ¡ˆ
   * 2. EventSource è®¢é˜… /api/qa/stream/{sessionId} â†’ æ¥æ”¶ LLM æµå¼è¾“å‡º
   * 
   * Architecture:
   * 1. POST /api/qa/stream â†’ Get sessionId and HOPE fast answer
   * 2. EventSource subscribe /api/qa/stream/{sessionId} â†’ Receive LLM streaming output
   * 
   * @param {Object} params - é—®é¢˜å‚æ•° (Question parameters)
   * @param {string} params.question - é—®é¢˜å†…å®¹ (Question content)
   * @param {string} [params.userId] - ç”¨æˆ· ID (User ID, optional)
   * @param {Function} onChunk - æ•°æ®å—å›è°ƒ (Chunk callback)
   * @returns {Promise<{sessionId: string, eventSource: EventSource}>}
   */
  async askStreaming(params, onChunk) {
    try {
      // Step 1: å‘èµ·æµå¼é—®ç­”ï¼Œè·å– sessionId å’Œ HOPE å¿«é€Ÿç­”æ¡ˆ
      // (Step 1: Initiate streaming Q&A, get sessionId and HOPE fast answer)
      console.log('ğŸš€ Starting streaming Q&A:', params.question)
      
      const response = await request.post('/qa/stream', {
        question: params.question,
        userId: params.userId || 'anonymous',
        useKnowledgeBase: params.useKnowledgeBase !== undefined ? params.useKnowledgeBase : true,
        knowledgeMode: params.knowledgeMode, // 'none' | 'rag' | 'role'
        roleName: params.roleName // è§’è‰²åç§°ï¼ˆå½“ knowledgeMode='role' æ—¶ï¼‰
      })

      console.log('ğŸ“¥ Received initial response:', response)

      const { sessionId, question, hopeAnswer, sseUrl } = response
      
      if (!sessionId || !sseUrl) {
        throw new Error('Invalid response: missing sessionId or sseUrl')
      }

      // Step 2: å¦‚æœ HOPE æœ‰å¿«é€Ÿç­”æ¡ˆï¼Œç«‹å³å‘é€
      // (Step 2: If HOPE has fast answer, send immediately)
      if (hopeAnswer && hopeAnswer.answer && onChunk) {
        onChunk({
          content: hopeAnswer.answer,
          done: false,
          type: 'hope',
          source: hopeAnswer.source,
          confidence: hopeAnswer.confidence,
          canDirectAnswer: hopeAnswer.canDirectAnswer,
          responseTime: hopeAnswer.responseTime
        })

        // å¦‚æœ HOPE èƒ½ç›´æ¥å›ç­”ï¼Œå¯èƒ½ä¸éœ€è¦ LLM
        // (If HOPE can directly answer, may not need LLM)
        if (hopeAnswer.canDirectAnswer) {
          // å‘é€å®Œæˆä¿¡å·
          // (Send completion signal)
          if (onChunk) {
            onChunk({
              content: '',
              done: true,
              sessionId,
              hopeAnswer: hopeAnswer.answer,
              source: hopeAnswer.source,
              type: 'complete'
            })
          }
          return { sessionId, eventSource: null }
        }
      }

      // Step 3: è®¢é˜… LLM æµå¼è¾“å‡ºï¼ˆSSEï¼‰
      // (Step 3: Subscribe to LLM streaming output via SSE)
      // EventSource éœ€è¦å®Œæ•´ URLï¼ˆåŒ…æ‹¬åè®®å’ŒåŸŸåï¼‰
      // sseUrl å·²åŒ…å« /api å‰ç¼€ï¼ˆå¦‚ /api/qa/stream/xxxï¼‰
      const eventSourceUrl = `${window.location.origin}${sseUrl}`
      const eventSource = new EventSource(eventSourceUrl)

      let fullLLMAnswer = ''
      let chunkCount = 0

      // ç›‘å¬ chunk äº‹ä»¶ï¼ˆHybridStreamingService ä½¿ç”¨ 'chunk' äº‹ä»¶åï¼‰
      // (Listen to chunk event from HybridStreamingService)
      eventSource.addEventListener('chunk', (event) => {
        try {
          const chunk = event.data // çº¯æ–‡æœ¬å—

          fullLLMAnswer += chunk
          chunkCount++

          console.log(`ğŸ“¦ Received chunk #${chunkCount}:`, chunk.substring(0, 50))

          if (onChunk) {
            onChunk({
              content: chunk,
              done: false,
              type: 'llm',
              chunkIndex: chunkCount
            })
          }
        } catch (error) {
          console.error('âŒ Failed to process chunk:', error)
        }
      })

      // ç›‘å¬ LLM æ–‡æœ¬å—äº‹ä»¶ï¼ˆStreamingQAController.dualTrackStreaming ä½¿ç”¨ 'llm' äº‹ä»¶åï¼‰
      // (Listen to LLM chunk events from dualTrackStreaming)
      eventSource.addEventListener('llm', (event) => {
        try {
          const message = JSON.parse(event.data)
          const chunk = message.content

          fullLLMAnswer += chunk
          chunkCount++

          console.log(`ğŸ“¦ Received LLM chunk #${chunkCount}:`, chunk.substring(0, 50))

          if (onChunk) {
            onChunk({
              content: chunk,
              done: false,
              type: 'llm',
              chunkIndex: message.chunkIndex
            })
          }
        } catch (error) {
          console.error('âŒ Failed to parse LLM chunk:', error, 'Data:', event.data)
        }
      })

      // ç›‘å¬å®Œæˆäº‹ä»¶
      // (Listen to complete event)
      eventSource.addEventListener('complete', (event) => {
        console.log('ğŸ“¢ Received complete event:', event.data)

        eventSource.close()

        // å…¼å®¹ä¸¤ç§æ ¼å¼ï¼šçº¯æ–‡æœ¬ "done" æˆ– JSON
        let totalChunks = chunkCount
        let totalTime = 0

        if (event.data !== 'done') {
          try {
            const message = JSON.parse(event.data)
            totalChunks = message.totalChunks || chunkCount
            totalTime = message.totalTime || 0
          } catch (error) {
            console.warn('âš ï¸ Complete message is not JSON, using fallback values')
          }
        }

        console.log(`âœ… LLM generation completed: ${totalChunks} chunks, ${totalTime}ms`)

        if (onChunk) {
          onChunk({
            content: '',
            done: true,
            type: 'complete',
            sessionId,
            hopeAnswer: hopeAnswer?.answer || null,
            llmAnswer: fullLLMAnswer,
            totalChunks,
            totalTime
          })
        }
      })

      // ç›‘å¬ HOPE äº‹ä»¶ï¼ˆdualTrackStreaming ä½¿ç”¨ï¼‰
      // (Listen to HOPE event from dualTrackStreaming)
      eventSource.addEventListener('hope', (event) => {
        try {
          const message = JSON.parse(event.data)
          console.log('ğŸ’¡ Received HOPE answer:', message)

          if (onChunk) {
            onChunk({
              content: message.content,
              done: false,
              type: 'hope',
              source: message.hopeSource,
              confidence: message.confidence
            })
          }
        } catch (error) {
          console.error('âŒ Failed to parse HOPE message:', error)
        }
      })

      // ç›‘å¬é”™è¯¯äº‹ä»¶
      // (Listen to error event)
      eventSource.addEventListener('error', (event) => {
        console.error('âŒ SSE error:', event)
        
        // åªåœ¨éæ­£å¸¸å…³é—­æ—¶æŠ¥é”™
        if (eventSource.readyState === EventSource.CLOSED) {
          console.log('ğŸ”Œ EventSource closed')
        } else if (eventSource.readyState === EventSource.CONNECTING) {
          console.log('ğŸ”„ EventSource reconnecting...')
        } else {
          eventSource.close()
          
          if (onChunk) {
            onChunk({
              content: '',
              done: true,
              type: 'error',
              error: 'SSE connection failed'
            })
          }
        }
      })

      // ç›‘å¬è¿æ¥æ‰“å¼€
      eventSource.addEventListener('open', () => {
        console.log('âœ… SSE connection opened:', eventSourceUrl)
      })

      // è¿”å› sessionId å’Œ eventSourceï¼ˆå…è®¸æ‰‹åŠ¨å…³é—­ï¼‰
      // (Return sessionId and eventSource for manual close)
      return { sessionId, eventSource }

    } catch (error) {
      console.error('âŒ Failed to ask streaming question:', error)
      throw error
    }
  },

  /**
   * è·å–é—®ç­”å†å² / Get Q&A history
   * @param {Object} params - æŸ¥è¯¢å‚æ•° / Query parameters
   * @param {number} params.page - é¡µç  / Page number
   * @param {number} params.pageSize - æ¯é¡µæ¡æ•° / Items per page
   * @returns {Promise} å†å²è®°å½• / History records
   */
  getHistory(params) {
    return request.get('/qa/history', params)
  },

  /**
   * è·å–ç›¸ä¼¼é—®é¢˜ / Get similar questions
   * @param {string} question - é—®é¢˜å†…å®¹ / Question content
   * @returns {Promise} ç›¸ä¼¼é—®é¢˜åˆ—è¡¨ / Similar questions list
   */
  getSimilarQuestions(question) {
    return request.get('/qa/similar', { question })
  },

  /**
   * åé¦ˆå›ç­”è´¨é‡ / Feedback answer quality
   * @param {Object} params - åé¦ˆå‚æ•° / Feedback parameters
   * @param {string} params.answerId - å›ç­” ID / Answer ID
   * @param {number} params.rating - è¯„åˆ†ï¼ˆ1-5ï¼‰/ Rating (1-5)
   * @param {string} params.comment - è¯„è®ºï¼ˆå¯é€‰ï¼‰/ Comment (optional)
   * @returns {Promise} åé¦ˆç»“æœ / Feedback result
   */
  feedback(params) {
    return request.post('/qa/feedback', params)
  },

  /**
   * è·å–æ¨èæç¤ºè¯ / Get recommended prompts
   * @returns {Promise} æ¨èæç¤ºè¯åˆ—è¡¨ / Recommended prompts list
   */
  getRecommendedPrompts() {
    return request.get('/qa/prompts/recommended')
  },
}

export default qaApi

