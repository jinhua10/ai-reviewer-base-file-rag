# PPL ONNX æœåŠ¡ KV Cache å…¼å®¹æ€§é—®é¢˜

> æ–‡æ¡£ç‰ˆæœ¬: v1.5  
> åˆ›å»ºæ—¥æœŸ: 2025-12-07  
> ä½œè€…: AI Reviewer Team

---

## âœ… é—®é¢˜å·²è§£å†³

**v1.5 æ›´æ–°ï¼ˆ2025-12-07ï¼‰ï¼šåŠ¨æ€æå– KV Cache ç»´åº¦ï¼**

ä¹‹å‰ç¡¬ç¼–ç äº† `numHeads=14`ï¼Œä½† Qwen æ¨¡å‹ä½¿ç”¨ GQAï¼ˆGrouped-Query Attentionï¼‰ï¼Œå®é™… `num_kv_heads=2`ã€‚

ç°åœ¨ä»æ¨¡å‹è¾“å…¥ä¿¡æ¯ä¸­ **åŠ¨æ€æå–** `numHeads` å’Œ `headDim`ï¼Œç¡®ä¿å…¼å®¹æ‰€æœ‰æ¨¡å‹é…ç½®ã€‚

---

## é—®é¢˜æ¦‚è¿°

### é”™è¯¯ç°è±¡

ä½¿ç”¨ ONNX æœ¬åœ°æ¨¡å‹ï¼ˆå¦‚ `qwen2.5-0.5b`ï¼‰è¿›è¡Œ PPLï¼ˆå›°æƒ‘åº¦ï¼‰è®¡ç®—æ—¶ï¼Œå‡ºç°ä»¥ä¸‹é”™è¯¯ï¼š

```
ai.onnxruntime.OrtException: Error code - ORT_RUNTIME_EXCEPTION
message: Non-zero status code returned while running Concat node. 
Name:'/model/layers.0/self_attn/Concat_5' 
Status Message: Missing Input: past_key_values.0.key
```

### æ ¹æœ¬åŸå› 

Qwen ç­‰ç°ä»£å¤§è¯­è¨€æ¨¡å‹çš„ ONNX å¯¼å‡ºç‰ˆæœ¬é€šå¸¸ä½¿ç”¨ **KV Cache** æœºåˆ¶æ¥åŠ é€Ÿè‡ªå›å½’æ¨ç†ã€‚è¿™æ„å‘³ç€æ¨¡å‹æœŸæœ›æ¥æ”¶ä»¥ä¸‹è¾“å…¥ï¼š

| è¾“å…¥åç§° | è¯´æ˜ | å¿…éœ€æ€§ |
|---------|------|--------|
| `input_ids` | Token ID åºåˆ— | âœ… å¿…éœ€ |
| `attention_mask` | æ³¨æ„åŠ›æ©ç  | âœ… å¿…éœ€ |
| `position_ids` | ä½ç½®ç¼–ç  | âœ… å¿…éœ€ |
| `past_key_values.{layer}.key` | æ¯å±‚çš„ Key ç¼“å­˜ | âš ï¸ KV Cache æ¨¡å‹å¿…éœ€ |
| `past_key_values.{layer}.value` | æ¯å±‚çš„ Value ç¼“å­˜ | âš ï¸ KV Cache æ¨¡å‹å¿…éœ€ |

å½“å‰ä»£ç åªæä¾›äº†å‰ä¸‰ä¸ªè¾“å…¥ï¼Œç¼ºå°‘ `past_key_values` ç›¸å…³è¾“å…¥ã€‚

---

## æŠ€æœ¯èƒŒæ™¯

### ä»€ä¹ˆæ˜¯ KV Cacheï¼Ÿ

KV Cacheï¼ˆKey-Value Cacheï¼‰æ˜¯ Transformer æ¨¡å‹è‡ªå›å½’æ¨ç†æ—¶çš„ä¸€ç§ä¼˜åŒ–æŠ€æœ¯ï¼š

```
ä¼ ç»Ÿæ¨ç†ï¼ˆæ—  KV Cacheï¼‰:
  æ¯æ¬¡ç”Ÿæˆæ–° token æ—¶ï¼Œé‡æ–°è®¡ç®—æ‰€æœ‰ä½ç½®çš„ Key å’Œ Value
  æ—¶é—´å¤æ‚åº¦: O(nÂ²)

KV Cache æ¨ç†:
  ç¼“å­˜å·²è®¡ç®—çš„ Key å’Œ Valueï¼Œåªè®¡ç®—æ–°ä½ç½®
  æ—¶é—´å¤æ‚åº¦: O(n)
```

### Qwen æ¨¡å‹çš„ KV Cache ç»“æ„

Qwen2.5-0.5B æ¨¡å‹æœ‰ 24 å±‚ Transformerï¼Œä½¿ç”¨ **GQAï¼ˆGrouped-Query Attentionï¼‰** ä¼˜åŒ–ï¼š
- `past_key_values.{layer}.key`: shape `[batch, num_kv_heads, seq_len, head_dim]`
- `past_key_values.{layer}.value`: shape `[batch, num_kv_heads, seq_len, head_dim]`

å…¶ä¸­ï¼š
- `batch = 1`ï¼ˆæ‰¹æ¬¡å¤§å°ï¼‰
- `num_kv_heads = 2`ï¼ˆ**æ³¨æ„ï¼šä¸æ˜¯ 14ï¼** GQA ä½¿ç”¨æ›´å°‘çš„ KV headsï¼‰
- `head_dim = 64`ï¼ˆæ¯ä¸ªå¤´çš„ç»´åº¦ï¼‰
- `seq_len = 0`ï¼ˆé¦–æ¬¡æ¨ç†æ—¶ä¸º 0ï¼‰

> âš ï¸ **GQA è¯´æ˜**ï¼šQwen ä½¿ç”¨ Grouped-Query Attentionï¼Œquery heads æ•°é‡ï¼ˆ14ï¼‰ä¸ key/value heads æ•°é‡ï¼ˆ2ï¼‰ä¸åŒã€‚è¿™æ˜¯ä¸ºäº†å‡å°‘ KV Cache çš„å†…å­˜å ç”¨ã€‚

---

## å½“å‰è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆæ¦‚è¿°

**v1.4 æ›´æ–°ï¼ˆ2025-12-07ï¼‰ï¼šä½¿ç”¨ DirectBuffer æˆåŠŸæ”¯æŒ KV Cacheï¼**

å‘ç° ONNX Runtime å¯¹æ™®é€š Java æ•°ç»„ä¸æ”¯æŒé›¶ç»´åº¦ï¼Œä½†å¯¹ **DirectBuffer** æ”¯æŒã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ä½¿ç”¨ `ByteBuffer.allocateDirect(0)` åˆ›å»ºç©ºçš„ç›´æ¥ç¼“å†²åŒº
2. å°†å…¶è½¬æ¢ä¸º `FloatBuffer`
3. ä½¿ç”¨ `OnnxTensor.createTensor(env, buffer, shape)` åˆ›å»ºå¼ é‡

### ä»£ç å®ç°

#### 1. æ¨¡å‹ä¿¡æ¯æ£€æµ‹ (`logModelInfo`) - åŠ¨æ€æå–ç»´åº¦

```java
private void logModelInfo() {
    Map<String, NodeInfo> inputInfo = session.getInputInfo();
    for (Map.Entry<String, NodeInfo> entry : inputInfo.entrySet()) {
        String name = entry.getKey();
        NodeInfo info = entry.getValue();
        
        if (name.startsWith("past_key_values.")) {
            useKVCache = true;
            
            // æå–å±‚æ•°
            String[] parts = name.split("\\.");
            if (parts.length >= 2) {
                int layerNum = Integer.parseInt(parts[1]);
                numLayers = Math.max(numLayers, layerNum + 1);
            }
            
            // å…³é”®ï¼šä»æ¨¡å‹è¾“å…¥åŠ¨æ€æå– numHeads å’Œ headDim
            if (numHeads == 0 && info.getInfo() instanceof TensorInfo) {
                TensorInfo tensorInfo = (TensorInfo) info.getInfo();
                long[] shape = tensorInfo.getShape();
                // KV Cache å½¢çŠ¶: [batch, num_kv_heads, seq_len, head_dim]
                if (shape.length >= 4) {
                    numHeads = (int) shape[1];  // num_kv_heads (ä¸æ˜¯ num_heads!)
                    headDim = (int) shape[3];
                }
            }
        }
    }
}
```

**ä¸ºä»€ä¹ˆéœ€è¦åŠ¨æ€æå–ï¼Ÿ**
- Qwen ä½¿ç”¨ GQAï¼ˆGrouped-Query Attentionï¼‰
- Query heads æ•°é‡ï¼ˆ14ï¼‰ä¸ KV heads æ•°é‡ï¼ˆ2ï¼‰ä¸åŒ
- ç¡¬ç¼–ç  `numHeads=14` ä¼šå¯¼è‡´ç»´åº¦ä¸åŒ¹é…é”™è¯¯

#### 2. æ·»åŠ ç©º KV Cache (`addEmptyKVCache`) - å…³é”®ä¿®å¤

```java
private void addEmptyKVCache(Map<String, OnnxTensor> inputs, List<OnnxTensor> tensorsToClose)
        throws OrtException {
    for (int layer = 0; layer < numLayers; layer++) {
        String keyName = "past_key_values." + layer + ".key";
        String valueName = "past_key_values." + layer + ".value";

        // å…³é”®ï¼šä½¿ç”¨ DirectFloatBuffer åˆ›å»ºé›¶ç»´åº¦å¼ é‡
        // å½¢çŠ¶: [batch=1, num_heads, seq_len=0, head_dim]
        long[] shape = new long[]{1, numHeads, 0, headDim};
        
        // åˆ›å»ºç›´æ¥ç¼“å†²åŒºï¼ˆå®¹é‡ä¸º 0ï¼‰
        java.nio.FloatBuffer emptyBuffer = java.nio.ByteBuffer
                .allocateDirect(0)
                .order(java.nio.ByteOrder.nativeOrder())
                .asFloatBuffer();
        
        OnnxTensor keyTensor = OnnxTensor.createTensor(env, emptyBuffer, shape);
        OnnxTensor valueTensor = OnnxTensor.createTensor(env, emptyBuffer, shape);

        tensorsToClose.add(keyTensor);
        tensorsToClose.add(valueTensor);

        inputs.put(keyName, keyTensor);
        inputs.put(valueName, valueTensor);
    }
}
```

**ä¸ºä»€ä¹ˆ DirectBuffer æœ‰æ•ˆï¼Ÿ**
- æ™®é€š Java æ•°ç»„ï¼šONNX Runtime éªŒè¯æ•°ç»„ç»´åº¦ï¼Œæ‹’ç»é›¶ç»´åº¦
- DirectBufferï¼šONNX Runtime ç›´æ¥ä½¿ç”¨ç¼“å†²åŒºæŒ‡é’ˆ + å½¢çŠ¶ä¿¡æ¯ï¼Œå…è®¸é›¶ç»´åº¦
```

#### 3. æ¨ç†æ—¶è‡ªåŠ¨å¤„ç† (`calculatePerplexity`)

```java
// å‡†å¤‡åŸºæœ¬è¾“å…¥
inputs.put("input_ids", inputIdsTensor);
inputs.put("attention_mask", attentionMaskTensor);
inputs.put("position_ids", positionIdsTensor);

// å¦‚æœæ¨¡å‹ä½¿ç”¨ KV Cacheï¼Œæ·»åŠ ç©ºçš„ past_key_values
if (useKVCache) {
    addEmptyKVCache(inputs, tensorsToClose);
}

// æ‰§è¡Œæ¨ç†
try (OrtSession.Result results = session.run(inputs)) {
    // ... è®¡ç®— PPL
}
```

---

## ç”¨æˆ·è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨ Ollama æ›¿ä»£ï¼ˆæ¨èï¼‰

Ollama æ˜¯ä¸€ä¸ªæœ¬åœ°å¤§æ¨¡å‹è¿è¡Œæ¡†æ¶ï¼Œä½¿ç”¨ç®€å•ä¸”ç¨³å®šã€‚

```bash
# 1. å®‰è£… Ollama
# Windows: https://ollama.com/download/windows
# Linux: curl -fsSL https://ollama.com/install.sh | sh
# macOS: brew install ollama

# 2. ä¸‹è½½ Qwen æ¨¡å‹
ollama pull qwen2.5:0.5b

# 3. éªŒè¯å®‰è£…
ollama list
```

ä¿®æ”¹é…ç½®æ–‡ä»¶ `application.yml`ï¼š

```yaml
knowledge:
  qa:
    ppl:
      # å°†é»˜è®¤æä¾›å•†ä» onnx æ”¹ä¸º ollama
      default-provider: ollama
      
      ollama:
        enabled: true
        base-url: http://localhost:11434
        model: qwen2.5:0.5b
```

### æ–¹æ¡ˆäºŒï¼šç¦ç”¨ PPL Rerank

å¦‚æœä¸éœ€è¦ PPL é‡æ’åºåŠŸèƒ½ï¼Œå¯ä»¥ç›´æ¥ç¦ç”¨ï¼š

```yaml
knowledge:
  qa:
    ppl:
      reranking:
        enabled: false
```

### æ–¹æ¡ˆä¸‰ï¼šä½¿ç”¨ä¸å¸¦ KV Cache çš„ ONNX æ¨¡å‹

å¦‚æœéœ€è¦ä½¿ç”¨ ONNX æœ¬åœ°æ¨ç†ï¼Œéœ€è¦é‡æ–°å¯¼å‡ºæ¨¡å‹æ—¶ç¦ç”¨ KV Cacheï¼š

```python
# ä½¿ç”¨ optimum-cli å¯¼å‡ºï¼ˆç¦ç”¨ KV Cacheï¼‰
optimum-cli export onnx \
    --model Qwen/Qwen2.5-0.5B-Instruct \
    --task text-generation \
    --no-post-process \
    qwen2.5-0.5b-onnx-no-cache/
```

---

## é…ç½®å‚è€ƒ

### PPL æœåŠ¡é™çº§é…ç½®

```yaml
knowledge:
  qa:
    ppl:
      # å¯ç”¨é™çº§ç­–ç•¥
      enable-fallback: true
      
      # é™çº§é¡ºåºï¼ˆä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰
      fallback-order:
        - ollama    # ä¼˜å…ˆï¼šæœ¬åœ° Ollama
        - onnx      # æ¬¡é€‰ï¼šæœ¬åœ° ONNX
        - openai    # å¤‡ç”¨ï¼šäº‘ç«¯ API
```

### å„å¼•æ“å¯¹æ¯”

| å¼•æ“ | é€Ÿåº¦ | ç²¾åº¦ | æˆæœ¬ | KV Cache æ”¯æŒ | æ¨èåœºæ™¯ |
|------|------|------|------|---------------|---------|
| ONNX | âš¡å¿« | ä¸­ | å…è´¹ | âœ… å·²æ”¯æŒï¼ˆv1.4 DirectBufferï¼‰ | **æ¨èæœ¬åœ°éƒ¨ç½²** |
| Ollama | âš¡å¿« | ä¸­ | å…è´¹ | âœ… è‡ªåŠ¨å¤„ç† | ç®€å•éƒ¨ç½² |
| OpenAI | æ…¢ | é«˜ | æ”¶è´¹ | âœ… ä¸æ¶‰åŠ | é«˜ç²¾åº¦éœ€æ±‚ |

---

## æœªæ¥ä¼˜åŒ–æ–¹å‘

### çŸ­æœŸï¼ˆv2.1ï¼‰

- [x] ~~æ·»åŠ ç©º KV Cache å¼ é‡æ”¯æŒ~~ âœ… å·²å®Œæˆï¼ˆä½¿ç”¨ DirectBufferï¼‰
- [x] ~~æµ‹è¯•å¹¶éªŒè¯ç©º KV Cache æ–¹æ¡ˆ~~ âœ… å·²å®Œæˆ
- [x] è‡ªåŠ¨æ£€æµ‹ KV Cache æ¨¡å‹å¹¶æ­£ç¡®å¤„ç† âœ… å·²å®Œæˆ

### é•¿æœŸï¼ˆv3.0ï¼‰

- [ ] æ”¯æŒå¢é‡æ¨ç†ï¼ˆåˆ©ç”¨ KV Cache åŠ é€Ÿè¿ç»­æ¨ç†ï¼‰
- [ ] æä¾›é¢„å¯¼å‡ºçš„æ—  KV Cache ONNX æ¨¡å‹ä¸‹è½½
- [ ] é›†æˆ GGUF æ ¼å¼æ¨¡å‹æ”¯æŒï¼ˆllama.cppï¼‰

---

## ç›¸å…³æ—¥å¿—

å½“æ¨¡å‹ä½¿ç”¨ KV Cache æ—¶ï¼Œå¯åŠ¨æ—¥å¿—ä¼šæ˜¾ç¤ºï¼š

```
ğŸ“Š æ¨¡å‹è¾“å…¥ä¿¡æ¯ (Model Input Info):
  - è¾“å…¥: input_ids (ç±»å‹: ...)
  - è¾“å…¥: attention_mask (ç±»å‹: ...)
  - è¾“å…¥: position_ids (ç±»å‹: ...)
  - è¾“å…¥: past_key_values.0.key (ç±»å‹: ...)
  - è¾“å…¥: past_key_values.0.value (ç±»å‹: ...)
  - è¾“å…¥: past_key_values.1.key (ç±»å‹: ...)
  ... (æ¯å±‚éƒ½æœ‰ key å’Œ value)
  
âš ï¸ æ¨¡å‹ä½¿ç”¨ KV Cacheï¼Œå…± 24 å±‚
âœ… å·²æ·»åŠ  24 å±‚ç©º KV Cache (Added 24 layers of empty KV Cache)
```

**PPL è®¡ç®—æˆåŠŸæ—¶**ï¼š
```
âœ… PPL è®¡ç®—å®Œæˆ: æ–‡æœ¬="Hello world", PPL=15.23, è€—æ—¶=50ms
```

---

## å¸¸è§é—®é¢˜æ’æŸ¥

### åœºæ™¯ï¼šPPL Rerank å¤±è´¥å¹¶ä½¿ç”¨åŸæ’åº

**æ—¥å¿—ç‰¹å¾**ï¼š
```
âš ï¸ rerank failed using Hugging Face ONNX: [Hugging Face ONNX] æ–‡æ¡£é‡æ’åºå¤±è´¥
ğŸ”„ Trying fallback for rerank...
âš ï¸ PPL Rerank å¤±è´¥ï¼Œä½¿ç”¨åŸæ’åº: [Hugging Face ONNX] rerank failed and all fallbacks exhausted
```

**åŸå› åˆ†æ**ï¼š

1. **ONNX æœåŠ¡æ£€æµ‹åˆ° KV Cache æ¨¡å‹**
   - ç³»ç»Ÿæ£€æµ‹åˆ°å½“å‰ ONNX æ¨¡å‹åŒ…å« KV Cache
   - ä¸»åŠ¨æ‹’ç»æœåŠ¡å¹¶æŠ›å‡ºå¼‚å¸¸ï¼ˆè¿™æ˜¯é¢„æœŸè¡Œä¸ºï¼‰

2. **é™çº§æœåŠ¡ä¸å¯ç”¨**
   - `all fallbacks exhausted` è¡¨ç¤ºæ‰€æœ‰å¤‡ç”¨æœåŠ¡éƒ½ä¸å¯ç”¨
   - å¯èƒ½åŸå› ï¼š
     - Ollama æœªå®‰è£…æˆ–æœªå¯åŠ¨
     - Ollama ä¸­æ²¡æœ‰ä¸‹è½½æ‰€éœ€æ¨¡å‹
     - é…ç½®çš„ OpenAI API Key æ— æ•ˆ

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# æ–¹æ¡ˆ 1ï¼šå¯åŠ¨ Ollama å¹¶ä¸‹è½½æ¨¡å‹
ollama serve                    # å¯åŠ¨ Ollama æœåŠ¡ï¼ˆå¦‚æœªè¿è¡Œï¼‰
ollama pull qwen2.5:0.5b       # ä¸‹è½½ Qwen æ¨¡å‹

# æ–¹æ¡ˆ 2ï¼šç¦ç”¨ PPL Rerank
# åœ¨ application.yml ä¸­è®¾ç½®:
# knowledge.qa.ppl.reranking.enabled: false
```

**éªŒè¯é™çº§æ˜¯å¦é…ç½®æ­£ç¡®**ï¼š

æ£€æŸ¥ `application.yml` ä¸­çš„é…ç½®ï¼š
```yaml
knowledge:
  qa:
    ppl:
      enable-fallback: true      # ç¡®ä¿å¯ç”¨é™çº§
      fallback-order:
        - ollama                 # ä¼˜å…ˆé™çº§åˆ° Ollama
        - openai                 # å¤‡ç”¨ï¼šäº‘ç«¯ API
      
      ollama:
        enabled: true
        base-url: http://localhost:11434
        model: qwen2.5:0.5b
```

### åœºæ™¯ï¼šå‘é‡ç´¢å¼•ä¸ºç©º

**æ—¥å¿—ç‰¹å¾**ï¼š
```
ç´¢å¼•ä¸ºç©ºï¼Œè¿”å›ç©ºç»“æœ
```

**è¯´æ˜**ï¼šè¿™æ˜¯æ­£å¸¸çš„ã€‚å‘é‡æ£€ç´¢è¿”å›ç©ºç»“æœæ—¶ï¼Œç³»ç»Ÿä¼šä½¿ç”¨çº¯ Lucene å…³é”®è¯æ£€ç´¢çš„ç»“æœã€‚æ··åˆæ£€ç´¢ä»ç„¶å¯ä»¥æ­£å¸¸å·¥ä½œã€‚

---

## å‚è€ƒèµ„æ–™

- [ONNX Runtime å®˜æ–¹æ–‡æ¡£](https://onnxruntime.ai/docs/)
- [Hugging Face Optimum ONNX å¯¼å‡º](https://huggingface.co/docs/optimum/onnxruntime/usage_guides/export)
- [Ollama å®˜æ–¹æ–‡æ¡£](https://ollama.com/)
- [Qwen2.5 æ¨¡å‹è¯´æ˜](https://github.com/QwenLM/Qwen2.5)

---

## æ›´æ–°å†å²

| ç‰ˆæœ¬ | æ—¥æœŸ | è¯´æ˜ |
|------|------|------|
| v1.5 | 2025-12-07 | **å…³é”®ä¿®å¤**ï¼šåŠ¨æ€æå– KV Cache ç»´åº¦ï¼ˆnumHeads/headDimï¼‰ï¼Œæ”¯æŒ GQA æ¨¡å‹ |
| v1.4 | 2025-12-07 | ä½¿ç”¨ DirectBuffer æˆåŠŸæ”¯æŒ KV Cache æ¨¡å‹ |
| v1.3 | 2025-12-07 | ç¦ç”¨ PPL Rerank åŠŸèƒ½ï¼Œæ›´æ–°é…ç½®æ–‡ä»¶ |
| v1.2 | 2025-12-07 | ç¡®è®¤ ONNX Runtime ä¸æ”¯æŒé›¶ç»´åº¦å¼ é‡ï¼Œæ”¹ä¸ºæ£€æµ‹å¹¶è‡ªåŠ¨é™çº§åˆ° Ollama |
| v1.1 | 2025-12-07 | å°è¯•å®ç° KV Cache æ”¯æŒï¼ˆæµ‹è¯•å¤±è´¥ï¼‰ |
| v1.0 | 2025-12-07 | åˆå§‹ç‰ˆæœ¬ï¼Œè®°å½• KV Cache å…¼å®¹æ€§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ |

