# Prompt 提示词配置说明

## 概述

从 v1.0 版本开始，系统支持通过配置文件自定义 LLM Prompt 提示词模板，无需修改代码即可调整 AI 回答的风格和要求。

## 配置位置

配置文件：`config/application.yml`

配置路径：`knowledge.qa.llm.prompt-template`

## 配置格式

```yaml
knowledge:
  qa:
    llm:
      # Prompt 提示词模板
      # 支持两个占位符：
      #   - {question}: 用户问题
      #   - {context}: 相关文档内容
      prompt-template: |
        你是一个专业的知识助手。请基于文档内容回答用户问题。
        
        # 回答要求
        1. 必须基于文档内容回答，不要编造信息
        2. 如果文档中没有相关信息，明确告知用户
        3. 回答要清晰、准确、有条理
        4. 可以引用文档名称作为信息来源
        5. 保持专业友好的语气
        
        # 用户问题
        {question}
        
        # 相关文档
        {context}
        
        # 请提供你的回答：
```

## 占位符说明

提示词模板支持以下占位符，系统会在运行时自动替换：

| 占位符 | 说明 | 示例 |
|--------|------|------|
| `{question}` | 用户提出的问题 | "什么是 RAG 技术？" |
| `{context}` | 从知识库检索到的相关文档内容 | 包含相关文档的文本片段 |

## 自定义示例

### 示例 1：客服助手风格

```yaml
prompt-template: |
  你是一位热情友好的客服助手。请根据产品文档回答客户问题。
  
  回答要求：
  - 使用简单易懂的语言
  - 保持耐心和礼貌
  - 如果文档中找不到答案，请引导客户联系人工客服
  
  客户问题：{question}
  
  相关文档：
  {context}
  
  请提供专业且友好的回答：
```

### 示例 2：技术文档助手

```yaml
prompt-template: |
  你是一位专业的技术文档助手。基于以下技术文档回答问题。
  
  要求：
  1. 回答要准确、专业、技术性强
  2. 包含具体的技术细节和示例
  3. 如适用，提供代码片段或命令
  4. 引用文档来源
  
  问题：{question}
  
  相关技术文档：
  {context}
  
  技术回答：
```

### 示例 3：教育辅导风格

```yaml
prompt-template: |
  你是一位耐心的教育辅导老师。请用通俗易懂的方式解答学生的问题。
  
  教学要求：
  - 分步骤讲解，由浅入深
  - 使用类比和例子帮助理解
  - 鼓励学生思考
  - 基于教材内容回答
  
  学生提问：{question}
  
  教材内容：
  {context}
  
  请提供教学解答：
```

### 示例 4：法律咨询风格

```yaml
prompt-template: |
  你是一位专业的法律顾问助手。请基于法律文档提供专业建议。
  
  注意事项：
  1. 严格基于法律条文和文档内容
  2. 保持客观、严谨的表述
  3. 明确指出法律依据
  4. 如涉及复杂情况，建议咨询专业律师
  
  咨询问题：{question}
  
  相关法律文档：
  {context}
  
  法律意见：
```

### 示例 5：简洁问答风格

```yaml
prompt-template: |
  基于以下文档回答问题，要求简洁明了。
  
  问题：{question}
  
  文档：{context}
  
  回答：
```

## 最佳实践

### 1. 提示词结构建议

推荐的提示词结构包含：

1. **角色定义**：明确 AI 的角色（如：专业助手、客服、老师等）
2. **回答要求**：列出具体的回答规范和注意事项
3. **问题部分**：使用 `{question}` 占位符
4. **上下文部分**：使用 `{context}` 占位符
5. **输出引导**：提示 AI 开始输出回答

### 2. 提示词优化技巧

- **清晰具体**：要求越具体，回答质量越好
- **分点列举**：使用编号或符号列举要求，便于 AI 理解
- **示例引导**：如果需要特定格式，可在提示词中给出示例
- **约束条件**：明确什么可以做，什么不可以做
- **语气控制**：通过用词影响 AI 回答的语气和风格

### 3. 调试和测试

1. 修改配置文件后，重启应用使配置生效
2. 通过 Web 界面测试不同问题的回答效果
3. 根据反馈调整提示词，逐步优化
4. 保存不同版本的提示词配置，便于对比测试

### 4. 常见问题

**Q: 修改配置后多久生效？**  
A: 需要重启应用。停止应用（stop.bat），修改配置文件，然后重新启动（start.bat）。

**Q: 占位符必须使用吗？**  
A: 是的，`{question}` 和 `{context}` 必须在提示词模板中存在，否则 AI 无法获取问题和文档内容。

**Q: 提示词太长会有问题吗？**  
A: 提示词本身会占用 LLM 的 token 配额。建议控制在 500 字符以内，避免过长影响上下文容量。

**Q: 如何恢复默认配置？**  
A: 删除 `prompt-template` 配置项，或使用上面"配置格式"部分的默认模板。

**Q: 支持多语言提示词吗？**  
A: 支持。可以使用中文、英文或其他语言编写提示词，根据您的 LLM 模型能力选择。

## 高级用法

### 结合其他配置项

Prompt 模板可以与其他配置项配合使用，实现更精细的控制：

```yaml
knowledge:
  qa:
    llm:
      # 控制上下文长度
      max-context-length: 20000
      max-doc-length: 5000
      
      # 自定义提示词
      prompt-template: |
        你是专业的技术支持助手。
        
        回答要求：
        1. 基于文档内容回答
        2. 保持简洁明了
        
        问题：{question}
        文档：{context}
        回答：
```

### 动态调整策略

根据业务场景，可以准备多个配置文件：

```
config/
  ├── application.yml              # 默认配置
  ├── application-customer.yml     # 客服场景
  ├── application-technical.yml    # 技术支持场景
  └── application-education.yml    # 教育辅导场景
```

通过启动参数切换：
```bash
java -jar ai-reviewer-base-file-rag-1.0.jar --spring.profiles.active=customer
```

## 相关配置

其他与 LLM 相关的配置项：

```yaml
knowledge:
  qa:
    llm:
      provider: openai              # LLM 提供商
      api-key: ${AI_API_KEY:}       # API 密钥
      api-url: https://api.deepseek.com/v1/chat/completions
      model: deepseek-chat          # 模型名称
      max-context-length: 20000     # 最大上下文长度
      max-doc-length: 5000          # 单文档最大长度
      prompt-template: |            # 提示词模板（本功能）
        ...
```

## 反馈和建议

如果您有好的提示词模板或改进建议，欢迎分享到：
- GitHub Issues
- 项目讨论区
- 贡献到项目文档

---

**最后更新**: 2025-11-25  
**版本**: v1.0

