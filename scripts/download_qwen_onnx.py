#!/usr/bin/env python3
"""
Qwen ONNX æ¨¡å‹ä¸‹è½½è„šæœ¬ï¼ˆä½¿ç”¨ optimum-cliï¼‰
æœ€ç®€å•ã€æœ€ç¨³å®šçš„æ–¹å¼

ä½¿ç”¨æ–¹æ³•ï¼š
    python download_qwen_onnx.py --model 0.5b
    æˆ–è€…
    python download_qwen_onnx.py --model 1.5b
"""

import os
import sys
import argparse
import subprocess
from pathlib import Path

def install_package(package_name):
    """å®‰è£… Python åŒ…"""
    print(f"ğŸ“¥ å®‰è£… {package_name}...")
    try:
        subprocess.check_call(
            [sys.executable, "-m", "pip", "install", "--upgrade", package_name],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.PIPE
        )
        print(f"âœ… {package_name} å®‰è£…æˆåŠŸ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ {package_name} å®‰è£…å¤±è´¥: {e.stderr.decode() if e.stderr else str(e)}")
        return False

def check_and_install_dependencies():
    """æ£€æŸ¥å¹¶è‡ªåŠ¨å®‰è£…æ‰€æœ‰å¿…éœ€çš„ä¾èµ–"""
    print("=" * 70)
    print("ğŸ“¦ æ£€æŸ¥å¹¶å®‰è£…ä¾èµ–...")
    print("=" * 70)

    required_packages = {
        "transformers": "transformers>=4.30.0",
        "optimum": "optimum[onnxruntime]>=1.14.0",
        "onnxruntime": "onnxruntime>=1.15.0",
        "torch": "torch>=2.0.0",
        "onnxscript": "onnxscript>=0.1.0"
    }

    installed_packages = []
    failed_packages = []

    for package_name, package_spec in required_packages.items():
        try:
            # å°è¯•å¯¼å…¥åŒ…
            __import__(package_name)
            print(f"âœ… {package_name} å·²å®‰è£…")
            installed_packages.append(package_name)
        except ImportError:
            print(f"âš ï¸  {package_name} æœªå®‰è£…ï¼Œå¼€å§‹å®‰è£…...")
            if install_package(package_spec):
                installed_packages.append(package_name)
            else:
                failed_packages.append(package_name)

    print()
    if failed_packages:
        print(f"âŒ ä»¥ä¸‹ä¾èµ–å®‰è£…å¤±è´¥: {', '.join(failed_packages)}")
        print("\nè¯·æ‰‹åŠ¨å®‰è£…:")
        print(f"pip install {' '.join([required_packages[p] for p in failed_packages])}")
        return False

    print(f"âœ… æ‰€æœ‰ä¾èµ–å·²å°±ç»ª ({len(installed_packages)}/{len(required_packages)})")
    print("=" * 70)
    print()
    return True

def check_optimum_cli():
    """æ£€æŸ¥ optimum-cli æ˜¯å¦å¯ç”¨"""
    result = subprocess.run(
        [sys.executable, "-m", "optimum.exporters.onnx", "--help"],
        capture_output=True
    )
    return result.returncode == 0

def download_onnx_model(model_name, output_dir):
    """ä½¿ç”¨ optimum-cli ä¸‹è½½ ONNX æ¨¡å‹"""

    print(f"ğŸš€ å¼€å§‹ä¸‹è½½å¹¶è½¬æ¢æ¨¡å‹: {model_name}")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    model_dir_name = model_name.split("/")[-1].lower()
    output_path = Path(output_dir) / model_dir_name
    output_path.mkdir(parents=True, exist_ok=True)

    print(f"ğŸ“ è¾“å‡ºè·¯å¾„: {output_path}")

    # ä½¿ç”¨ optimum-cli å¯¼å‡º
    print("ğŸ”„ è½¬æ¢ä¸º ONNX æ ¼å¼ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ï¼‰...")
    print("ğŸ’¡ æç¤ºï¼šé¦–æ¬¡ä¸‹è½½ä¼šä» Hugging Face ä¸‹è½½æ¨¡å‹ï¼Œé€Ÿåº¦å–å†³äºç½‘ç»œ")

    cmd = [
        sys.executable, "-m", "optimum.exporters.onnx",
        "--model", model_name,
        "--task", "text-generation-with-past",
        str(output_path)
    ]

    print(f"\næ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}\n")

    result = subprocess.run(cmd, text=True)

    if result.returncode == 0:
        print(f"\nâœ… æ¨¡å‹ä¸‹è½½å’Œè½¬æ¢å®Œæˆï¼")
        print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {output_path}")

        # åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶
        print("\nğŸ“„ ç”Ÿæˆçš„æ–‡ä»¶:")
        for file in output_path.iterdir():
            size_mb = file.stat().st_size / (1024 * 1024)
            print(f"  - {file.name} ({size_mb:.1f} MB)")

        # éªŒè¯æ¨¡å‹å®Œæ•´æ€§
        if not validate_onnx_model(output_path):
            return False

        return True
    else:
        print(f"\nâŒ è½¬æ¢å¤±è´¥")
        return False


def validate_onnx_model(model_path):
    """
    éªŒè¯ ONNX æ¨¡å‹æ–‡ä»¶çš„å®Œæ•´æ€§

    Args:
        model_path: æ¨¡å‹ç›®å½•è·¯å¾„

    Returns:
        bool: éªŒè¯æ˜¯å¦é€šè¿‡
    """
    print("\n" + "=" * 70)
    print("ğŸ” éªŒè¯æ¨¡å‹å®Œæ•´æ€§...")
    print("=" * 70)

    model_path = Path(model_path)
    errors = []
    warnings = []

    # 1. æ£€æŸ¥å¿…éœ€æ–‡ä»¶
    required_files = {
        "model.onnx": "ONNX æ¨¡å‹æ–‡ä»¶",
        "tokenizer.json": "Tokenizer æ–‡ä»¶"
    }

    optional_files = {
        "model.onnx_data": "æ¨¡å‹æƒé‡æ•°æ®ï¼ˆå¤§æ¨¡å‹éœ€è¦ï¼‰",
        "tokenizer_config.json": "Tokenizer é…ç½®",
        "config.json": "æ¨¡å‹é…ç½®",
        "special_tokens_map.json": "ç‰¹æ®Š Token æ˜ å°„"
    }

    print("\nğŸ“‹ æ£€æŸ¥å¿…éœ€æ–‡ä»¶:")
    for filename, desc in required_files.items():
        filepath = model_path / filename
        if filepath.exists():
            size_mb = filepath.stat().st_size / (1024 * 1024)
            print(f"  âœ… {filename} ({size_mb:.2f} MB) - {desc}")
        else:
            errors.append(f"ç¼ºå¤±å¿…éœ€æ–‡ä»¶: {filename} ({desc})")
            print(f"  âŒ {filename} - {desc} [ç¼ºå¤±]")

    print("\nğŸ“‹ æ£€æŸ¥å¯é€‰æ–‡ä»¶:")
    for filename, desc in optional_files.items():
        filepath = model_path / filename
        if filepath.exists():
            size_mb = filepath.stat().st_size / (1024 * 1024)
            print(f"  âœ… {filename} ({size_mb:.2f} MB) - {desc}")
        else:
            print(f"  âš ï¸  {filename} - {desc} [ç¼ºå¤±]")

    # 2. éªŒè¯ model.onnx æ–‡ä»¶å¤§å°
    onnx_file = model_path / "model.onnx"
    onnx_data_file = model_path / "model.onnx_data"

    if onnx_file.exists():
        onnx_size = onnx_file.stat().st_size
        onnx_size_mb = onnx_size / (1024 * 1024)

        print(f"\nğŸ“Š æ¨¡å‹æ–‡ä»¶åˆ†æ:")
        print(f"  - model.onnx å¤§å°: {onnx_size_mb:.2f} MB")

        # æ£€æŸ¥ model.onnx_data æ–‡ä»¶
        if onnx_data_file.exists():
            data_size_mb = onnx_data_file.stat().st_size / (1024 * 1024)
            print(f"  - model.onnx_data å¤§å°: {data_size_mb:.2f} MB")
            total_size_mb = onnx_size_mb + data_size_mb
            print(f"  - æ€»æ¨¡å‹å¤§å°: {total_size_mb:.2f} MB")

            # Qwen 0.5B æ¨¡å‹åº”è¯¥è‡³å°‘ 500MBï¼Œ1.5B è‡³å°‘ 1.5GB
            if total_size_mb < 200:
                warnings.append(f"æ¨¡å‹æ€»å¤§å°ä»… {total_size_mb:.1f}MBï¼Œå¯¹äº Qwen æ¨¡å‹æ¥è¯´å¯èƒ½ä¸å®Œæ•´")
        else:
            # æ£€æŸ¥ model.onnx æ˜¯å¦å¼•ç”¨äº†å¤–éƒ¨æ•°æ®
            has_external_ref = False
            try:
                with open(onnx_file, 'rb') as f:
                    content = f.read(50000)  # è¯»å–å‰50KB
                    if b'model.onnx_data' in content or b'onnx_data' in content or b'external_data' in content:
                        has_external_ref = True
            except Exception as e:
                warnings.append(f"æ— æ³•æ£€æŸ¥ model.onnx å†…å®¹: {e}")

            if has_external_ref:
                errors.append(
                    f"model.onnx å¼•ç”¨äº†å¤–éƒ¨æ•°æ®æ–‡ä»¶ model.onnx_dataï¼Œä½†è¯¥æ–‡ä»¶ä¸å­˜åœ¨ï¼\n"
                    f"   è¿™ä¼šå¯¼è‡´æ¨¡å‹åŠ è½½å¤±è´¥ã€‚è¯·é‡æ–°ä¸‹è½½æ¨¡å‹ã€‚"
                )
                print(f"  âŒ æ£€æµ‹åˆ°å¤–éƒ¨æ•°æ®å¼•ç”¨ï¼Œä½† model.onnx_data æ–‡ä»¶ç¼ºå¤±!")
            elif onnx_size_mb < 100:
                # Qwen æ¨¡å‹å³ä½¿æ˜¯æœ€å°çš„ 0.5B ç‰ˆæœ¬ä¹Ÿåº”è¯¥å¾ˆå¤§
                errors.append(
                    f"model.onnx ä»… {onnx_size_mb:.2f}MBï¼Œè¿™å¯¹äº Qwen æ¨¡å‹æ¥è¯´å¤ªå°äº†ï¼\n"
                    f"   é¢„æœŸå¤§å°: Qwen-0.5B ~1GB, Qwen-1.5B ~3GB\n"
                    f"   é—®é¢˜: model.onnx_data æƒé‡æ–‡ä»¶ç¼ºå¤±ï¼Œæ¨¡å‹ä¸å®Œæ•´"
                )
                print(f"  âŒ model.onnx ä»… {onnx_size_mb:.2f}MB - æ¨¡å‹ä¸å®Œæ•´ï¼Œç¼ºå°‘æƒé‡æ•°æ®!")
            elif onnx_size_mb < 500:
                warnings.append(
                    f"model.onnx ä»… {onnx_size_mb:.1f}MBï¼Œæ²¡æœ‰ model.onnx_data æ–‡ä»¶ã€‚\n"
                    f"   Qwen æ¨¡å‹é€šå¸¸éœ€è¦ 500MB+ï¼Œå¯èƒ½ä¸å®Œæ•´ã€‚"
                )
                print(f"  âš ï¸  model.onnx å¤§å°åå°ï¼Œå¯èƒ½ç¼ºå°‘æƒé‡æ•°æ®")
            else:
                print(f"  - æ¨¡å‹ä¸ºå†…è”æƒé‡æ ¼å¼ï¼ˆæƒé‡åµŒå…¥åœ¨ .onnx æ–‡ä»¶ä¸­ï¼‰")

    # 3. å°è¯•ä½¿ç”¨ ONNX Runtime éªŒè¯
    print("\nğŸ§ª ä½¿ç”¨ ONNX Runtime éªŒè¯æ¨¡å‹...")
    try:
        import onnxruntime as ort

        sess_options = ort.SessionOptions()
        sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_DISABLE_ALL

        session = ort.InferenceSession(
            str(onnx_file),
            sess_options=sess_options,
            providers=['CPUExecutionProvider']
        )

        print("  âœ… ONNX Runtime åŠ è½½æˆåŠŸ")
        print(f"\nğŸ“‹ æ¨¡å‹ç»“æ„:")
        print(f"  è¾“å…¥:")
        for inp in session.get_inputs():
            print(f"    - {inp.name}: {inp.shape} ({inp.type})")
        print(f"  è¾“å‡º:")
        for out in session.get_outputs():
            print(f"    - {out.name}: {out.shape} ({out.type})")

    except Exception as e:
        error_msg = str(e)
        if "model.onnx_data" in error_msg or "external data" in error_msg.lower():
            errors.append(
                f"ONNX Runtime åŠ è½½å¤±è´¥: ç¼ºå¤±å¤–éƒ¨æ•°æ®æ–‡ä»¶ model.onnx_data\n"
                f"   åŸå§‹é”™è¯¯: {error_msg[:200]}"
            )
        else:
            errors.append(f"ONNX Runtime åŠ è½½å¤±è´¥: {error_msg[:300]}")
        print(f"  âŒ ONNX Runtime éªŒè¯å¤±è´¥: {error_msg[:200]}")

    # 4. è¾“å‡ºéªŒè¯ç»“æœ
    print("\n" + "=" * 70)
    if errors:
        print("âŒ æ¨¡å‹éªŒè¯å¤±è´¥!")
        print("\né”™è¯¯åˆ—è¡¨:")
        for i, error in enumerate(errors, 1):
            print(f"  {i}. {error}")
        print("\nğŸ’¡ å»ºè®®:")
        print("  1. åˆ é™¤å½“å‰æ¨¡å‹ç›®å½•ï¼Œé‡æ–°è¿è¡Œä¸‹è½½è„šæœ¬")
        print("  2. æ£€æŸ¥ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³")
        print("  3. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š")
        print("  4. å°è¯•ä½¿ç”¨ --mirror å‚æ•°ä½¿ç”¨å›½å†…é•œåƒ")
        return False
    elif warnings:
        print("âš ï¸  æ¨¡å‹éªŒè¯é€šè¿‡ï¼ˆæœ‰è­¦å‘Šï¼‰")
        print("\nè­¦å‘Šåˆ—è¡¨:")
        for i, warning in enumerate(warnings, 1):
            print(f"  {i}. {warning}")
        return True
    else:
        print("âœ… æ¨¡å‹éªŒè¯é€šè¿‡!")
        return True

def main():
    parser = argparse.ArgumentParser(
        description="ä¸‹è½½ Qwen æ¨¡å‹å¹¶è½¬æ¢ä¸º ONNX æ ¼å¼ï¼ˆä½¿ç”¨ optimum-cliï¼‰"
    )
    parser.add_argument(
        "--model",
        type=str,
        default="0.5b",
        choices=["0.5b", "1.5b", "7b"],
        help="é€‰æ‹©æ¨¡å‹å¤§å°ï¼š0.5bï¼ˆæ¨èï¼‰ã€1.5bã€7b"
    )
    parser.add_argument(
        "--output",
        type=str,
        default="./models",
        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼š./modelsï¼‰"
    )
    parser.add_argument(
        "--mirror",
        action="store_true",
        help="ä½¿ç”¨å›½å†…é•œåƒåŠ é€Ÿä¸‹è½½"
    )

    args = parser.parse_args()

    # æ¨¡å‹æ˜ å°„
    model_map = {
        "0.5b": "Qwen/Qwen2.5-0.5B-Instruct",
        "1.5b": "Qwen/Qwen2.5-1.5B-Instruct",
        "7b": "Qwen/Qwen2-7B-Instruct"
    }

    print("=" * 70)
    print("ğŸ‡¨ğŸ‡³ Qwen ONNX æ¨¡å‹ä¸‹è½½å·¥å…·ï¼ˆä½¿ç”¨ optimum-cliï¼‰")
    print("=" * 70)
    print()

    # æ£€æŸ¥å¹¶å®‰è£…ä¾èµ–
    if not check_and_install_dependencies():
        sys.exit(1)

    # è®¾ç½®é•œåƒ
    if args.mirror:
        print("ğŸŒ ä½¿ç”¨å›½å†…é•œåƒ...")
        os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

    # å†æ¬¡éªŒè¯ optimum-cli å¯ç”¨æ€§
    if not check_optimum_cli():
        print("âŒ optimum-cli ä»ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥å®‰è£…")
        sys.exit(1)

    print("âœ… optimum-cli å·²å°±ç»ª\n")

    # ä¸‹è½½æ¨¡å‹
    model_name = model_map[args.model]
    success = download_onnx_model(model_name, args.output)

    if success:
        print("\n" + "=" * 70)
        print("ğŸ‰ å®Œæˆï¼")
        print("=" * 70)
        print()
        print("ğŸ“ ä¸‹ä¸€æ­¥ï¼š")
        print("1. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶")
        print(f"   ls {args.output}/{model_name.split('/')[-1].lower()}/")
        print()
        print("2. æ›´æ–° application.yml é…ç½®")
        model_dir = model_name.split('/')[-1].lower()
        print(f"   model-path: ./{args.output}/{model_dir}/model.onnx")
        print(f"   tokenizer-path: ./{args.output}/{model_dir}/tokenizer.json")
        print()
        print("3. å¯åŠ¨åº”ç”¨")
        print("   ./mvnw spring-boot:run")
    else:
        print("\nâŒ æ¨¡å‹ä¸‹è½½å¤±è´¥")
        print("\nğŸ’¡ æ•…éšœæ’æŸ¥:")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("2. å°è¯•ä½¿ç”¨é•œåƒ: --mirror")
        print("3. æ£€æŸ¥ç£ç›˜ç©ºé—´ï¼ˆéœ€è¦ 2-10GBï¼‰")
        print("4. æŸ¥çœ‹é”™è¯¯ä¿¡æ¯å¹¶æœç´¢è§£å†³æ–¹æ¡ˆ")
        print("\nğŸ’¡ æ›¿ä»£æ–¹æ¡ˆ:")
        print("ä½¿ç”¨ Ollamaï¼ˆæ›´ç®€å•ï¼‰:")
        print("  ollama pull qwen2.5:0.5b")
        sys.exit(1)

if __name__ == "__main__":
    main()

