#!/usr/bin/env python3
"""
BGE æ¨¡å‹ ONNX è½¬æ¢è„šæœ¬
ä½¿ç”¨ optimum çš„ ORTModelForFeatureExtraction è¿›è¡Œè½¬æ¢
"""

import sys
import shutil
from pathlib import Path

def main():
    print("=" * 60)
    print("ğŸ”„ BGE æ¨¡å‹ ONNX è½¬æ¢å·¥å…·")
    print("=" * 60)

    model_path = Path("models/bge-base-zh")
    output_dir = Path("models/bge-base-zh-onnx-temp")

    if not model_path.exists():
        print(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_path}")
        return 1

    print(f"\nğŸ“ æºæ¨¡å‹: {model_path}")
    print(f"ğŸ“ ä¸´æ—¶è¾“å‡º: {output_dir}")

    # æ£€æŸ¥å½“å‰ model.onnx å¤§å°
    current_onnx = model_path / "model.onnx"
    if current_onnx.exists():
        size_mb = current_onnx.stat().st_size / (1024 * 1024)
        print(f"\nâš ï¸  å½“å‰ model.onnx å¤§å°: {size_mb:.2f} MB")
        if size_mb < 10:
            print("   è¿™ä¸ªæ–‡ä»¶å¤ªå°ï¼Œéœ€è¦é‡æ–°è½¬æ¢")

    print("\nğŸ”„ å¼€å§‹è½¬æ¢...")

    try:
        from optimum.onnxruntime import ORTModelForFeatureExtraction

        # æ¸…ç†æ—§çš„ä¸´æ—¶ç›®å½•
        if output_dir.exists():
            shutil.rmtree(output_dir)

        output_dir.mkdir(parents=True, exist_ok=True)

        # è½¬æ¢æ¨¡å‹
        print("   åŠ è½½æ¨¡å‹å¹¶è½¬æ¢ä¸º ONNX...")
        ort_model = ORTModelForFeatureExtraction.from_pretrained(
            str(model_path),
            export=True
        )
        ort_model.save_pretrained(str(output_dir))
        print("   âœ… è½¬æ¢å®Œæˆ")

        # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
        print("\nğŸ“„ ç”Ÿæˆçš„æ–‡ä»¶:")
        total_size = 0
        for f in sorted(output_dir.iterdir()):
            size_mb = f.stat().st_size / (1024 * 1024)
            total_size += size_mb
            print(f"   {f.name}: {size_mb:.2f} MB")
        print(f"   æ€»å¤§å°: {total_size:.2f} MB")

        # å¤åˆ¶æ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•
        print("\nğŸ“‹ å¤åˆ¶æ–‡ä»¶åˆ°æ¨¡å‹ç›®å½•...")

        onnx_file = output_dir / "model.onnx"
        onnx_data = output_dir / "model.onnx_data"

        if onnx_file.exists():
            # å¤‡ä»½æ—§æ–‡ä»¶
            if current_onnx.exists():
                backup = model_path / "model.onnx.bak"
                shutil.move(str(current_onnx), str(backup))
                print(f"   å·²å¤‡ä»½æ—§æ–‡ä»¶åˆ° model.onnx.bak")

            shutil.copy2(str(onnx_file), str(model_path / "model.onnx"))
            new_size = (model_path / "model.onnx").stat().st_size / (1024 * 1024)
            print(f"   âœ… model.onnx ({new_size:.2f} MB)")

        if onnx_data.exists():
            shutil.copy2(str(onnx_data), str(model_path / "model.onnx_data"))
            data_size = (model_path / "model.onnx_data").stat().st_size / (1024 * 1024)
            print(f"   âœ… model.onnx_data ({data_size:.2f} MB)")

        # æ¸…ç†ä¸´æ—¶ç›®å½•
        print("\nğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        shutil.rmtree(output_dir)
        print("   âœ… å·²åˆ é™¤ä¸´æ—¶ç›®å½•")

        # éªŒè¯
        print("\nğŸ§ª éªŒè¯æ¨¡å‹...")
        final_onnx = model_path / "model.onnx"
        final_size = final_onnx.stat().st_size / (1024 * 1024)

        if final_size < 10:
            print(f"   âŒ è½¬æ¢åæ–‡ä»¶ä»ç„¶å¤ªå° ({final_size:.2f} MB)")
            return 1

        try:
            import onnxruntime as ort
            sess = ort.InferenceSession(str(final_onnx), providers=['CPUExecutionProvider'])
            print(f"   âœ… ONNX Runtime åŠ è½½æˆåŠŸ")
            print(f"   è¾“å…¥: {[i.name for i in sess.get_inputs()]}")
            print(f"   è¾“å‡º: {[o.name for o in sess.get_outputs()]}")
        except Exception as e:
            print(f"   âš ï¸ ONNX Runtime éªŒè¯å¤±è´¥: {e}")

        print("\n" + "=" * 60)
        print("âœ… è½¬æ¢å®Œæˆ!")
        print("=" * 60)
        return 0

    except ImportError as e:
        print(f"\nâŒ ç¼ºå°‘ä¾èµ–: {e}")
        print("è¯·å®‰è£…: pip install optimum[onnxruntime]")
        return 1
    except Exception as e:
        print(f"\nâŒ è½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())

